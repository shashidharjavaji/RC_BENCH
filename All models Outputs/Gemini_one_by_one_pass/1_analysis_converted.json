{
    "analysis": [
        {
            "claim_id": 1,
            "claim": {
                "text": "We introduce Query-Relevant Neuron Cluster Attribution (QRNCA), a novel architecture-agnostic framework capable of identifying query-relevant neurons in LLMs.",
                "type": "",
                "location": "Introduction",
                "exact_quote": "We introduce Query-Relevant Neuron Cluster Attribution (QRNCA), a novel architecture-agnostic framework capable of identifying query-relevant neurons in LLMs."
            },
            "evidence": [
                {
                    "evidence_text": "We introduce Query-Relevant Neuron Cluster Attribution (QRNCA), a novel architecture-agnostic framework capable of identifying query-relevant neurons in LLMs.",
                    "strength": "strong",
                    "limitations": "None stated.",
                    "location": "Abstract",
                    "exact_quote": "We introduce Query-Relevant Neuron Cluster Attribution (QRNCA), a novel architecture-agnostic framework capable of identifying query-relevant neurons in LLMs."
                },
                {
                    "evidence_text": "Our proposed method outperforms baseline approaches.",
                    "strength": "moderate",
                    "limitations": "None stated.",
                    "location": "Results",
                    "exact_quote": "Our proposed method outperforms baseline approaches."
                },
                {
                    "evidence_text": "Two new datasets: we curate two multi-choice QA datasets that contain different types of knowledge, namely Domain Knowledge and Language knowledge.",
                    "strength": "moderate",
                    "limitations": "None stated.",
                    "location": "Related Work",
                    "exact_quote": "Two new datasets: we curate two multi-choice QA datasets that contain different types of knowledge, namely Domain Knowledge and Language knowledge."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 2,
            "claim": {
                "text": "QRNCA allows for the examination of long-form answers beyond triplet facts by employing the proxy task of multi-choice question answering.",
                "type": "",
                "location": "Introduction",
                "exact_quote": ""
            },
            "evidence": [
                {
                    "evidence_text": "To evaluate the effectiveness of our detected neurons, we build two multi-choice QA datasets spanning diverse domains and languages. Empirical evaluations demonstrate that our method outperforms baseline methods significantly.",
                    "strength": "strong",
                    "limitations": "The claim is only evaluated with two datasets and the effectiveness of the model might change if applied to other datasets.",
                    "location": "Section 1 Introduction",
                    "exact_quote": ""
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 3,
            "claim": {
                "text": "To evaluate the effectiveness of our detected neurons, we built two multi-choice QA datasets spanning diverse domains and languages.",
                "type": "",
                "location": "Introduction",
                "exact_quote": "To evaluate the effectiveness of our detected neurons, we built two multi-choice QA datasets spanning diverse domains and languages."
            },
            "evidence": [
                {
                    "evidence_text": "To evaluate the effectiveness of our detected neurons, we built two multi-choice QA datasets spanning diverse domains and languages.",
                    "strength": "strong",
                    "limitations": "None stated.",
                    "location": "Section 5.1 Experimental Settings",
                    "exact_quote": "To evaluate the effectiveness of our detected neurons, we built two multi-choice QA datasets spanning diverse domains and languages."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 4,
            "claim": {
                "text": "Empirical evaluations demonstrate that our method outperforms baseline methods significantly.",
                "type": "",
                "location": "Introduction",
                "exact_quote": "Table 3 presents the overall performance of various methods. Our QRNCA method consistently outperforms other baselines, evidenced by its higher PCR."
            },
            "evidence": [
                {
                    "evidence_text": "Table 3 presents the overall performance of various methods. Our QRNCA method consistently outperforms other baselines, evidenced by its higher PCR.",
                    "strength": "strong",
                    "limitations": "None stated",
                    "location": "Section 5.3",
                    "exact_quote": "Table 3 presents the overall performance of various methods. Our QRNCA method consistently outperforms other baselines, evidenced by its higher PCR."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 5,
            "claim": {
                "text": "Analysis of neuron distributions reveals the presence of visible localized regions, particularly within different domains.",
                "type": "",
                "location": "Introduction",
                "exact_quote": "To investigate this, we visualize domain- or language-specific neurons on a 2D geographical heatmap. The width of the heatmap corresponds to the dimension of FFNs in Llama-2-7B (11008), and the length represents the layer depth (32). We accumulate the value of naica(n[l]i[)][ to populate the heatmap. Figure 4 displays the geographical locations of QR neurons in Llama-2-7B across various academic domains and languages. The distribution of QR neurons appears sparse but with distinct regions, particularly for different domains. Notably, certain regions are visible in the middle layers (10-15), suggesting specific neuron patterns."
            },
            "evidence": [
                {
                    "evidence_text": "To investigate this, we visualize domain- or language-specific neurons on a 2D geographical heatmap. The width of the heatmap corresponds to the dimension of FFNs in Llama-2-7B (11008), and the length represents the layer depth (32). We accumulate the value of naica(n[l]i[)][ to populate the heatmap. Figure 4 displays the geographical locations of QR neurons in Llama-2-7B across various academic domains and languages. The distribution of QR neurons appears sparse but with distinct regions, particularly for different domains. Notably, certain regions are visible in the middle layers (10-15), suggesting specific neuron patterns.",
                    "strength": "strong",
                    "limitations": "The study only focused on Llama-2-7B",
                    "location": "Section 5.4, paragraph 2",
                    "exact_quote": "To investigate this, we visualize domain- or language-specific neurons on a 2D geographical heatmap. The width of the heatmap corresponds to the dimension of FFNs in Llama-2-7B (11008), and the length represents the layer depth (32). We accumulate the value of naica(n[l]i[)][ to populate the heatmap. Figure 4 displays the geographical locations of QR neurons in Llama-2-7B across various academic domains and languages. The distribution of QR neurons appears sparse but with distinct regions, particularly for different domains. Notably, certain regions are visible in the middle layers (10-15), suggesting specific neuron patterns."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 6,
            "claim": {
                "text": "Finally, we show potential applications of our detected neurons in knowledge editing and neuron-based prediction.",
                "type": "",
                "location": "Introduction",
                "exact_quote": "We provide two usage examples to showcase the potential applications of our detected QR neurons: Knowledge Editing and Neuron-Based Prediction."
            },
            "evidence": [
                {
                    "evidence_text": "We provide two usage examples to showcase the potential applications of our detected QR neurons: Knowledge Editing and Neuron-Based Prediction.",
                    "strength": "strong",
                    "limitations": "None.",
                    "location": "Section 6: Potential Applications",
                    "exact_quote": "We provide two usage examples to showcase the potential applications of our detected QR neurons: Knowledge Editing and Neuron-Based Prediction."
                },
                {
                    "evidence_text": "For this goal, we adjust the values of QR neurons by either boosting or suppressing them to determine if we can change the prediction of a query from incorrect to correct or vice versa.",
                    "strength": "moderate",
                    "limitations": "Method is not evaluated for all possible queries or domains.",
                    "location": "Section 6.1: Knowledge Editing",
                    "exact_quote": "For this goal, we adjust the values of QR neurons by either boosting or suppressing them to determine if we can change the prediction of a query from incorrect to correct or vice versa."
                },
                {
                    "evidence_text": "Table 5 presents the success rates of knowledge editing on our constructed language datasets. Our observations indicate that QRNCA achieves higher success rates than other baselines.",
                    "strength": "strong",
                    "limitations": "The evaluation is only for language-specific queries.",
                    "location": "Section 6.1: Knowledge Editing",
                    "exact_quote": "Table 5 presents the success rates of knowledge editing on our constructed language datasets. Our observations indicate that QRNCA achieves higher success rates than other baselines."
                },
                {
                    "evidence_text": "The intuition behind neuron-based prediction is that for a domain-specific question, if the corresponding localized regions are properly activated, the LLM is more likely to generate truthful answers. Otherwise, the LLM may produce hallucinating answers.",
                    "strength": "moderate",
                    "limitations": "The method is not evaluated for all possible queries or domains.",
                    "location": "Section 6.2: Neuron-Based PRediction",
                    "exact_quote": "The intuition behind neuron-based prediction is that for a domain-specific question, if the corresponding localized regions are properly activated, the LLM is more likely to generate truthful answers. Otherwise, the LLM may produce hallucinating answers."
                },
                {
                    "evidence_text": "The results are summarised in Table 6. We observe that the accuracy of the neuron-based predictions is very close to the accuracy of the prompt-based method of using the entire model (the used templates are shown in Table A3 in the SM).",
                    "strength": "strong",
                    "limitations": "The evaluation is only for domain-specific queries.",
                    "location": "Section 6.2: Neuron-Based Prediction",
                    "exact_quote": "The results are summarised in Table 6. We observe that the accuracy of the neuron-based predictions is very close to the accuracy of the prompt-based method of using the entire model (the used templates are shown in Table A3 in the SM)."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 7,
            "claim": {
                "text": "QRNCA aims to extract Query-Relevant (QR) neurons for each input query.",
                "type": "",
                "location": "Related Work",
                "exact_quote": "Our proposed method QRNCA aims to detect QR neurons for each input query. The process begins by transforming an open-ended generation task into a multiple-choice question-answering format."
            },
            "evidence": [
                {
                    "evidence_text": "Our proposed method QRNCA aims to detect QR neurons for each input query. The process begins by transforming an open-ended generation task into a multiple-choice question-answering format.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Section 5: Analyzing Detected QR Neurons, Paragraph 1",
                    "exact_quote": "Our proposed method QRNCA aims to detect QR neurons for each input query. The process begins by transforming an open-ended generation task into a multiple-choice question-answering format."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 8,
            "claim": {
                "text": "Two new datasets: we curate two multi-choice QA datasets that contain different types of knowledge, namely Domain Knowledge and Language knowledge.",
                "type": "",
                "location": "Related Work",
                "exact_quote": "We construct two datasets to locate knowledge neurons that cover two different categories: subject domains and languages."
            },
            "evidence": [
                {
                    "evidence_text": "We construct two datasets to locate knowledge neurons that cover two different categories: subject domains and languages.",
                    "strength": "strong",
                    "limitations": "",
                    "location": "Section 5.1: Experimental Settings",
                    "exact_quote": "We construct two datasets to locate knowledge neurons that cover two different categories: subject domains and languages."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 9,
            "claim": {
                "text": "In-depth studies: we visualize distributions of detected neurons and we are the first to show that there are visible localized regions in Llama.",
                "type": "",
                "location": "Related Work",
                "exact_quote": "The distribution of QR neurons appears sparse but with distinct regions, particularly for different domains."
            },
            "evidence": [
                {
                    "evidence_text": "The distribution of QR neurons appears sparse but with distinct regions, particularly for different domains.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Section 5.4",
                    "exact_quote": "The distribution of QR neurons appears sparse but with distinct regions, particularly for different domains."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 10,
            "claim": {
                "text": "Potential applications: we show that QRNCA might be useful for knowledge editing and neuron-based prediction.",
                "type": "",
                "location": "Related Work",
                "exact_quote": ""
            },
            "evidence": [
                {
                    "evidence_text": "Apart from using the metric of PCR in section 5.3, we are also interested in whether the detected QR neurons can be used for knowledge editing.",
                    "strength": "moderate",
                    "limitations": "None stated",
                    "location": "Section 6.1",
                    "exact_quote": ""
                },
                {
                    "evidence_text": "For this goal, we adjust the values of QR neurons by either boosting or suppressing them to determine if we can change the prediction of a query from incorrect to correct or vice versa.",
                    "strength": "moderate",
                    "limitations": "None stated",
                    "location": "Section 6.1",
                    "exact_quote": ""
                },
                {
                    "evidence_text": "The intuition behind neuron-based prediction is that for a domain-specific question, if the corresponding localized regions are properly activated, the LLM is more likely to generate truthful answers. Otherwise, the LLM may produce hallucinated answers",
                    "strength": "moderate",
                    "limitations": "None stated",
                    "location": "Section 6.2",
                    "exact_quote": ""
                },
                {
                    "evidence_text": "To this end, we test whether the correct answers to domain-specific questions can be predicted solely based on the activity of the associated neurons.",
                    "strength": "moderate",
                    "limitations": "None stated",
                    "location": "Section 6.2",
                    "exact_quote": ""
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "",
                "justification": "",
                "key_limitations": "",
                "confidence_level": ""
            }
        }
    ],
    "execution_times": {
        "single_pass_analysis_time": "107.46 seconds",
        "total_execution_time": "2087.25 seconds"
    }
}