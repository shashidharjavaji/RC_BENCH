Claim 1:
Type: methodology
Statement: The history of machine learning reveals a recurring theme: manually created artifacts become replaced by learned, more efficient solutions over time as we get more compute and data.
Location: Introduction
Exact Quote: However, the history of machine learning reveals a recurring theme: manually created artifacts become replaced by learned, more efficient solutions over time as we get more compute and data [15].

Evidence:
- Evidence Text: Early example from computer vision, where hand-designed features like HOG [18] were eventually replaced by learned features from Convolutional Neural Networks (CNNs, Krizhevsky et al. [36]).
  Strength: strong
  Location: Introduction
  Limitations: Only provides one example.
  Exact Quote: An early example is from computer vision, where hand-designed features like HOG [18] were eventually replaced by learned features from Convolutional Neural Networks (CNNs, Krizhevsky et al. [36]).

- Evidence Text: More recently, AutoML methods [34] and AI-Generating Algorithms (AI-GAs, Clune [15]) have also demonstrated the superiority of learned AI systems compared to hand-designed AI systems.
  Strength: strong
  Location: Introduction
  Limitations: Does not provide specific examples.
  Exact Quote: More recently, AutoML methods [34] and AI-Generating Algorithms (AI-GAs, Clune [15]) have also demonstrated the superiority of learned AI systems compared to hand-designed AI systems.

- Evidence Text: For example, the current best-performing CNN models come from Neural Architecture Search [23, 71] instead of manual design; in LLM alignment, learned loss functions [44] outperform most hand-designed ones such as DPO [63]; The AI Scientist [45] demonstrates an automated research pipeline, including the development of novel ML algorithms; and an endless number of robotics learning environments can be automatically generated in works like OMNI-EPIC [24], which demonstrate surprising creativity in generated environments and allow more efficient environment creation than the manual approach (see more examples in Section 5).
  Strength: strong
  Location: Introduction
  Limitations: Examples are not directly related to agentic systems.
  Exact Quote: For example, the current best-performing CNN models come from Neural Architecture Search [23, 71] instead of manual design; in LLM alignment, learned loss functions [44] outperform most hand-designed ones such as DPO [63]; The AI Scientist [45] demonstrates an automated research pipeline, including the development of novel ML algorithms; and an endless number of robotics learning environments can be automatically generated in works like OMNI-EPIC [24], which demonstrate surprising creativity in generated environments and allow more efficient environment creation than the manual approach (see more examples in Section 5).

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by multiple specific examples from different areas of machine learning.
Key Limitations: The examples do not specifically focus on agentic systems.

--------------------------------------------------

Claim 2:
Type: contribution
Statement: Automated Design of Agentic Systems (ADAS) may prove to be the fastest path to developing powerful agents.
Location: Introduction
Exact Quote: Therefore, in this paper, we propose a new research question: Can we automate the design of agentic systems rather _than relying on manual efforts?_ To explore the above research question, we describe a newly forming research area we call **Automated Design of Agentic Systems (ADAS), which aims to automatically invent novel build-_ing blocks and design powerful agentic systems (Section 2). We argue that ADAS may prove to be the fastest path to developing powerful agents, and show initial evidence that learned agents can greatly outperform hand-designed agents.

Evidence:
- Evidence Text: The proposed Meta Agent Search significantly outperforms state-of-the-art hand-designed baselines on the ARC logic puzzle task, four popular benchmarks on reading comprehension, math, science questions, and multi-task problem solving.
  Strength: strong
  Location: Introduction
  Limitations: The results may not generalize to other domains or tasks.
  Exact Quote: Our experiments show that the discovered agents substantially outperform state-of-the-art hand-designed baselines. For instance, our agents improve F1 scores on reading comprehension tasks by **13.6/100 and accuracy rates on math tasks by 14.4%. Additionally, they improve accuracy over baselines by 25.9% and 13.2% on GSM8K [16] and GSM-Hard [27] math tasks, respectively, after _transferring across domains.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by experimental results showing that the proposed algorithm outperforms hand-designed agents on a range of tasks.
Key Limitations: The results may not generalize to other domains or tasks, and the algorithm may not be able to discover all possible agents.

--------------------------------------------------

Claim 3:
Type: methodology
Statement: Most existing ADAS methods focus only on designing prompts, greatly limiting their ability to invent flexible design patterns in agents.
Location: Introduction
Exact Quote: Although a few existing works can be considered as ADAS methods, most of them focus only on designing prompts [87, 25], greatly limiting their ability to invent flexible design patterns in agents (Section 5).

Evidence:
- Evidence Text: PromptBreeder [25] mutates only text prompts, leaving other components, such as workflows, unchanged, limiting the discovery of agents with different workfl
  Strength: strong
  Location: Introduction
  Limitations: Only provides one example.
  Exact Quote: For example, PromptBreeder [25] mutates only text prompts, leaving other components, such as workflows, unchanged, limiting the discovery of agents with different workfl

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by an example showing that existing ADAS methods have limited ability to design flexible agents.
Key Limitations: The claim may not apply to all existing ADAS methods.

--------------------------------------------------

Claim 4:
Type: result
Statement: Meta Agent Search discovers novel agentic systems and outperforms existing state-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) challenge.
Location: Experiments / Case Study: ARC Challenge
Exact Quote: We first demonstrate how Meta Agent Search discovers novel agentic systems and outperforms existing state-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) challenge [14].

Evidence:
- Evidence Text: Meta Agent Search effectively and progressively discovers agents that perform better than state-of-the-art hand-designed baselines.
  Strength: strong
  Location: Figure 3a
  Limitations: None mentioned
  Exact Quote: As shown in Figure 3a, Meta Agent Search effectively and progressively discovers agents that perform better than state-of-the-art hand-designed baselines.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results in Figure 3a, which show that Meta Agent Search discovers agents that achieve higher performance than hand-designed baselines on the ARC challenge.
Key Limitations: The performance of Meta Agent Search may vary depending on the specific task and dataset.

--------------------------------------------------

Claim 5:
Type: result
Statement: Meta Agent Search has the potential to improve the capabilities of agents across math, reading, and reasoning domains.
Location: Experiments / Reasoning and Problem-Solving Domains
Exact Quote: Next, we investigate the potential of our algorithm to improve the capabilities of agents across math, reading, and reasoning domains.

Evidence:
- Evidence Text: Meta Agent Search discovers superior agents compared to the baselines in every domain.
  Strength: strong
  Location: Table 1
  Limitations: None mentioned
  Exact Quote: Meta Agent Search discovers superior agents compared**\nto the baselines in every domain.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results in Table 1, which show that Meta Agent Search discovers agents that achieve higher performance than hand-designed baselines across multiple domains.
Key Limitations: The performance of Meta Agent Search may vary depending on the specific task and dataset.

--------------------------------------------------

Claim 6:
Type: result
Statement: Meta Agent Search discovers agents that outperform state-of-the-art hand-designed agents on the ARC challenge.
Location: Experiments / Case Study: ARC Challenge
Exact Quote: We first demonstrate how Meta Agent Search discovers novel agentic systems and outperforms existing state-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) challenge [14].

Evidence:
- Evidence Text: Meta Agent Search discovers agents that achieve higher accuracy than state-of-the-art hand-designed agents on the ARC challenge.
  Strength: strong
  Location: Figure 3a
  Limitations: None mentioned
  Exact Quote: As shown in Figure 3a, Meta Agent Search effectively and progressively discovers agents that perform better than state-of-the-art hand-designed baselines.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results in Figure 3a, which show that Meta Agent Search discovers agents that achieve higher accuracy than hand-designed baselines on the ARC challenge.
Key Limitations: The performance of Meta Agent Search may vary depending on the specific task and dataset.

--------------------------------------------------

Claim 7:
Type: result
Statement: The best agent discovered by Meta Agent Search on the ARC challenge uses a complex feedback mechanism to refine answers more effectively.
Location: Experiments / Case Study: ARC Challenge
Exact Quote: The best-discovered agent is shown in Figure 3b, where a complex feedback mechanism is adopted to refine answers more effectively.

Evidence:
- Evidence Text: The visualization of the best agent discovered by Meta Agent Search on the ARC challenge shows a complex feedback mechanism.
  Strength: strong
  Location: Figure 3b
  Limitations: None mentioned
  Exact Quote: The visualization of the best agent discovered by Meta Agent Search on the ARC challenge.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by the visualization in Figure 3b, which shows that the best agent discovered by Meta Agent Search uses a complex feedback mechanism to refine answers.
Key Limitations: The performance of this feedback mechanism may vary depending on the specific task and dataset.

--------------------------------------------------

Claim 8:
Type: result
Statement: Meta Agent Search outperforms baselines for all evaluated domains, with significant improvements in accuracy and F1 score.
Location: Section 4.3
Exact Quote: Overall, the results across various domains showcase the effectiveness of Meta Agent Search in searching for agents tailored to specific domains.

Evidence:
- Evidence Text: Meta Agent Search achieves an accuracy of 53.4% on the MGSM (Math) domain, significantly higher than the best baseline of 39.0%.
  Strength: strong
  Location: Table 2
  Limitations: None mentioned.
  Exact Quote: Dynamic Role-Playing Architecture **53.4 ± 3.5**

- Evidence Text: Meta Agent Search outperforms baselines in both Math and non-Math domains when transferring agents from MGSM.
  Strength: moderate
  Location: Section 4.3
  Limitations: The performance of transferred agents in non-Math domains is not as high as agents specifically designed for those domains.
  Exact Quote: We find that agents discovered in the math domain can also be transferred to non-math domains.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence strongly supports the claim that Meta Agent Search outperforms baselines in both Math and non-Math domains.
Key Limitations: The claim is limited to the specific domains and baselines evaluated in the study.

--------------------------------------------------

Claim 9:
Type: result
Statement: Agents discovered by Meta Agent Search can generalize to different tasks and domains.
Location: Section 4.3
Exact Quote: These results highlight Meta Agent Search ’s ability to discover generalizable design patterns and agentic systems.

Evidence:
- Evidence Text: Agents transferred from the MGSM (Math) domain to the GSM8K and GSM-Hard Math domains achieve an accuracy of 69.5% and 31.2%, respectively.
  Strength: strong
  Location: Table 2
  Limitations: None mentioned.
  Exact Quote: |Dynamic Role-Playing Architecture **69.5 ± 3.2** **31.2 ± 3.2**|

- Evidence Text: Agents transferred from the MGSM (Math) domain to the MMLU (Multi-task) and DROP (Reading Comprehension) non-Math domains achieve an accuracy of 62.4% and 70.4%, respectively.
  Strength: moderate
  Location: Table 2
  Limitations: The performance of transferred agents in non-Math domains is not as high as agents specifically designed for those domains.
  Exact Quote: |Dynamic Role-Playing Architecture 62.4 ± 3.4 70.4 ± 0.9|

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence supports the claim that agents discovered by Meta Agent Search can generalize to different tasks and domains, although their performance may not be as high as agents specifically designed for those domains.
Key Limitations: The claim is limited to the specific domains and tasks evaluated in the study.

--------------------------------------------------

Claim 10:
Type: performance
Statement: Meta Agent Search can discover agents that outperform hand-designed agents across different models and domains.
Location: Section B: Generalizability and Transferability
Exact Quote: We observe that the searched agents consistently outperform the hand-designed agents with a substantial gap.

Evidence:
- Evidence Text: Table 3 shows that the searched agents outperform the hand-designed agents on ARC when transferred across different models.
  Strength: strong
  Location: Section B: Generalizability and Transferability
  Limitations: The results are limited to the specific models and domains tested.
  Exact Quote: Agents discovered by Meta Agent Search consistently outperform the baselines across different models.

- Evidence Text: Table 4 shows that the searched agents outperform the hand-designed agents on different math domains when transferred within math domains.
  Strength: strong
  Location: Section B: Generalizability and Transferability
  Limitations: The results are limited to the specific math domains tested.
  Exact Quote: Agents discovered by Meta Agent Search consistently outperform the baselines across different math domains.

- Evidence Text: Table 5 shows that the agents discovered in the math domain can be transferred to non-math domains and outperform or match the performance of baselines.
  Strength: strong
  Location: Section B: Generalizability and Transferability
  Limitations: The results are limited to the specific non-math domains tested.
  Exact Quote: Agents discovered by Meta Agent Search in the math domain can outperform or match the performance of baselines after being transferred to domains beyond math.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence strongly supports the claim that Meta Agent Search can discover agents that outperform hand-designed agents across different models and domains.
Key Limitations: The results are limited to the specific models and domains tested.

--------------------------------------------------

Claim 11:
Type: performance
Statement: Meta Agent Search can discover agents that generalize across different domains.
Location: Section B: Generalizability and Transferability
Exact Quote: These results illustrate that Meta Agent Search can discover generalizable design patterns and agentic systems.

Evidence:
- Evidence Text: Table 4 shows that the agents discovered in the math domain can be transferred to non-math domains and outperform or match the performance of baselines.
  Strength: strong
  Location: Section B: Generalizability and Transferability
  Limitations: The results are limited to the specific non-math domains tested.
  Exact Quote: Agents discovered by Meta Agent Search in the math domain can outperform or match the performance of baselines after being transferred to domains beyond math.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence supports the claim that Meta Agent Search can discover agents that generalize across different domains, but the results are limited to the specific non-math domains tested.
Key Limitations: The results are limited to the specific non-math domains tested.

--------------------------------------------------

Claim 12:
Type: methodology
Statement: Meta Agent Search can be used to study the origins of complexity emerging from human organization and society.
Location: Section A: More Future Work
Exact Quote: Therefore, the study in ADAS may enable us to observe how to create a simple set of conditions and have an algorithm to bootstrap itself from simplicity to produce complexity in a system akin to human society.

Evidence:
- Evidence Text: The agentic system is a machine learning system that operates primarily over natural language, a representation that is interpretable to humans and used by humans in constructing our organization and society.
  Strength: strong
  Location: Section A: More Future Work
  Limitations: The agentic system is a simplified model of human organization and society.
  Exact Quote: The agentic system is a machine learning system that operates primarily over natural language—a representation that is interpretable to humans and used by humans in constructing our organization and society.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence supports the claim that Meta Agent Search can be used to study the origins of complexity emerging from human organization and society, but the agentic system is a simplified model of human organization and society.
Key Limitations: The agentic system is a simplified model of human organization and society.

--------------------------------------------------

