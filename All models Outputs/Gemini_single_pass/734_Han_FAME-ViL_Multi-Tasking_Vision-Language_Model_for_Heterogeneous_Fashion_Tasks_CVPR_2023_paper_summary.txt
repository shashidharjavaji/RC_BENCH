Claim 1:
Type: contribution
Statement: Multi-task learning can save many parameters.
Location: Parameter-efficient tuning
Exact Quote: Due to the increase in the size of V+L models, there is a growing interest in developing parameter-efficient methods to quickly adapt a large pre-trained model to specific tasks by using as few extra parameters as possible.

Evidence:
Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is about the advantages of multi-task learning, but the provided evidence does not support this claim. It only talks about the motivation for developing parameter-efficient methods.
Key Limitations: Lack of evidence supporting the claim.

--------------------------------------------------

Claim 2:
Type: methodology
Statement: FAME-ViL is a multi-task learning method that is designed for heterogeneous fashion tasks.
Location: Introduction
Exact Quote: In this work, we introduce a novel FAshion-focused Multi-task Efficient learning method for various Vision-and-Language based fashion tasks, dubbed as FAME-ViL.

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is about the design of FAME-ViL, and the provided evidence directly supports this claim.
Key Limitations: None.

--------------------------------------------------

Claim 3:
Type: performance
Statement: FAME-ViL achieves superior performance across a set of diverse fashion tasks with much fewer parameters.
Location: Introduction
Exact Quote: It achieves superior performance across a set of diverse fashion tasks with much fewer parameters as in Fig. 1.

Evidence:
Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is about the performance of FAME-ViL, but the provided evidence is just a figure without any concrete data or experimental results.
Key Limitations: Lack of concrete evidence supporting the claim.

--------------------------------------------------

Claim 4:
Type: methodology
Statement: FAME-ViL is able to adapt to various fashion tasks with two novel adapters.
Location: Introduction
Exact Quote: Specifically, we design a task-versatile architecture on top of a pre-trained generic V+L model (i.e., CLIP [60]). To adapt the simple two-stream architecture of CLIP to various fashion tasks, we introduce a lightweight Cross-Attention Adapter (XAA) to enable the cross-modality interaction between the two streams.

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is about the design of FAME-ViL, and the provided evidence partially supports this claim by mentioning the introduction of two novel adapters.
Key Limitations: Lack of detailed information about the two adapters.

--------------------------------------------------

Claim 5:
Type: methodology
Statement: FAME-ViL introduces an efficient and effective multi-task training strategy supporting heterogeneous task modes in one unified model.
Location: Introduction
Exact Quote: We introduce an efficient and effective multi-task training strategy supporting heterogeneous task modes in one unified model.

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is about the training strategy of FAME-ViL, and the provided evidence directly supports this claim.
Key Limitations: Lack of detailed information about the training strategy.

--------------------------------------------------

Claim 6:
Type: performance
Statement: FAME-ViL achieves new state-of-the-art performance on all tasks with significantly fewer parameters.
Location: 5. Conclusions
Exact Quote: Our FAME-ViL achieves new state-of-the-art performance on all tasks with significantly fewer parameters.

Evidence:
Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is not supported by any evidence in the provided text.
Key Limitations: Lack of supporting evidence.

--------------------------------------------------

Claim 7:
Type: methodology
Statement: The proposed task-versatile architecture with cross-attention adapters and task-specific adapters is effective.
Location: 5. Conclusions
Exact Quote: It addresses cross-modal retrieval, text-guided image retrieval, multi-modal classification, and image captioning in a unified architecture. This is made possible by the proposed task-versatile architecture with cross-attention adapters and task-specific adapters

Evidence:
Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is not supported by any evidence in the provided text.
Key Limitations: Lack of supporting evidence.

--------------------------------------------------

Claim 8:
Type: methodology
Statement: The proposed scalable multi-task training pipeline with multi-teacher distillation is effective.
Location: 5. Conclusions
Exact Quote: and a scalable multi-task training pipeline with multi-teacher distillation.

Evidence:
Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is not supported by any evidence in the provided text.
Key Limitations: Lack of supporting evidence.

--------------------------------------------------

