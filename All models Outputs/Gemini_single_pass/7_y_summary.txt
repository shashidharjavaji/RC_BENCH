Claim 1:
Type: performance
Statement: The utilization of textual and audio data from quarterly earnings conference calls increases volatility prediction accuracy by 17%-49%.
Location: ABSTRACT
Exact Quote: This includes a comprehensive comparison to a variety of baselines, which demonstrates very significant improvements in prediction accuracy, in the range 17% - 49% compared to the current state-of-the-art.

Evidence:
- Evidence Text: The accuracy of the proposed method is compared against several baseline techniques and shows improvements ranging from 17% to 49%.
  Strength: strong
  Location: Section 5
  Limitations: None.
  Exact Quote: The results of this evaluation demonstrate clear and significant prediction accuracy benefits accruing to our proposed approach, accuracy improvements in the range 17% - 49% compared to the current-state-of-the-art.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results comparing the proposed method with several baseline techniques, showing significant improvements in prediction accuracy.
Key Limitations: The evaluation is based on a single dataset and may not generalize to other datasets.

--------------------------------------------------

Claim 2:
Type: methodology
Statement: A novel Hierarchical Transformer-based Multi-Task (HTML) model is proposed for volatility forecasting.
Location: INTRODUCTION
Exact Quote: Figure 2 presents our Hierarchical, Transformer-based, Multi-Task (HTML) model which combines a hierarchical, transformer [55] with multi-task learning [39].

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: low
Confidence Level: medium
Justification: The claim is based on the introduction of a novel HTML model, but there is no experimental evaluation or comparison with other methods to support this claim.
Key Limitations: The effectiveness of the proposed HTML model is not demonstrated.

--------------------------------------------------

Claim 3:
Type: contribution
Statement: The proposed method leverages both textual and vocal features for volatility prediction.
Location: INTRODUCTION
Exact Quote: Following [46], we extract 27 vocal features including pitch, intensity, jitter, and the harmonic to noise ratio using Praat [6]. The audio and text features are combined in the information fusion layer to provide input features for the multi-task learner.

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by the description of the proposed method, which includes the extraction of both textual and vocal features for volatility prediction.
Key Limitations: The effectiveness of combining textual and vocal features is not experimentally evaluated.

--------------------------------------------------

Claim 4:
Type: methodology
Statement: Multi-task learning is employed to simultaneously predict average n-day volatility and single-day volatility.
Location: INTRODUCTION
Exact Quote: Multi-task learning – exploiting similarities and differences between related, simultaneous learning tasks – is used because it has proven to be successful when it comes to controlling for overfitting and improving generalisation [10], and here we simultaneously learn models to predict: (1) average n-day volatility (that is, the volatility of the following n days); and (2) single-day volatility (that is, the volatility on a single day, n-days in the future).

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by the description of the proposed method, which employs multi-task learning for volatility prediction.
Key Limitations: The effectiveness of using multi-task learning is not experimentally evaluated.

--------------------------------------------------

