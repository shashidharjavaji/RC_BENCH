Claim 1:
Type: performance
Statement: REPLUG significantly improves the performance of Codex by 12.0% on NQ and 5.0% on TQA, outperforming previous state-of-the-art model Atlas.
Location: Part3
Exact Quote: REPLUG LSR significantly improves the performance of the original Codex by 12.0% on NQ and 5.0% on TQA. It outperforms the previous best model, Atlas, which was fine-tuned with 64 training examples, achieving a new state-of-the-art in the few-shot setting.

Evidence:
- Evidence Text: REPLUG LSR achieves a 12.0% improvement on NQ and 5.0% improvement on TQA over Codex.
  Strength: strong
  Location: Part3
  Limitations: None.
  Exact Quote: REPLUG LSR significantly improves the performance of the original Codex by 12.0% on NQ and 5.0% on TQA.

- Evidence Text: REPLUG LSR outperforms Atlas, which was fine-tuned with 64 training examples.
  Strength: moderate
  Location: Part3
  Limitations: Atlas is a different model from Codex, so the comparison may not be entirely fair.
  Exact Quote: It outperforms the previous best model, Atlas, which was fine-tuned with 64 training examples, achieving a new state-of-the-art in the few-shot setting.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: high
Justification: The evidence provides concrete numbers to support the claim, but the comparison to Atlas may not be entirely fair.
Key Limitations: The comparison to Atlas may not be entirely fair because Atlas is a different model from Codex.

--------------------------------------------------

Claim 2:
Type: methodology
Statement: REPLUG is applicable to diverse language models.
Location: Part3
Exact Quote: Here we further study whether REPLUG could enhance diverse language model families that have been pre-trained using different data and methods.

Evidence:
- Evidence Text: REPLUG improves the perplexity of GPT-2, BLOOM, and OPT models of varying sizes.
  Strength: strong
  Location: Part3
  Limitations: None.
  Exact Quote: We evaluate each model on Wikitext-103 test data and report its perplexity. For comparison, we augment each model with REPLUG that adopts the ensemble method to incorporate top 10 retrieved documents.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence provides concrete examples of how REPLUG improves the performance of diverse language models.
Key Limitations: None.

--------------------------------------------------

Claim 3:
Type: methodology
Statement: The performance gain brought by REPLUG does not come from the ensembling effect.
Location: Part3
Exact Quote: To study whether the gains come solely from the ensemble method, we compare our method to ensembling random documents.

Evidence:
- Evidence Text: Ensembling random documents leads to worse performance.
  Strength: strong
  Location: Part3
  Limitations: None.
  Exact Quote: We observed that ensembling random documents leads to worse performance, indicating that the performance gains of REPLUG do not come from the ensembling effect.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence provides a clear comparison between REPLUG and ensembling random documents.
Key Limitations: None.

--------------------------------------------------

Claim 4:
Type: methodology
Statement: LSR retriever outperforms other off-the-shelf retrievers.
Location: Part3
Exact Quote: We investigate the effectivenss of tunable retriever (LSR) compared with off-the-shelf retrievers.

Evidence:
- Evidence Text: LSR outperforms BERT-base, DPR, and BM25 on the Wikitext-103 perplexity task.
  Strength: strong
  Location: Part3
  Limitations: None.
  Exact Quote: Among all off-the-shelf retrievers, the sparse retriever BM25 performs best. However, it still lags behind our LM supervised retriever (Contriever LSR), demonstrating the effectiveness of our training scheme that adapts the retriever to LMs.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence provides a clear comparison between LSR and other off-the-shelf retrievers.
Key Limitations: None.

--------------------------------------------------

