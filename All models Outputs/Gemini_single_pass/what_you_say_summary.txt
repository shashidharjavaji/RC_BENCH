Claim 1:
Type: methodology
Statement: A total of 2,243 earnings conference calls are downloaded from Seeking Alpha and EarningsCast.
Location: Data Statistics
Exact Quote: We download a total of 2,243 earnings conference calls from Seeking Alpha and EarningsCast.

Evidence:
- Evidence Text: We download a total of 2,243 earnings conference calls from Seeking Alpha and EarningsCast.
  Strength: strong
  Location: Data Statistics
  Limitations: None mentioned
  Exact Quote: We download a total of 2,243 earnings conference calls from Seeking Alpha and EarningsCast.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence directly supports the claim and provides specific details about the data collection process.
Key Limitations: None identified

--------------------------------------------------

Claim 2:
Type: methodology
Statement: We discard a large proportion of raw data because the audio-text alignment is very noisy and is prone to errors.
Location: Data Statistics
Exact Quote: We discard a large proportion of raw data because the audio-text alignment is very noisy and is prone to errors.

Evidence:
- Evidence Text: We discard a large proportion of raw data because the audio-text alignment is very noisy and is prone to errors.
  Strength: strong
  Location: Data Statistics
  Limitations: The specific proportion of discarded data is not mentioned.
  Exact Quote: We discard a large proportion of raw data because the audio-text alignment is very noisy and is prone to errors.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence directly supports the claim but lacks specific details about the discarded data.
Key Limitations: Lack of specific discarded data proportion.

--------------------------------------------------

Claim 3:
Type: contribution
Statement: We release our processed earnings conference calls dataset for readers who are interested in reproducing the results.
Location: Data Statistics
Exact Quote: We release our processed earnings conference calls dataset for readers who are interested in reproducing the results.

Evidence:
- Evidence Text: We release our processed earnings conference calls dataset for readers who are interested in reproducing the results.
  Strength: strong
  Location: Data Statistics
  Limitations: The specific availability and accessibility of the dataset are not mentioned.
  Exact Quote: We release our processed earnings conference calls dataset for readers who are interested in reproducing the results.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence directly supports the claim but lacks specific details about the dataset availability.
Key Limitations: Lack of specific dataset availability details.

--------------------------------------------------

Claim 4:
Type: methodology
Statement: Prior research uses only shallow machine learning model and bag-of-word features to represent financial documents.
Location: Model
Exact Quote: Prior research (Kogan et al., 2009; Rekabsaz et al., 2017) uses only shallow machine learning model (such as logistic regression) and bag-of-word features to represent financial documents.

Evidence:
- Evidence Text: Prior research (Kogan et al., 2009; Rekabsaz et al., 2017) uses only shallow machine learning model (such as logistic regression) and bag-of-word features to represent financial documents.
  Strength: strong
  Location: Model
  Limitations: Specific limitations of the prior research are not discussed.
  Exact Quote: Prior research (Kogan et al., 2009; Rekabsaz et al., 2017) uses only shallow machine learning model (such as logistic regression) and bag-of-word features to represent financial documents.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence directly supports the claim but lacks a critical analysis of the prior research limitations.
Key Limitations: Lack of critical analysis of prior research limitations.

--------------------------------------------------

Claim 5:
Type: methodology
Statement: We choose to use a recurrent neural network to capture the sentences relation and dependency.
Location: Model
Exact Quote: We choose to use a recurrent neural network to capture the sentences relation and dependency.

Evidence:
- Evidence Text: We choose to use a recurrent neural network to capture the sentences relation and dependency.
  Strength: strong
  Location: Model
  Limitations: The specific recurrent neural network architecture and its advantages are not discussed.
  Exact Quote: We choose to use a recurrent neural network to capture the sentences relation and dependency.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence supports the claim but lacks specific details about the recurrent neural network architecture and its advantages.
Key Limitations: Lack of specific recurrent neural network architecture and its advantages discussion.

--------------------------------------------------

Claim 6:
Type: contribution
Statement: We present a deep model to capture context-dependent unimodal features and fuse multimodal features for the regression task.
Location: Model
Exact Quote: We present a deep model to capture context-dependent unimodal features and fuse multimodal features for the regression task.

Evidence:
- Evidence Text: We present a deep model to capture context-dependent unimodal features and fuse multimodal features for the regression task.
  Strength: strong
  Location: Model
  Limitations: The specific deep model architecture and its advantages are not discussed.
  Exact Quote: We present a deep model to capture context-dependent unimodal features and fuse multimodal features for the regression task.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence supports the claim but lacks specific details about the deep model architecture and its advantages.
Key Limitations: Lack of specific deep model architecture and its advantages discussion.

--------------------------------------------------

