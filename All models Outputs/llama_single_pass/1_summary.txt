Claim 1:
Type: contribution
Statement: Statistical learners such as neural networks closely track the statistical regularities in their training sets, making them vulnerable to adopting heuristics that are valid for frequent cases but fail on less frequent ones.
Location: Section 1: Introduction
Exact Quote: Statistical learners such as neural networks closely track the statistical regularities in their training sets. This process makes them vulnerable to adopting heuristics that are valid for frequent cases but fail on less frequent ones.

Evidence:
- Evidence Text: The authors provide examples from the MNLI training set that contradict the lexical overlap, subsequence, and constituent heuristics (Appendix A).
  Strength: moderate
  Location: Appendix A
  Limitations: Limited to specific examples from MNLI
  Exact Quote: The sentences in (7) show examples from the MNLI training set that contradict the lexical overlap, subsequence, and constituent heuristics.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence supports the claim by providing concrete examples from MNLI that contradict the heuristics, but the scope of these examples is limited.
Key Limitations: Limited scope of examples

--------------------------------------------------

Claim 2:
Type: methodology
Statement: The HANS dataset is designed to diagnose the use of fallible structural heuristics in NLI models.
Location: Section 1: Introduction
Exact Quote: We introduce a new evaluation set called HANS (Heuristic Analysis for NLI Systems), designed to diagnose the use of such fallible structural heuristics.

Evidence:
- Evidence Text: The authors describe the HANS dataset and its construction process (Section 3: Dataset Construction).
  Strength: strong
  Location: Section 3: Dataset Construction
  Limitations: None mentioned
  Exact Quote: For each heuristic, we generated five templates for examples that support the heuristic and five templates for examples that contradict it.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence strongly supports the claim by providing a detailed description of the HANS dataset and its construction process.
Key Limitations: None

--------------------------------------------------

Claim 3:
Type: result
Statement: The four NLI models (DA, ESIM, SPINN, and BERT) perform very poorly on HANS, suggesting that their high accuracies on NLI test sets may be due to the exploitation of invalid heuristics rather than deeper understanding of language.
Location: Section 5: Results
Exact Quote: All models achieved high scores on the MNLI test set, replicating the accuracies found in past work. On the HANS dataset, all models almost always assigned the correct label in the cases where the label is entailment, but performed poorly on the cases where the heuristics make incorrect predictions.

Evidence:
- Evidence Text: The authors present the results of the four NLI models on HANS (Table 1b).
  Strength: strong
  Location: Section 5: Results, Table 1b
  Limitations: Limited to the four evaluated models
  Exact Quote: All models behaved as we would expect them to if they had adopted the heuristics targeted by HANS.

- Evidence Text: The authors compare the performance of the models on HANS to their performance on MNLI (Figure 1).
  Strength: strong
  Location: Section 5: Results, Figure 1
  Limitations: Limited to the comparison with MNLI
  Exact Quote: All models achieved high scores on the MNLI test set, replicating the accuracies found in past work.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence strongly supports the claim by providing comprehensive results of the four NLI models on HANS and comparing their performance to MNLI.
Key Limitations: Limited to the four evaluated models

--------------------------------------------------

Claim 4:
Type: contribution
Statement: Augmenting the training data with HANS-like examples improves the performance of the models on HANS.
Location: Section 7: Augmenting the training data with HANS-like examples
Exact Quote: To test that hypothesis, we retrained each model on the MNLI training set augmented with a dataset structured exactly like HANS.

Evidence:
- Evidence Text: The authors present the results of the models trained on the augmented MNLI dataset (Figure 2).
  Strength: strong
  Location: Section 7: Augmenting the training data with HANS-like examples, Figure 2
  Limitations: Limited to the specific augmentation experiment
  Exact Quote: The models trained on the augmented MNLI performed very well on HANS.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence strongly supports the claim by providing comprehensive results of the models trained on the augmented MNLI dataset.
Key Limitations: Limited to the specific augmentation experiment

--------------------------------------------------

