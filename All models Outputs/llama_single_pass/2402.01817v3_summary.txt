Claim 1:
Type: contribution
Statement: LLMs cannot plan themselves but can play a variety of constructive roles in solving planning tasks–especially as approximate knowledge sources and candidate plan generators in the so-called LLM-Modulo Frameworks, where they are used in conjunction with external sound model-based verifiers.
Location: Section 1. Introduction
Exact Quote: We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification... We also argue that LLMs should be viewed as universal approximate knowledge sources that have much more meaningful roles to play in planning/reasoning tasks beyond simple front-end/back-end format translators.

Evidence:
- Evidence Text: Several recent studies confirm that LLMs are not actually able to generate executable plans when they are used in autonomous modes (Valmeekam et al., 2023c; Liu et al., 2023; Silver et al., 2022).
  Strength: strong
  Location: Section 2.1. LLMs cannot generate executable plans in autonomous mode
  Limitations: Limited to autonomous mode, specific studies
  Exact Quote: Despite initial claims about the planning capabilities of LLMs... several recent studies confirm that LLMs are not actually able to generate executable plans when they are used in autonomous modes

- Evidence Text: Results in the autonomous mode are pretty bleak. On average, only about 12% of the plans that the best LLM (GPT-4) generates are actually executable without errors and goal-reaching.
  Strength: strong
  Location: Section 2.1. LLMs cannot generate executable plans in autonomous mode
  Limitations: Specific to the study's dataset and LLM model
  Exact Quote: On average, only about 12% of the plans that the best LLM (GPT-4) generates are actually executable without errors and goal-reaching.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence strongly supports the claim that LLMs are incapable of planning in autonomous mode, highlighting their limitations in generating executable plans.
Key Limitations: Autonomous mode, specific LLM models and datasets

--------------------------------------------------

Claim 2:
Type: contribution
Statement: LLMs can help come up with approximate quasi-symbolic transition models, reward models, and models of high-level actions, which has made a bigger splash in RL.
Location: Section 5. Related Work
Exact Quote: Interestingly, the fact that LLM’s can help come up with approximate quasi-symbolic transition models, reward models, and models of high level actions has made a bigger splash in RL.

Evidence:
- Evidence Text: Given the horrendous sample complexity of the DRL methods even in reaching a single subgoal, and the well-known fact that even approximate symbolic models can help drastically improve the performance (c.f. (Guan et al., 2022)).
  Strength: moderate
  Location: Section 5. Related Work
  Limitations: Specific to RL and DRL methods
  Exact Quote: Given the horrendous sample complexity of the DRL methods even in reaching a single subgoal, and the well-known fact that even approximate symbolic models can help drastically improve the performance

- Evidence Text: There has been a performance revolution of sorts in RL, with works like Yao et al., 2023b; Liang et al., 2023; Wang et al., 2023b, leveraging LLMs for improved performance.
  Strength: strong
  Location: Section 5. Related Work
  Limitations: Specific to the mentioned studies and RL context
  Exact Quote: If we look beyond the improvements in these lower level goal seeking behaviors–especially in the presence of ergodic simulators, the RL approaches dependent on LLMs will encounter the same issues regarding subgoal interactions

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence supports the claim, showing the positive impact of LLMs in RL, but with noted limitations and context specificity.
Key Limitations: RL and DRL methods, specific studies

--------------------------------------------------

Claim 3:
Type: performance
Statement: The LLM-Modulo framework can significantly improve planning performance, as shown in the travel planning case study, where it achieved a 6x improvement over baselines with weaker models.
Location: Section 4. Two Case Studies of LLM-Modulo
Exact Quote: Our preliminary results show... that LLM-Modulo based agentification with automated critics in the loop significantly improves the performance (6x of baselines) even with a limit of 10 back prompting cycles, and weaker models such as GPT-3.5-Turbo.

Evidence:
- Evidence Text: The LLM-Modulo framework was adapted to the travel planning benchmark, which involves a rich mix of travel constraints presented in flexible natural language form.
  Strength: strong
  Location: Section 4. Two Case Studies of LLM-Modulo
  Limitations: Specific to the travel planning domain and benchmark
  Exact Quote: We used a benchmark proposed in (Xie et al., 2024), which involves a rich mix of travel constraints presented in flexible natural language form.

- Evidence Text: The framework achieved a 6x improvement over baselines with weaker models, and LLMs successfully implemented functions corresponding to hard critics and several common-sense critics.
  Strength: strong
  Location: Section 4. Two Case Studies of LLM-Modulo
  Limitations: Specific to the study's setup and models used
  Exact Quote: Our preliminary results show... that LLM-Modulo based agentification with automated critics in the loop significantly improves the performance (6x of baselines) even with a limit of 10 back prompting cycles, and weaker models such as GPT-3.5-Turbo.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence strongly supports the claim, demonstrating the effectiveness of the LLM-Modulo framework in improving planning performance in a specific domain.
Key Limitations: Travel planning domain, specific benchmark and models

--------------------------------------------------

