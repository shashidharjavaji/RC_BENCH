{
    "paper_analysis": [],
    "raw_claims": " For example:\n```json\n{\n    \"claims\": [\n        {\n            \"claim_id\": 1,\n            \"claim_text\": \"LLMs struggle with ambiguity in human communication, leading to misinterpretations, miscommunications, and biased responses.\",\n            \"location\": \"Introduction\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"LLMs often struggle with the inherent uncertainties of human communication, leading to misinterpretations, miscommunications, and biased responses which weaken their trust and ability to be used for real-world tasks.\"\n        },\n        {\n            \"claim_id\": 2,\n            \"claim_text\": \"Simple, training-free, token-level disambiguation methods may be effectively used to improve LLM performance for ambiguous question answering tasks.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We demonstrate how simple, training-free, token-level disambiguation methods may be effectively used to improve LLM performance for ambiguous question answering tasks.\"\n        },\n        {\n            \"claim_id\": 3,\n            \"claim_text\": \"Using open-domain question answering as a test case, we compare off-the-shelf and few-shot LLM performance, focusing on measuring the impact of explicit disambiguation strategies.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Using open-domain question answering as a test case, we compare off-the-shelf and few-shot LLM performance, focusing on measuring the impact of explicit disambiguation strategies.\"\n        },\n        {\n            \"claim_id\": 4,\n            \"claim_text\": \"Simple prompt-based, training-free approaches may be useful in improving LLM performance for ambiguous queries.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Interestingly, we see that for both GPT 4o and 4o-mini, using simple disambiguating prompts improves performance over the naive setting, implying that simple prompt-based, training-free approaches may be useful in improving LLM performance for ambiguous queries.\"\n        },\n        {\n            \"claim_id\": 5,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 6,\n            \"claim_text\": \"Simple training-free prompting methods for disambiguation work well in improving performance.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Interestingly, we see that for both GPT 4o and 4o-mini, using simple disambiguating prompts improves performance over the naive setting, implying that simple prompt-based, training-free approaches may be useful in improving LLM performance for ambiguous queries.\"\n        },\n        {\n            \"claim_id\": 7,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 8,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 9,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 10,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 11,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 12,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 13,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 14,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 15,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 16,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 17,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 18,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 19,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 20,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 21,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 22,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 23,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 24,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 25,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 26,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 27,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 28,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 29,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 30,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 31,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 32,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 33,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 34,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 35,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 36,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 37,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 38,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 39,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 40,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 41,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 42,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 43,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 44,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 45,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 46,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 47,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 48,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 49,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 50,\n            \"claim_text\": \"Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Our results indicate that contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions, making them impossible to fix by prompting.\"\n        },\n        {\n            \"claim_id\": 51,\n            \"claim_text\": \"Simple prompt-based disambiguation techniques may help significantly in improving the performance of the LLM.\",\n            \"location\": \"Conclusion and Future Works\",\n            \"claim_type\": \"Conclusion\",\n            \"exact_quote\": \"Our analysis shows that even though LLMs struggle with ambiguity in prompts, simple training-free prompt-based disambiguation methods may help significantly in improving the performance of the LLM.\"\n        },\n        {\n            \"claim_id\": 52,\n            \"claim_text\": \"Fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"To evaluate whether small scale fine-tuning helps in improving LLM performance on ambiguous questions, we perform few-shot fine-tuning on GPT 4o-mini. To adapt our model for handling ambiguous questions, we fine-tuned the model using OpenAI\u2019s API. We randomly sampled 50 question-answer pairs from AmbigQA. Each ambiguous question was stored as the prompt for the LLM, with ground truth being stored as the expected response from the LLM. The file was formatted as shown below for the 50 questions. Using this, we initiated a fine-tuning job on OpenAI\u2019s fine-tuning API which returned a model checkpoint. We used this fine-tuned model ID instead of gpt-4o-mini within our baseline prompt configuration. \u201cmessages\u201d:\\n\u201crole\u201d: \u201cuser\u201d, \u201ccontent\u201d: <ambiguous question>, \\n\u201crole\u201d: \u201cassistant\u201d, \u201ccontent\u201d: <ground truth answer>\u201d\\nThe GT Answer Overlap for the 4o-mini model is 0.643 while that for the fine-tuned 4o-mini model is 0.626. Therefore, we see that fine-tuning, at least at this small scale, does not provide any improvement in LLM performance on ambiguous questions.\"\n        },\n        {\n            \"claim_id\": 53,\n            \"claim_text\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\",\n            \"location\": \"Results and Discussion\",\n            \"claim_type\": \"Observation\",\n            \"exact_quote\": \"Using a lower temperature value for LLM generation results in reducing the \u2018stochasticity\u2019 of the generated text, where the variance is reduced and the generated text is more predictable over multiple runs.\"\n        },\n        {\n            \"claim_id\": 54",
    "raw_evidence": "",
    "raw_conclusions": "",
    "execution_times": {
        "claims_analysis_time": "305.20 seconds",
        "evidence_analysis_time": "1.03 seconds",
        "conclusions_analysis_time": "1.03 seconds",
        "total_execution_time": "309.01 seconds"
    }
}