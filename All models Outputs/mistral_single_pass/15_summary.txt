Claim 1:
Type: result
Statement: Pre-trained language models can reason without prompting.
Location: Introduction
Exact Quote: We investigate whether pre-trained language models inherently possess reasoning capabilities, without explicit prompts or human intervention.

Evidence:
- Evidence Text: Table 1 shows examples of greedy decoded paths and alternative top-ùëò paths over the PaLM-2 Large model.
  Strength: strong
  Location: Section 2.1
  Limitations: None
  Exact Quote: Table 1 | Examples of greedy decoded paths and alternative top-ùëò paths over the PaLM-2 Large model.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence shows that pre-trained language models can generate CoT paths without explicit prompting.
Key Limitations: None

--------------------------------------------------

Claim 2:
Type: methodology
Statement: CoT-decoding can reliably extract CoT paths.
Location: Section 2.2
Exact Quote: CoT-decoding extracts such CoT paths among the decoded paths from the model.

Evidence:
- Evidence Text: Table 1 illustrates that CoT paths do not consistently outrank non-CoT ones in the model‚Äôs probability assessment.
  Strength: strong
  Location: Section 2.2
  Limitations: None
  Exact Quote: Table 1 | Examples of greedy decoded paths and alternative top-ùëò paths over the PaLM-2 Large model.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence shows that CoT paths can be reliably extracted using CoT-decoding.
Key Limitations: None

--------------------------------------------------

Claim 3:
Type: performance
Statement: CoT-decoding improves model reasoning performance.
Location: Section 3.1
Exact Quote: CoT-decoding is the only decoding strategy that effectively enables language models to reason.

Evidence:
- Evidence Text: Table 4 shows that CoT-decoding is the only decoding strategy that effectively improves language model reasoning.
  Strength: strong
  Location: Section 3.1
  Limitations: None
  Exact Quote: Table 4 | CoT-decoding is the only decoding strategy that can significantly enhance language models‚Äô reasoning.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence shows that CoT-decoding significantly improves model reasoning performance.
Key Limitations: None

--------------------------------------------------

Claim 4:
Type: contribution
Statement: CoT-decoding can be combined with CoT-prompting to further boost reasoning performance.
Location: Section 3.3
Exact Quote: CoT-decoding can be easily combined with CoT-prompting, yielding even larger reasoning gains over multiple language models.

Evidence:
- Evidence Text: Table 7 shows that adding CoT-decoding on top of zero-shot CoT-prompting can further boost the reasoning performance.
  Strength: strong
  Location: Section 3.3
  Limitations: None
  Exact Quote: Table 7 | Adding CoT-decoding on top of zero-shot CoT-prompting can further boost the reasoning performance on both models.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence shows that combining CoT-decoding with CoT-prompting can further improve reasoning performance.
Key Limitations: None

--------------------------------------------------

