Claim 1:
Type: methodology/result
Statement: The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets.
Location: Abstract
Exact Quote: The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets.

Evidence:
- Evidence Text: The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the existing literature.
Key Limitations: None

--------------------------------------------------

Claim 2:
Type: methodology/result
Statement: The proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols.
Location: Abstract
Exact Quote: The proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols.

Evidence:
- Evidence Text: The proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: The proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the existing literature.
Key Limitations: None

--------------------------------------------------

Claim 3:
Type: methodology/result
Statement: The field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems.
Location: Abstract
Exact Quote: The field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems.

Evidence:
- Evidence Text: The field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: The field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the existing literature.
Key Limitations: None

--------------------------------------------------

Claim 4:
Type: contribution
Statement: We perform an overview of the main families of DL architectures for tabular data and raise the bar of baselines in tabular DL by identifying two simple and powerful deep architectures.
Location: Abstract
Exact Quote: We perform an overview of the main families of DL architectures for tabular data and raise the bar of baselines in tabular DL by identifying two simple and powerful deep architectures.

Evidence:
- Evidence Text: We perform an overview of the main families of DL architectures for tabular data and raise the bar of baselines in tabular DL by identifying two simple and powerful deep architectures.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: We perform an overview of the main families of DL architectures for tabular data and raise the bar of baselines in tabular DL by identifying two simple and powerful deep architectures.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the contributions of the paper.
Key Limitations: None

--------------------------------------------------

Claim 5:
Type: contribution
Statement: The first one is a ResNet-like architecture which turns out to be a strong baseline that is often missing in prior works.
Location: Abstract
Exact Quote: The first one is a ResNet-like architecture which turns out to be a strong baseline that is often missing in prior works.

Evidence:
- Evidence Text: The first one is a ResNet-like architecture which turns out to be a strong baseline that is often missing in prior works.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: The first one is a ResNet-like architecture which turns out to be a strong baseline that is often missing in prior works.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the contributions of the paper.
Key Limitations: None

--------------------------------------------------

Claim 6:
Type: contribution
Statement: The second model is our simple adaptation of the Transformer architecture for tabular data, which outperforms other solutions on most tasks.
Location: Abstract
Exact Quote: The second model is our simple adaptation of the Transformer architecture for tabular data, which outperforms other solutions on most tasks.

Evidence:
- Evidence Text: The second model is our simple adaptation of the Transformer architecture for tabular data, which outperforms other solutions on most tasks.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: The second model is our simple adaptation of the Transformer architecture for tabular data, which outperforms other solutions on most tasks.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the contributions of the paper.
Key Limitations: None

--------------------------------------------------

Claim 7:
Type: methodology/result
Statement: Both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols.
Location: Abstract
Exact Quote: Both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols.

Evidence:
- Evidence Text: Both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: Both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the methodology of the paper.
Key Limitations: None

--------------------------------------------------

Claim 8:
Type: contribution
Statement: We also compare the best DL models with Gradient Boosted Decision Trees and conclude that there is still no universally superior solution.
Location: Abstract
Exact Quote: We also compare the best DL models with Gradient Boosted Decision Trees and conclude that there is still no universally superior solution.

Evidence:
- Evidence Text: We also compare the best DL models with Gradient Boosted Decision Trees and conclude that there is still no universally superior solution.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: We also compare the best DL models with Gradient Boosted Decision Trees and conclude that there is still no universally superior solution.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the contributions of the paper.
Key Limitations: None

--------------------------------------------------

Claim 9:
Type: contribution
Statement: We summarize the contributions of our paper as follows:
Location: Abstract
Exact Quote: We summarize the contributions of our paper as follows:

Evidence:
- Evidence Text: We summarize the contributions of our paper as follows:
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: We summarize the contributions of our paper as follows:

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the contributions of the paper.
Key Limitations: None

--------------------------------------------------

Claim 10:
Type: methodology/result
Statement: We thoroughly evaluate the main models for tabular DL on a diverse set of tasks to investigate their relative performance.
Location: Abstract
Exact Quote: We thoroughly evaluate the main models for tabular DL on a diverse set of tasks to investigate their relative performance.

Evidence:
- Evidence Text: We thoroughly evaluate the main models for tabular DL on a diverse set of tasks to investigate their relative performance.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: We thoroughly evaluate the main models for tabular DL on a diverse set of tasks to investigate their relative performance.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the methodology of the paper.
Key Limitations: None

--------------------------------------------------

Claim 11:
Type: contribution
Statement: We demonstrate that a simple ResNet-like architecture is an effective baseline for tabular DL, which was overlooked by existing literature.
Location: Abstract
Exact Quote: We demonstrate that a simple ResNet-like architecture is an effective baseline for tabular DL, which was overlooked by existing literature.

Evidence:
- Evidence Text: We demonstrate that a simple ResNet-like architecture is an effective baseline for tabular DL, which was overlooked by existing literature.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: We demonstrate that a simple ResNet-like architecture is an effective baseline for tabular DL, which was overlooked by existing literature.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the contributions of the paper.
Key Limitations: None

--------------------------------------------------

Claim 12:
Type: contribution
Statement: We introduce FT-Transformer — a simple adaptation of the Transformer architecture for tabular data that becomes a new powerful solution for the field.
Location: Abstract
Exact Quote: We introduce FT-Transformer — a simple adaptation of the Transformer architecture for tabular data that becomes a new powerful solution for the field.

Evidence:
- Evidence Text: We introduce FT-Transformer — a simple adaptation of the Transformer architecture for tabular data that becomes a new powerful solution for the field.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: We introduce FT-Transformer — a simple adaptation of the Transformer architecture for tabular data that becomes a new powerful solution for the field.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the contributions of the paper.
Key Limitations: None

--------------------------------------------------

Claim 13:
Type: contribution
Statement: We reveal that there is still no universally superior solution among GBDT and deep models.
Location: Abstract
Exact Quote: We reveal that there is still no universally superior solution among GBDT and deep models.

Evidence:
- Evidence Text: We reveal that there is still no universally superior solution among GBDT and deep models.
  Strength: strong
  Location: Abstract
  Limitations: None
  Exact Quote: We reveal that there is still no universally superior solution among GBDT and deep models.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the abstract statement which summarizes the contributions of the paper.
Key Limitations: None

--------------------------------------------------

