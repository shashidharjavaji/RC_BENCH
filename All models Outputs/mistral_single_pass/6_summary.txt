Claim 1:
Type: performance
Statement: kNN-LM improves perplexity on WIKITEXT-103 from 18.65 to a new state-of-the-art of 16.12.
Location: Section 4.1
Exact Quote: Table 1 shows that kNN-LM improves perplexity on WIKITEXT-103 from 18.65 (Baevski & Auli, 2019) to a new state-of-the-art of 16.12.

Evidence:
- Evidence Text: Table 1 shows that kNN-LM improves perplexity on WIKITEXT-103 from 18.65 (Baevski & Auli, 2019) to a new state-of-the-art of 16.12.
  Strength: strong
  Location: Section 4.1
  Limitations: None
  Exact Quote: Table 1 shows that kNN-LM improves perplexity on WIKITEXT-103 from 18.65 (Baevski & Auli, 2019) to a new state-of-the-art of 16.12.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by a direct comparison of perplexity values before and after applying kNN-LM.
Key Limitations: None

--------------------------------------------------

Claim 2:
Type: contribution
Statement: kNN-LM allows a single model to be useful in multiple domains by simply adding a datastore per domain.
Location: Section 4.3
Exact Quote: Table 4 shows that an in-domain LM on BOOKS has a relatively low perplexity (11.89), while a model trained on WIKI-3B performs poorly on the BOOKS domain (34.84 perplexity). Adding kNN search over BOOKS to the WIKI-3B model reduces perplexity by 14 points (to 20.47), demonstrating that kNN-LM allows a single model to be useful in multiple domains, by simply adding a datastore per domain.

Evidence:
- Evidence Text: Table 4 shows that an in-domain LM on BOOKS has a relatively low perplexity (11.89), while a model trained on WIKI-3B performs poorly on the BOOKS domain (34.84 perplexity). Adding kNN search over BOOKS to the WIKI-3B model reduces perplexity by 14 points (to 20.47), demonstrating that kNN-LM allows a single model to be useful in multiple domains, by simply adding a datastore per domain.
  Strength: strong
  Location: Section 4.3
  Limitations: None
  Exact Quote: Table 4 shows that an in-domain LM on BOOKS has a relatively low perplexity (11.89), while a model trained on WIKI-3B performs poorly on the BOOKS domain (34.84 perplexity). Adding kNN search over BOOKS to the WIKI-3B model reduces perplexity by 14 points (to 20.47), demonstrating that kNN-LM allows a single model to be useful in multiple domains, by simply adding a datastore per domain.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by a direct comparison of perplexity values before and after adding a datastore for domain adaptation.
Key Limitations: None

--------------------------------------------------

Claim 3:
Type: methodology
Statement: kNN-LM improves performance by retrieving neighbors from the training data.
Location: Section 4.1
Exact Quote: Table 1 shows that kNN-LM improves perplexity on WIKITEXT-103 from 18.65 (Baevski & Auli, 2019) to a new state-of-the-art of 16.12.

Evidence:
- Evidence Text: Table 1 shows that kNN-LM improves perplexity on WIKITEXT-103 from 18.65 (Baevski & Auli, 2019) to a new state-of-the-art of 16.12.
  Strength: strong
  Location: Section 4.1
  Limitations: None
  Exact Quote: Table 1 shows that kNN-LM improves perplexity on WIKITEXT-103 from 18.65 (Baevski & Auli, 2019) to a new state-of-the-art of 16.12.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by a direct comparison of perplexity values before and after applying kNN-LM.
Key Limitations: None

--------------------------------------------------

Claim 4:
Type: contribution
Statement: kNN-LM allows for efficient scaling up to larger training sets.
Location: Section 4.2
Exact Quote: Table 3 shows that, as expected, the model trained on 3B tokens dramatically outperforms the model trained on 100M tokens, improving perplexity from 19.59 to 15.17. However, adding nearest neighbors retrieval over those 3B examples to the model trained on 100M tokens improves perplexity from 19.59 to 13.73; i.e. retrieving nearest neighbors from the corpus outperforms training on it.

Evidence:
- Evidence Text: Table 3 shows that, as expected, the model trained on 3B tokens dramatically outperforms the model trained on 100M tokens, improving perplexity from 19.59 to 15.17. However, adding nearest neighbors retrieval over those 3B examples to the model trained on 100M tokens improves perplexity from 19.59 to 13.73; i.e. retrieving nearest neighbors from the corpus outperforms training on it.
  Strength: strong
  Location: Section 4.2
  Limitations: None
  Exact Quote: Table 3 shows that, as expected, the model trained on 3B tokens dramatically outperforms the model trained on 100M tokens, improving perplexity from 19.59 to 15.17. However, adding nearest neighbors retrieval over those 3B examples to the model trained on 100M tokens improves perplexity from 19.59 to 13.73; i.e. retrieving nearest neighbors from the corpus outperforms training on it.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by a direct comparison of perplexity values before and after applying kNN-LM.
Key Limitations: None

--------------------------------------------------

Claim 5:
Type: methodology
Statement: kNN-LM improves performance by retrieving neighbors from the training data.
Location: Section 4.1
Exact Quote: Table 1 shows that kNN-LM improves perplexity on WIKITEXT-103 from 18.65 (Baevski & Auli, 2019) to a new state-of-the-art of 16.12.

Evidence:
- Evidence Text: Table 1 shows that kNN-LM improves perplexity on WIKITEXT-103 from 18.65 (Baevski & Auli, 2019) to a new state-of-the-art of 16.12.
  Strength: strong
  Location: Section 4.1
  Limitations: None
  Exact Quote: Table 1 shows that kNN-LM improves perplexity on WIKITEXT-103 from 18.65 (Baevski & Auli, 2019) to a new state-of-the-art of 16.12.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by a direct comparison of perplexity values before and after applying kNN-LM.
Key Limitations: None

--------------------------------------------------

