Claim 1:
Type: contribution
Statement: There is a significant gap between textual and visual representations in MLLMs, and representations of texts with and without hallucinations are entangled
Location: Introduction
Exact Quote: A significant modality gap remains between the textual and visual tokens despite visual projection; Representations of texts that contain and do not contain hallucinations are entangled

Evidence:
- Evidence Text: Visualization showing distribution gap in Figure 1(a)
  Strength: strong
  Location: Introduction/Figure 1
  Limitations: Limited to specific model (LLaVA) and visualization method not fully detailed
  Exact Quote: As shown in Figure 1, textual and visual representations have cross-model semantic gaps, while non-hallucinating and hallucinative text representations are mixed

- Evidence Text: PCA visualization of representation distributions
  Strength: moderate
  Location: Section 4.5
  Limitations: Based on subset of 200 image-text pairs
  Exact Quote: As illustrated in Figure 4 (a), a substantial modality gap is observable in the data distribution without contrast learning

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: Multiple visualizations across different analyses support the claim, though limited to specific models
Key Limitations: Analysis primarily based on one model (LLaVA) and relatively small sample size for visualization

--------------------------------------------------

Claim 2:
Type: performance
Statement: HACL improves model performance on hallucination benchmarks while maintaining or improving general capabilities
Location: Section 4.2
Exact Quote: Table 1 demonstrates a significant improvement in the overall performance of MMHal-Bench after applying our method to LLaVA [32], MiniGPT-4[55], and LLaVA1.5[31]

Evidence:
- Evidence Text: Improvement on MMhal-Bench benchmark
  Strength: strong
  Location: Section 4.2
  Limitations: Limited to specific benchmark types
  Exact Quote: MiniGPT-4-HACL exhibited considerable performance gain over MiniGPT-4 [55]

- Evidence Text: POPE benchmark improvements
  Strength: strong
  Location: Section 4.2
  Limitations: None specified
  Exact Quote: the average F1 score of LLaVA-HACL increased by 17.8% compared to LLaVA [32]

- Evidence Text: General capability improvements
  Strength: moderate
  Location: Section 4.3
  Limitations: Varies across different benchmarks
  Exact Quote: all three models exhibited improvements across multiple benchmarks

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: Consistent improvements shown across multiple models and benchmarks with quantitative results
Key Limitations: Some improvements are modest in scale

--------------------------------------------------

Claim 3:
Type: methodology
Statement: Training LLMs during Stage 1 pretraining with HACL leads to performance degradation
Location: Section 4.4
Exact Quote: the models experienced a significant performance decline when LLMs are activated

Evidence:
- Evidence Text: Ablation study results
  Strength: moderate
  Location: Section 4.4
  Limitations: Limited explanation of causal factors
  Exact Quote: We hypothesize that this downturn could be linked to low-quality data in the first pretraining stage and the introduction of additional contrast learning tasks

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: Empirical evidence supports the claim but underlying mechanisms not fully explored
Key Limitations: Hypothesis about causes not fully validated

--------------------------------------------------

