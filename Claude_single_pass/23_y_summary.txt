Claim 1:
Type: contribution
Statement: MME is the first comprehensive evaluation benchmark for MLLMs that covers both perception and cognition abilities
Location: Introduction and Section 2
Exact Quote: In this paper, we fill in this blank, presenting the first comprehensive MLLM Evaluation benchmark MME. It measures both perception and cognition abilities on a total of 14 subtasks.

Evidence:
- Evidence Text: MME includes 10 perception subtasks (existence, count, position, color, movie posters, celebrities, scenes, landmarks, artworks, OCR) and 4 cognition subtasks (commonsense reasoning, numerical calculation, text translation, code reasoning)
  Strength: strong
  Location: Section 2.3
  Limitations: Completeness of coverage cannot be definitively proven
  Exact Quote: There are a total of 10 subtasks for the evaluation of the perception ability...There are four subtasks for the evaluation of the cognition ability

- Evidence Text: Evaluation of 30 state-of-the-art MLLMs on all subtasks
  Strength: strong
  Location: Section 3
  Limitations: Models evaluated may not represent all important MLLMs
  Exact Quote: In this section, a total of 30 MLLMs are evaluated on our MME benchmark

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The benchmark demonstrably covers multiple perception and cognition capabilities with detailed evaluation methodology
Key Limitations: Cannot definitively prove it is the 'first' comprehensive benchmark

--------------------------------------------------

Claim 2:
Type: result
Statement: MLLMs still have significant room for improvement in cognition tasks
Location: Section 3.1.2
Exact Quote: Regardless of whether it is commonsense reasoning, numerical calculation, or text translation, none of the highest scores exceed 150. This suggests that MLLMs have a lot of room for improvement in these capabilities.

Evidence:
- Evidence Text: Best scores for cognition tasks: commonsense reasoning (142.14), numerical calculation (<150), text translation (<150)
  Strength: strong
  Location: Section 3.1.2
  Limitations: Scoring method's calibration could affect interpretation
  Exact Quote: GPT-4V gets a score of 142.14

- Evidence Text: Common problems identified in cognitive reasoning
  Strength: moderate
  Location: Section 4
  Limitations: Qualitative assessment based on example cases
  Exact Quote: We conclude four common problems that largely affect the performance of MLLMs

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: high
Justification: Consistent poor performance across multiple models and tasks supports the conclusion
Key Limitations: Benchmark difficulty calibration could affect interpretation of room for improvement

--------------------------------------------------

Claim 3:
Type: methodology
Statement: The instruction design of yes/no questions enables accurate and objective quantitative evaluation
Location: Section 2.1-2.2
Exact Quote: Benefitting from our instruction design 'please answer yes or no', we can easily perform quantitative statistics based on the 'yes' or 'no' output of MLLMs, which is accurate and objective.

Evidence:
- Evidence Text: Clear metrics defined: accuracy per question and accuracy+ per image pair
  Strength: strong
  Location: Section 2.2
  Limitations: Binary answers may oversimplify some capabilities
  Exact Quote: The former is calculated based on each question, while the latter is based on each image where both of the two questions need to be answered correctly.

- Evidence Text: Comparison with alternative approaches
  Strength: moderate
  Location: Section 2.1
  Limitations: Limited exploration of other potential approaches
  Exact Quote: It should be noted that we have also tried to design instructions with multiple choice questions, but find that it may beyond the capabilities of current MLLMs to follow complex instructions.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The methodology enables clear quantitative comparison while avoiding ambiguity
Key Limitations: Binary yes/no format may not capture nuanced capabilities

--------------------------------------------------

