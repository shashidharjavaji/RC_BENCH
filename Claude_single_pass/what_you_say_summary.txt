Claim 1:
Type: performance
Statement: The multimodal deep regression model (MDRM) outperforms all baseline methods for stock volatility prediction
Location: Results and Discussion Section
Exact Quote: The results show that our multimodal deep regression model (MDRM) outperforms all baselines.

Evidence:
- Evidence Text: MDRM achieves 54.1% improvement over past volatility baseline for 3-day prediction
  Strength: strong
  Location: Results Section
  Limitations: Only tested on S&P 500 companies in 2017
  Exact Quote: Comparing with using past volatility only, the improvement gain is as substantial as 54.1% for 3-days prediction

- Evidence Text: Quantitative performance improvements over other baselines
  Strength: strong
  Location: Results Section
  Limitations: Short-term predictions only
  Exact Quote: The improvement over other baseline methods are 19.1% (tf-idf bag-of-words), 17.8% (word embeddings), 20.4%(simple fusion) respectively for 3-days prediction

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: high
Justification: Multiple quantitative comparisons show consistent improvements across different baselines and prediction horizons
Key Limitations: Limited to one year of S&P 500 data, performance advantages decrease for longer-term predictions

--------------------------------------------------

Claim 2:
Type: result
Statement: Multimodal features (text + audio) are more helpful than unimodal features alone for stock volatility prediction
Location: Results and Discussion Section
Exact Quote: We can also conclude from the results that multimodal features are more helpful than unimodal features (either text or audio) alone

Evidence:
- Evidence Text: Multimodal outperforms unimodal by 4.2% for 3-day predictions
  Strength: moderate
  Location: Results Section
  Limitations: Relatively small improvement margin
  Exact Quote: When we predict the stock volatility 3-days following the conference call, multimodal (1.371) outperform unimodal (1.431) by 4.2%

- Evidence Text: Multimodal approach helps prevent overfitting compared to audio-only
  Strength: moderate
  Location: Results Section
  Limitations: Qualitative observation
  Exact Quote: We find that training a deep LSTM network with audio data only can result in overfitting very quickly

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: Consistent improvements shown across multiple metrics, though margins are modest
Key Limitations: Improvements are relatively small and diminish for longer-term predictions

--------------------------------------------------

Claim 3:
Type: result
Statement: Individual vocal features, especially pitch and intensity, are important predictors of stock volatility
Location: Results Section
Exact Quote: Our experiment results show that without mean pitch feature, the MSE of our model increases 0.7%

Evidence:
- Evidence Text: Impact of removing individual vocal features
  Strength: moderate
  Location: Results Section
  Limitations: Small effect sizes
  Exact Quote: The left-out of standard deviation of pitch also raises MSE by 0.65%. For mean intensity and number of pulses, MSE increases by 0.63% and 0.56% respectively

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: Ablation study shows consistent but small effects of vocal features
Key Limitations: Small effect sizes, limited to specific vocal features tested

--------------------------------------------------

