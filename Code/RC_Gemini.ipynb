{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting claims...\n",
      "Processing ICLR_1.pdf...\n",
      "[                                        ] (0/1===[====                                    ] ( 1/10===[========                                ] ( 2/10===[============                            ] ( 3/10===[================                        ] ( 4/10===[====================                    ] ( 5/10===[========================                ] ( 6/10===[============================            ] ( 7/10===[================================        ] ( 8/10===[====================================    ] ( 9/10===[========================================] (10/10]\n",
      "Analyzing evidence...\n",
      "Error parsing response: Invalid control character at: line 6 column 48 (char 112)\n",
      "Raw response: {\n",
      "  \"claim_id\": 2,\n",
      "  \"evidence\": [\n",
      "    {\n",
      "      \"evidence_id\": 1,\n",
      "      \"evidence_text\": \"CQCC significantly out-\n",
      "performed MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively. Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\",\n",
      "      \"evidence_type\": \"primary\",\n",
      "      \"strength\": \"strong\",\n",
      "      \"limitations\": \"No limitations are stated in the provided context.\",\n",
      "      \"location\": \"Abstract\",\n",
      "      \"exact_quote\": \"CQCC significantly outperformed MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively. Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Analyzing conclusions...\n",
      "\n",
      "=== Complete Paper Analysis ===\n",
      "\n",
      "Claim 1:\n",
      "Statement: CQCC significantly outperforms MFCC in the classification of neurodegenerative diseases\n",
      "\n",
      "Evidence:\n",
      "- Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\n",
      "  Strength: strong\n",
      "  Limitations: None stated\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC outperforms MFCC in classifying neurodegenerative diseases with significant absolute improvements of 5.6% and 7.7% on RF and SVM classifiers respectively.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: The evidence is robust as it is based on a study that used a large dataset and employed rigorous experimental methods. The results were consistent across different classifiers and evaluation metrics.\n",
      "Limitations: The study did not compare CQCC with other state-of-the-art feature extraction methods, and it is unclear how well CQCC would perform in more complex classification tasks.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 2:\n",
      "Statement: CQCC shows enhanced performance over traditional acoustic measures\n",
      "\n",
      "Evidence:\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC shows enhanced performance over traditional acoustic measures such as Jitter, Shimmer, and Teager Energy.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: The evidence is robust as it is based on a study that used a large dataset and employed rigorous experimental methods. The results were consistent across different classifiers and evaluation metrics.\n",
      "Limitations: The study did not compare CQCC with other advanced feature extraction methods, and it is unclear how well CQCC would perform in more complex classification tasks.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 3:\n",
      "Statement: CQCC features are robust against MFCC features\n",
      "\n",
      "Evidence:\n",
      "- CQCC features outperformed MFCC features with an absolute increment of 5.6% and 7.7% on RF and SVM classifiers, respectively.\n",
      "  Strength: strong\n",
      "  Limitations: None stated\n",
      "- CQCC yielded the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\n",
      "  Strength: strong\n",
      "  Limitations: None stated\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC features are robust against MFCC features.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: The evidence is robust as it is based on a study that used a large dataset and employed rigorous experimental methods. The results were consistent across different classifiers, evaluation metrics, and pathological classification tasks.\n",
      "Limitations: The study did not compare CQCC with other advanced feature extraction methods, and it is unclear how well CQCC would perform in more complex classification tasks.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Intermediate results saved to 'intermediate_results.json'\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import datetime\n",
    "import pdfplumber\n",
    "from typing import Dict, List, Any\n",
    "import pymupdf4llm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "class PaperAnalyzer:\n",
    "    def __init__(self, api_key: str):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel('gemini-pro')\n",
    "        self.paper_text = None\n",
    "        self.execution_times = {\n",
    "        \"claims_analysis\": 0,\n",
    "        \"evidence_analysis\": 0,\n",
    "        \"conclusions_analysis\": 0,\n",
    "        \"total_time\": 0,\n",
    "        \"total_sleep_time\": 0,  # Add this\n",
    "        \"actual_processing_time\": 0  # Add this\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    def extract_text_from_pdf(self, filename: str) -> str:\n",
    "        \"\"\"Extract text from PDF file using PyMuPDF\"\"\"\n",
    "        try:\n",
    "            # Convert PDF to markdown format\n",
    "            self.paper_text = pymupdf4llm.to_markdown(filename)\n",
    "            return self.paper_text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from PDF: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "        \n",
    "    def get_claims(self, filename: str) -> Dict:\n",
    "        \"\"\"Extract all claims from the paper\"\"\"\n",
    "        # text = self.extract_text_from_pdf(filename)\n",
    "\n",
    "\n",
    "        if not self.paper_text:\n",
    "            text = self.extract_text_from_pdf(filename)\n",
    "        else:\n",
    "            text = self.paper_text\n",
    "    \n",
    "        start_time = time.time()\n",
    "\n",
    "        if not self.paper_text:\n",
    "            raise Exception(\"Failed to extract text from PDF\")\n",
    "\n",
    "        \n",
    "        claims_prompt = f\"\"\"\n",
    "        Analyze this research paper and extract ALL possible claims made by the authors.\n",
    "        Paper text: {text}\n",
    "        \n",
    "        Your task is to identify all statements in the text that meet the following criteria for a claim:\n",
    "        1. Makes a specific, testable assertion about results, methods, or contributions\n",
    "        2. Represents a novel finding, improvement, or advancement\n",
    "        3. Presents a clear position or conclusion\n",
    "\n",
    "        Make sure to:\n",
    "        1. Include both major and minor claims\n",
    "        2. Don't miss any claims\n",
    "        3. Present each claim as a separate item\n",
    "        \n",
    "        Return ONLY the following JSON structure:\n",
    "        {{\n",
    "            \"claims\": [\n",
    "                {{\n",
    "                    \"claim_id\": 1,\n",
    "                    \"claim_text\": \"statement of the claim\",\n",
    "                    \"location\": \"section/paragraph where this claim appears\",\n",
    "                    \"claim_type\": \"Nature of the claim\",\n",
    "                    \"exact_quote\": \"complete verbatim text containing the claim\"\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \"\"\"\n",
    "        time.sleep(45)\n",
    "        self.execution_times[\"total_sleep_time\"] += 45\n",
    "        response = self.model.generate_content(claims_prompt)\n",
    "        # self.execution_times[\"claims_analysis\"] = time.time() - start_time\n",
    "\n",
    "        self.execution_times[\"claims_analysis\"] = time.time() - start_time\n",
    "\n",
    "        return self._parse_json_response(response.text)\n",
    "\n",
    "    def analyze_evidence(self, filename: str, claims: Dict) -> List[Dict]:\n",
    "        \"\"\"Find evidence for each claim\"\"\"\n",
    "        # text = extract_text_from_pdf(filename)\n",
    "\n",
    "        \n",
    "\n",
    "        if not self.paper_text:\n",
    "            text = self.extract_text_from_pdf(filename)\n",
    "        else:\n",
    "            text = self.paper_text\n",
    "\n",
    "        start_time = time.time()\n",
    "        evidence_results = []\n",
    "        \n",
    "        for claim in claims['claims']:\n",
    "            evidence_prompt = f\"\"\"\n",
    "            Paper text: {text}\n",
    "            \n",
    "            For the following claim from the paper:\n",
    "            \"{claim['claim_text']}\"\n",
    "            \n",
    "            Please identify relevant evidence that:\n",
    "            1. Directly supports or contradicts the claim's specific assertion\n",
    "            2. Is presented with experimental results, data, or concrete examples\n",
    "            3. Can be traced to specific methods, results, or discussion sections\n",
    "            4. Is not from the abstract or introduction\n",
    "\n",
    "            If NO evidence is found for the given Claim, return:\n",
    "            {{\n",
    "                \"claim_id\": {claim['claim_id']},\n",
    "                \"evidence\": [],\n",
    "                \"no_evidence_reason\": \"Explain why no evidence was found (e.g., 'Claim is unsupported', 'Claim is theoretical without empirical evidence', etc.)\"\n",
    "            }}\n",
    "            ELSE:\n",
    "            Return ONLY the following JSON structure:\n",
    "            {{\n",
    "                \"claim_id\": {claim['claim_id']},\n",
    "                \"evidence\": [\n",
    "                    {{\n",
    "                        \"evidence_id\": 1,\n",
    "                        \"evidence_text\": \"specific experimental result/data point\",\n",
    "                        \"evidence_type\": \"primary/secondary\",\n",
    "                        \"strength\": \"strong/moderate/weak\",\n",
    "                        \"limitations\": \"stated limitations or assumptions\",\n",
    "                        \"location\": \"specific section & paragraph\",\n",
    "                        \"exact_quote\": \"verbatim text from paper\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "            time.sleep(45)\n",
    "            self.execution_times[\"total_sleep_time\"] += 45\n",
    "            response = self.model.generate_content(evidence_prompt)\n",
    "            result = self._parse_json_response(response.text)\n",
    "            if result:\n",
    "                evidence_results.append(result)\n",
    "        \n",
    "        self.execution_times[\"evidence_analysis\"] = time.time() - start_time\n",
    "        return evidence_results\n",
    "\n",
    "    def analyze_conclusions(self, filename: str, claims: Dict, evidence_results: List[Dict]) -> Dict:\n",
    "        \"\"\"Analyze conclusions considering claims and evidence\"\"\"\n",
    "        # text = extract_text_from_pdf(filename)\n",
    "\n",
    "        if not self.paper_text:\n",
    "            text = self.extract_text_from_pdf(filename)\n",
    "        else:\n",
    "            text = self.paper_text\n",
    "        \n",
    "        # Build evidence summary\n",
    "        def build_evidence_summary(claim_id):\n",
    "            claim_evidence = next((e['evidence'] for e in evidence_results if e.get('claim_id') == claim_id), [])\n",
    "            evidence_text = []\n",
    "            for idx, evidence in enumerate(claim_evidence, 1):\n",
    "                evidence_text.append(\n",
    "                    f\"  Evidence {idx}:\\n\"\n",
    "                    f\"    - Text: {evidence.get('evidence_text', 'No text provided')}\\n\"\n",
    "                    f\"    - Strength: {evidence.get('strength', 'Not specified')}\\n\"\n",
    "                    f\"    - Limitations: {evidence.get('limitations', 'None specified')}\\n\"\n",
    "                    f\"    - Location: {evidence.get('location', 'Location not specified')}\"\n",
    "                )\n",
    "            return \"\\n\".join(evidence_text)\n",
    "\n",
    "        # Create analysis summary\n",
    "        analysis_sections = []\n",
    "        for claim in claims.get('claims', []):\n",
    "            claim_id = claim.get('claim_id')\n",
    "            claim_section = (\n",
    "                f\"\\nClaim {claim_id}:\\n\"\n",
    "                f\"Statement: {claim.get('claim_text', 'No text provided')}\\n\"\n",
    "                f\"Location: {claim.get('location', 'Location not specified')}\\n\"\n",
    "                f\"\\nEvidence Summary:\\n{build_evidence_summary(claim_id)}\"\n",
    "            )\n",
    "            analysis_sections.append(claim_section)\n",
    "\n",
    "        full_analysis = \"\\n\".join(analysis_sections)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "        conclusions_prompt = f\"\"\"\n",
    "        Paper text: {text}\n",
    "        \n",
    "        Analyze the following claims and their supporting evidence:\n",
    "        {full_analysis}\n",
    "\n",
    "        For each claim, provide a comprehensive conclusion analysis following these guidelines:\n",
    "\n",
    "        1. Evidence Assessment:\n",
    "        - Evaluate the strength and quality of ALL evidence presented\n",
    "        - Consider both supporting and contradicting evidence\n",
    "        - Assess the methodology and reliability of evidence\n",
    "\n",
    "        2. Conclusion Analysis:\n",
    "        - Determine what the authors concluded about each claim\n",
    "        - Evaluate if conclusions are justified by the evidence\n",
    "        - Consider the relationship between evidence quality and conclusion strength\n",
    "\n",
    "        3. Robustness Evaluation:\n",
    "        - Assess how well the evidence supports the conclusions\n",
    "        - Consider methodological strengths and weaknesses\n",
    "        - Evaluate the consistency of evidence across different sources\n",
    "\n",
    "        4. Limitations Analysis:\n",
    "        - Identify specific limitations in both evidence and conclusions\n",
    "        - Consider gaps in methodology or data\n",
    "        - Note any potential biases or confounding factors\n",
    "\n",
    "        Return ONLY the following JSON structure:\n",
    "        {{\n",
    "            \"conclusions\": [\n",
    "                {{\n",
    "                    \"claim_id\": number,\n",
    "                    \"author_conclusion\": \"detailed description of authors' conclusion based on evidence\",\n",
    "                    \"conclusion_justified\": true/false,\n",
    "                    \"justification_explanation\": \"detailed explanation of why conclusion is/isn't justified\",\n",
    "                    \"robustness_analysis\": \"comprehensive analysis of evidence strength and reliability\",\n",
    "                    \"limitations\": \"specific limitations and caveats\",\n",
    "                    \"location\": \"section/paragraph where conclusion appears\",\n",
    "                    \"evidence_alignment\": \"analysis of how well evidence aligns with conclusion\",\n",
    "                    \"confidence_level\": \"high/medium/low based on evidence quality\",\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \"\"\"\n",
    "        time.sleep(45)\n",
    "        self.execution_times[\"total_sleep_time\"] += 45\n",
    "        response = self.model.generate_content(conclusions_prompt)\n",
    "        result = self._parse_json_response(response.text)\n",
    "\n",
    "        if not result or not isinstance(result, dict) or 'conclusions' not in result:\n",
    "            return {\"conclusions\": []}\n",
    "\n",
    "        # Ensure complete coverage\n",
    "        claims_ids = set(claim['claim_id'] for claim in claims.get('claims', []))\n",
    "        all_conclusions = result.get('conclusions', [])\n",
    "        \n",
    "        complete_conclusions = []\n",
    "        for claim_id in claims_ids:\n",
    "            existing_conclusion = next(\n",
    "                (c for c in all_conclusions if c.get('claim_id') == claim_id),\n",
    "                None\n",
    "            )\n",
    "            \n",
    "            if existing_conclusion:\n",
    "                complete_conclusions.append(existing_conclusion)\n",
    "            else:\n",
    "                complete_conclusions.append({\n",
    "                    \"claim_id\": claim_id,\n",
    "                    \"author_conclusion\": \"No conclusion available\",\n",
    "                    \"conclusion_justified\": False,\n",
    "                    \"justification_explanation\": \"Analysis not available\",\n",
    "                    \"robustness_analysis\": \"No robustness analysis available\",\n",
    "                    \"limitations\": \"No limitations analysis available\",\n",
    "                    \"location\": \"Location not specified\",\n",
    "                    \"evidence_alignment\": \"No alignment analysis available\",\n",
    "                    \"confidence_level\": \"low\"\n",
    "                })\n",
    "        self.execution_times[\"conclusions_analysis\"] = time.time() - start_time\n",
    "\n",
    "        return {\n",
    "            \"conclusions\": complete_conclusions,\n",
    "            \"analysis_metadata\": {\n",
    "                \"total_claims_analyzed\": len(claims_ids),\n",
    "                \"claims_with_conclusions\": len(all_conclusions),\n",
    "                \"analysis_timestamp\": str(datetime.datetime.now())\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _parse_json_response(self, response: str) -> Dict:\n",
    "        \"\"\"Parse JSON response and handle errors\"\"\"\n",
    "        try:\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in response\")\n",
    "                \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            return json.loads(json_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {e}\")\n",
    "            print(\"Raw response:\", response)\n",
    "            return None\n",
    "\n",
    "    def combine_results(self, claims: Dict, evidence_results: List[Dict], conclusions: Dict) -> Dict:\n",
    "        \"\"\"Combine all analysis results into a final structured format\"\"\"\n",
    "        final_results = {\n",
    "            \"paper_analysis\": []\n",
    "        }\n",
    "        \n",
    "        conclusions_dict = {\n",
    "            c['claim_id']: c \n",
    "            for c in conclusions.get('conclusions', [])\n",
    "        } if conclusions else {}\n",
    "        \n",
    "        evidence_dict = {\n",
    "            e['claim_id']: e.get('evidence', [])\n",
    "            for e in evidence_results if isinstance(e, dict)\n",
    "        }\n",
    "        \n",
    "        for claim in claims.get('claims', []):\n",
    "            claim_id = claim['claim_id']\n",
    "            conclusion = conclusions_dict.get(claim_id, {})\n",
    "            evidence = evidence_dict.get(claim_id, [])\n",
    "            \n",
    "            analysis = {\n",
    "                \"claim_id\": claim_id,\n",
    "                \"claim\": claim.get('claim_text', ''),\n",
    "                \"claim_location\": claim.get('location', 'Location not specified'),\n",
    "                \"evidence\": evidence,\n",
    "                \"evidence_locations\": [ev.get('location', 'Location not specified') for ev in evidence],\n",
    "                \"conclusion\": {\n",
    "                    \"author_conclusion\": conclusion.get('author_conclusion', 'No conclusion available'),\n",
    "                    \"conclusion_justified\": conclusion.get('conclusion_justified', False),\n",
    "                    \"robustness_analysis\": conclusion.get('robustness_analysis', 'No robustness analysis available'),\n",
    "                    \"limitations\": conclusion.get('limitations', 'No limitations analysis available'),\n",
    "                    \"conclusion_location\": conclusion.get('location', 'Location not specified')\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            final_results['paper_analysis'].append(analysis)\n",
    "\n",
    "        final_results[\"execution_times\"] = {\n",
    "            \"claims_analysis_time\": f\"{self.execution_times['claims_analysis']:.2f} seconds\",\n",
    "            \"evidence_analysis_time\": f\"{self.execution_times['evidence_analysis']:.2f} seconds\",\n",
    "            \"conclusions_analysis_time\": f\"{self.execution_times['conclusions_analysis']:.2f} seconds\",\n",
    "            \"total_sleep_time\": f\"{self.execution_times['total_sleep_time']:.2f} seconds\",\n",
    "            \"actual_processing_time\": f\"{(self.execution_times['total_time'] - self.execution_times['total_sleep_time']):.2f} seconds\",\n",
    "            \"total_execution_time\": f\"{self.execution_times['total_time']:.2f} seconds\"\n",
    "        }\n",
    "\n",
    "        \n",
    "        return final_results\n",
    "\n",
    "    def print_analysis_results(self, final_results: Dict):\n",
    "        \"\"\"Print the analysis results in a readable format\"\"\"\n",
    "        print(\"\\n=== Complete Paper Analysis ===\\n\")\n",
    "        \n",
    "        for analysis in final_results['paper_analysis']:\n",
    "            print(f\"Claim {analysis['claim_id']}:\")\n",
    "            print(f\"Statement: {analysis['claim']}\")\n",
    "            print(\"\\nEvidence:\")\n",
    "            for evidence in analysis['evidence']:\n",
    "                print(f\"- {evidence['evidence_text']}\")\n",
    "                print(f\"  Strength: {evidence['strength']}\")\n",
    "                print(f\"  Limitations: {evidence['limitations']}\")\n",
    "            \n",
    "            print(\"\\nConclusion:\")\n",
    "            print(f\"Author's Conclusion: {analysis['conclusion']['author_conclusion']}\")\n",
    "            print(f\"Justified by Evidence: {'Yes' if analysis['conclusion']['conclusion_justified'] else 'No'}\")\n",
    "            print(f\"Robustness: {analysis['conclusion']['robustness_analysis']}\")\n",
    "            print(f\"Limitations: {analysis['conclusion']['limitations']}\")\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "def main():\n",
    "    # Initialize analyzer\n",
    "    api_key = \"AIzaSyAxRZoijGYCA0EisBJTxm1KGs7KBD0Nppo\"\n",
    "    analyzer = PaperAnalyzer(api_key)\n",
    "    \n",
    "    # Analyze paper\n",
    "    filename = \"ICLR_1.pdf\"\n",
    "    basefile_name = Path(filename).stem\n",
    "\n",
    "    try:\n",
    "\n",
    "        total_start_time = time.time()\n",
    "\n",
    "        # Step 1: Extract claims\n",
    "        print(\"Extracting claims...\")\n",
    "        claims = analyzer.get_claims(filename)\n",
    "\n",
    "        # Step 2: Analyze evidence\n",
    "        print(\"Analyzing evidence...\")\n",
    "        evidence_results = analyzer.analyze_evidence(filename, claims)\n",
    "        \n",
    "        # Step 3: Analyze conclusions\n",
    "        print(\"Analyzing conclusions...\")\n",
    "        conclusions = analyzer.analyze_conclusions(filename, claims, evidence_results)\n",
    "        \n",
    "\n",
    "        analyzer.execution_times[\"total_time\"] = time.time() - total_start_time\n",
    "\n",
    "        # Combine results\n",
    "        final_results = analyzer.combine_results(claims, evidence_results, conclusions)\n",
    "        \n",
    "        # Print results\n",
    "        analyzer.print_analysis_results(final_results)\n",
    "        os.makedirs('Gemini_one_by_one', exist_ok=True)\n",
    "\n",
    "        # Save results\n",
    "        with open(f'Gemini_one_by_one/{basefile_name}_analysis.json', 'w') as f:\n",
    "            json.dump(final_results, f, indent=4)\n",
    "        \n",
    "        # Save intermediate results\n",
    "        intermediate_results = {\n",
    "            \"claims\": claims,\n",
    "            \"evidence\": evidence_results,\n",
    "            \"conclusions\": conclusions,\n",
    "            \"execution_times\": final_results[\"execution_times\"]\n",
    "\n",
    "\n",
    "        }\n",
    "        with open(f'Gemini_one_by_one/{basefile_name}_intermediate.json', 'w') as f:\n",
    "            json.dump(intermediate_results, f, indent=4)\n",
    "        print(\"Intermediate results saved to 'intermediate_results.json'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing paper: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of ICLR_1.pdf\n",
      "Extracting text from PDF...\n",
      "Processing ICLR_1.pdf...\n",
      "[                                        ] (0/1===[====                                    ] ( 1/10===[========                                ] ( 2/10===[============                            ] ( 3/10===[================                        ] ( 4/10===[====================                    ] ( 5/10===[========================                ] ( 6/10===[============================            ] ( 7/10===[================================        ] ( 8/10===[====================================    ] ( 9/10===[========================================] (10/10]\n",
      "Analyzing paper...\n",
      "Parsing response...\n",
      "Raw response: ```json\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"claim_id\": 1,\n",
      "      \"claim\": {\n",
      "        \"text\": \"CQCCs outperformed the baseline MFCC features with an absolute increment of 5.6% and 7.7% on RF and SVM classifiers, respectively.\",\n",
      "        \"type\": \"performance\",\n",
      "        \"location\": \"5.2.2 Classification between different pathologies\",\n",
      "        \"exact_quote\": \"It can be observed from the tables that the proposed CQCC features outperform the baseline MFCC features with an absolute increment of 5.6% and 7.7% on RF and SVM classifiers, respectively.\"\n",
      "      },\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_text\": \"CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\",\n",
      "          \"strength\": \"strong\",\n",
      "          \"limitations\": \"None\",\n",
      "          \"location\": \"5.2.2 Classification between different pathologies\",\n",
      "          \"exact_quote\": \"Furthermore, Table 6, shows the classification results between ALS and Parkinson’s patients across different acoustical features when employing Random Forest (RF) and Support Vector Machine (SVM) classifiers. It can be observed from Table 6 that CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\"\n",
      "        }\n",
      "      ],\n",
      "      \"evaluation\": {\n",
      "        \"conclusion_justified\": true,\n",
      "        \"robustness\": \"high\",\n",
      "        \"justification\": \"Evidence shows that CQCC outperforms MFCC on both RF and SVM classifiers for ALS and Parkinson's classification.\",\n",
      "        \"key_limitations\": \"None\",\n",
      "        \"confidence_level\": \"high\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 2,\n",
      "      \"claim\": {\n",
      "        \"text\": \"CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\",\n",
      "        \"type\": \"performance\",\n",
      "        \"location\": \"Abstract\",\n",
      "        \"exact_quote\": \"Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\"\n",
      "      },\n",
      "      \"evidence\": [],\n",
      "      \"evaluation\": {\n",
      "        \"conclusion_justified\": true,\n",
      "        \"robustness\": \"medium\",\n",
      "        \"justification\": \"Evidence is missing in the provided context.\",\n",
      "        \"key_limitations\": \"Lack of specific evidence to support the claim.\",\n",
      "        \"confidence_level\": \"medium\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 3,\n",
      "      \"claim\": {\n",
      "        \"text\": \"CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\",\n",
      "        \"type\": \"performance\",\n",
      "        \"location\": \"Abstract\",\n",
      "        \"exact_quote\": \"Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\"\n",
      "      },\n",
      "      \"evidence\": [],\n",
      "      \"evaluation\": {\n",
      "        \"conclusion_justified\": true,\n",
      "        \"robustness\": \"medium\",\n",
      "        \"justification\": \"Evidence is missing in the provided context.\",\n",
      "        \"key_limitations\": \"Lack of specific evidence to support the claim.\",\n",
      "        \"confidence_level\": \"medium\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 4,\n",
      "      \"claim\": {\n",
      "        \"text\": \"The form-invariance property ensures consistent feature representation across varying pitch and tonal conditions, thereby enhancing classification robustness.\",\n",
      "        \"type\": \"contribution\",\n",
      "        \"location\": \"Abstract\",\n",
      "        \"exact_quote\": \"The effectiveness of CQCC features is underpinned by the form-invariance property of the Constant Q Transform (CQT), which ensures consistent feature representation across varying pitch and tonal conditions, thereby enhancing classification robustness.\"\n",
      "      },\n",
      "      \"evidence\": [],\n",
      "      \"evaluation\": {\n",
      "        \"conclusion_justified\": false,\n",
      "        \"robustness\": \"low\",\n",
      "        \"justification\": \"Evidence is missing in the provided context.\",\n",
      "        \"key_limitations\": \"Lack of specific evidence to support the claim.\",\n",
      "        \"confidence_level\": \"low\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 5,\n",
      "      \"claim\": {\n",
      "        \"text\": \"CQCC features are more effective at distinguishing between neurodegenerative disorders and healthy individuals, making them a more robust feature set for classification tasks.\",\n",
      "        \"type\": \"contribution\",\n",
      "        \"location\": \"5.2.3 Feature visualization using LDA plots\",\n",
      "        \"exact_quote\": \"This stronger discriminative power indicates that CQCC features are more effective at distinguishing between neurodegenerative disorders and healthy individuals, making them a more robust feature set for classification tasks.\"\n",
      "      },\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_text\": \"The LDA plot of CQCC features exhibits a clearer separation, especially between the ALS and Parkinson’s disease classes.\",\n",
      "          \"strength\": \"strong\",\n",
      "          \"limitations\": \"None\",\n",
      "          \"location\": \"5.2.3 Feature visualization using LDA plots\",\n",
      "          \"exact_quote\": \"However, the LDA plot of CQCC features exhibits a clearer separation, especially between the ALS and Parkinson’s disease classes.\"\n",
      "        }\n",
      "      ],\n",
      "      \"evaluation\": {\n",
      "        \"conclusion_justified\": true,\n",
      "        \"robustness\": \"high\",\n",
      "        \"justification\": \"Evidence from LDA plots supports the claim that CQCC features are more effective in distinguishing between neurodegenerative disorders and healthy individuals.\",\n",
      "        \"key_limitations\": \"None\",\n",
      "        \"confidence_level\": \"high\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully parsed JSON response\n",
      "\n",
      "=== Complete Paper Analysis ===\n",
      "\n",
      "Claim 1:\n",
      "Statement: CQCCs outperformed the baseline MFCC features with an absolute increment of 5.6% and 7.7% on RF and SVM classifiers, respectively.\n",
      "\n",
      "Evidence:\n",
      "- CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\n",
      "  Strength: strong\n",
      "  Limitations: None\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: Evidence shows that CQCC outperforms MFCC on both RF and SVM classifiers for ALS and Parkinson's classification.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: high\n",
      "Limitations: None\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 2:\n",
      "Statement: CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\n",
      "\n",
      "Evidence:\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: Evidence is missing in the provided context.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: medium\n",
      "Limitations: Lack of specific evidence to support the claim.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 3:\n",
      "Statement: CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\n",
      "\n",
      "Evidence:\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: Evidence is missing in the provided context.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: medium\n",
      "Limitations: Lack of specific evidence to support the claim.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 4:\n",
      "Statement: The form-invariance property ensures consistent feature representation across varying pitch and tonal conditions, thereby enhancing classification robustness.\n",
      "\n",
      "Evidence:\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: Evidence is missing in the provided context.\n",
      "Justified by Evidence: No\n",
      "Robustness: low\n",
      "Limitations: Lack of specific evidence to support the claim.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 5:\n",
      "Statement: CQCC features are more effective at distinguishing between neurodegenerative disorders and healthy individuals, making them a more robust feature set for classification tasks.\n",
      "\n",
      "Evidence:\n",
      "- The LDA plot of CQCC features exhibits a clearer separation, especially between the ALS and Parkinson’s disease classes.\n",
      "  Strength: strong\n",
      "  Limitations: None\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: Evidence from LDA plots supports the claim that CQCC features are more effective in distinguishing between neurodegenerative disorders and healthy individuals.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: high\n",
      "Limitations: None\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pymupdf4llm\n",
    "import time\n",
    "import datetime\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class SinglePassPaperAnalyzer:\n",
    "    def __init__(self, api_key: str):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel('gemini-pro')\n",
    "        self.paper_text = None\n",
    "        self.execution_times = {\n",
    "        \"single_pass_analysis\": 0,\n",
    "        \"total_time\": 0,\n",
    "        \"total_sleep_time\": 0,  # Add this\n",
    "        \"actual_processing_time\": 0  # Add this\n",
    "    }\n",
    "        \n",
    "    def extract_text_from_pdf(self, filename: str) -> str:\n",
    "        \"\"\"Extract text from PDF file using PyMuPDF\"\"\"\n",
    "        try:\n",
    "            self.paper_text = pymupdf4llm.to_markdown(filename)\n",
    "            return self.paper_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from PDF: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def analyze_paper(self, filename):\n",
    "        \"\"\"Perform comprehensive single-pass analysis of the paper\"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        if not self.paper_text:\n",
    "            text = self.extract_text_from_pdf(filename)\n",
    "        else:\n",
    "            text = self.paper_text\n",
    "            \n",
    "        if not text:\n",
    "            raise Exception(\"Failed to extract text from PDF\")\n",
    "        \n",
    "        comprehensive_prompt = f\"\"\"\n",
    "        Analyze this research paper and provide a comprehensive evaluation.\n",
    "        Paper text: {text}\n",
    "\n",
    "        Follow these guidelines:\n",
    "\n",
    "        1. Identify ALL claims in the paper where each claim:\n",
    "           - Makes a specific, verifiable assertion\n",
    "           - Is supported by concrete evidence\n",
    "           - Represents findings, contributions, or methodological advantages\n",
    "           - Can be from any section except abstract\n",
    "\n",
    "        2. For each identified claim:\n",
    "           - Extract ALL supporting or contradicting evidence (experimental results, data, or methodology)\n",
    "           - Evaluate the evidence strength and limitations\n",
    "           - Assess how well conclusions align with evidence\n",
    "\n",
    "        Return ONLY the following JSON structure:\n",
    "        {{\n",
    "            \"analysis\": [\n",
    "                {{\n",
    "                    \"claim_id\": number,\n",
    "                    \"claim\": {{\n",
    "                        \"text\": \"statement of the claim\",\n",
    "                        \"type\": \"methodology/result/contribution/performance\",\n",
    "                        \"location\": \"section/paragraph\",\n",
    "                        \"exact_quote\": \"verbatim text from paper\"\n",
    "                    }},\n",
    "                    \"evidence\": [\n",
    "                        {{\n",
    "                            \"evidence_text\": \"specific experimental result/data\",\n",
    "                            \"strength\": \"strong/moderate/weak\",\n",
    "                            \"limitations\": \"specific limitations\",\n",
    "                            \"location\": \"section/paragraph\",\n",
    "                            \"exact_quote\": \"verbatim text from paper\"\n",
    "                        }}\n",
    "                    ],\n",
    "                    \"evaluation\": {{\n",
    "                        \"conclusion_justified\": true/false,\n",
    "                        \"robustness\": \"high/medium/low\",\n",
    "                        \"justification\": \"explanation of evidence-conclusion alignment\",\n",
    "                        \"key_limitations\": \"critical limitations affecting validity\",\n",
    "                        \"confidence_level\": \"high/medium/low\"\n",
    "                    }}\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "        Ensure:\n",
    "        - ALL substantive claims are captured\n",
    "        - Evaluations are objective and well-reasoned\n",
    "        - All locations and quotes are precise\n",
    "        - Multiple pieces of evidence per claim are included when present\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add rate limiting\n",
    "        time.sleep(45)\n",
    "        self.execution_times[\"total_sleep_time\"] += 45\n",
    "        # Get response from Gemini\n",
    "        response = self.model.generate_content(comprehensive_prompt)\n",
    "        # self.execution_times[\"single_pass_analysis\"] = time.time() - start_time\n",
    "\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        self.execution_times[\"single_pass_analysis\"] = elapsed_time\n",
    "        self.execution_times[\"actual_processing_time\"] = elapsed_time - self.execution_times[\"total_sleep_time\"]\n",
    "\n",
    "\n",
    "\n",
    "        return self._parse_json_response(response.text)\n",
    "\n",
    "    def _parse_json_response(self, response: str) -> Dict:\n",
    "        \"\"\"Parse JSON response with better error handling\"\"\"\n",
    "        try:\n",
    "            print(\"Parsing response...\")\n",
    "            print(\"Raw response:\", response)\n",
    "            \n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            \n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in response\")\n",
    "                \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            result = json.loads(json_str)\n",
    "            \n",
    "            print(\"Successfully parsed JSON response\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {str(e)}\")\n",
    "            print(\"Raw response:\", response)\n",
    "            return None\n",
    "        \n",
    "\n",
    "    def combine_results(self, analysis_results: Dict) -> tuple:\n",
    "        \"\"\"Restructure the single-pass analysis results into the desired format\"\"\"\n",
    "        claims = {\n",
    "            \"claims\": [\n",
    "                {\n",
    "                    \"claim_id\": item[\"claim_id\"],\n",
    "                    \"claim_text\": item[\"claim\"][\"text\"],\n",
    "                    \"location\": item[\"claim\"][\"location\"],\n",
    "                    \"claim_type\": item[\"claim\"][\"type\"],\n",
    "                    \"exact_quote\": item[\"claim\"][\"exact_quote\"]\n",
    "                }\n",
    "                for item in analysis_results[\"analysis\"]\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        evidence_results = [\n",
    "            {\n",
    "                \"claim_id\": item[\"claim_id\"],\n",
    "                \"evidence\": [\n",
    "                    {\n",
    "                        \"evidence_id\": idx + 1,\n",
    "                        \"evidence_text\": ev[\"evidence_text\"],\n",
    "                        \"evidence_type\": \"primary\",\n",
    "                        \"strength\": ev[\"strength\"],\n",
    "                        \"limitations\": ev[\"limitations\"],\n",
    "                        \"location\": ev[\"location\"],\n",
    "                        \"exact_quote\": ev[\"exact_quote\"]\n",
    "                    }\n",
    "                    for idx, ev in enumerate(item[\"evidence\"])\n",
    "                ]\n",
    "            }\n",
    "            for item in analysis_results[\"analysis\"]\n",
    "        ]\n",
    "        \n",
    "        conclusions = {\n",
    "            \"conclusions\": [\n",
    "                {\n",
    "                    \"claim_id\": item[\"claim_id\"],\n",
    "                    \"author_conclusion\": item[\"evaluation\"][\"justification\"],\n",
    "                    \"conclusion_justified\": item[\"evaluation\"][\"conclusion_justified\"],\n",
    "                    \"robustness_analysis\": item[\"evaluation\"][\"robustness\"],\n",
    "                    \"limitations\": item[\"evaluation\"][\"key_limitations\"],\n",
    "                    \"evidence_alignment\": item[\"evaluation\"][\"justification\"],\n",
    "                    \"confidence_level\": item[\"evaluation\"][\"confidence_level\"]\n",
    "                }\n",
    "                for item in analysis_results[\"analysis\"]\n",
    "            ],\n",
    "            \"analysis_metadata\": {\n",
    "                \"total_claims_analyzed\": len(analysis_results[\"analysis\"]),\n",
    "                \"claims_with_conclusions\": len(analysis_results[\"analysis\"]),\n",
    "                \"analysis_timestamp\": str(datetime.datetime.now())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        final_results = {\n",
    "            \"paper_analysis\": []\n",
    "        }\n",
    "        \n",
    "        for item in analysis_results[\"analysis\"]:\n",
    "            claim_id = item[\"claim_id\"]\n",
    "            analysis = {\n",
    "                \"claim_id\": claim_id,\n",
    "                \"claim\": item[\"claim\"][\"text\"],\n",
    "                \"claim_location\": item[\"claim\"][\"location\"],\n",
    "                \"evidence\": item[\"evidence\"],\n",
    "                \"evidence_locations\": [ev[\"location\"] for ev in item[\"evidence\"]],\n",
    "                \"conclusion\": {\n",
    "                    \"author_conclusion\": item[\"evaluation\"][\"justification\"],\n",
    "                    \"conclusion_justified\": item[\"evaluation\"][\"conclusion_justified\"],\n",
    "                    \"robustness_analysis\": item[\"evaluation\"][\"robustness\"],\n",
    "                    \"limitations\": item[\"evaluation\"][\"key_limitations\"],\n",
    "                    \"conclusion_location\": item[\"claim\"][\"location\"]\n",
    "                }\n",
    "            }\n",
    "            final_results[\"paper_analysis\"].append(analysis)\n",
    "        \n",
    "        return claims, evidence_results, conclusions, final_results\n",
    "\n",
    "    def print_analysis_results(self, final_results: Dict):\n",
    "        \"\"\"Print the analysis results in a readable format\"\"\"\n",
    "        print(\"\\n=== Complete Paper Analysis ===\\n\")\n",
    "        \n",
    "        for analysis in final_results['paper_analysis']:\n",
    "            print(f\"Claim {analysis['claim_id']}:\")\n",
    "            print(f\"Statement: {analysis['claim']}\")\n",
    "            print(\"\\nEvidence:\")\n",
    "            for evidence in analysis['evidence']:\n",
    "                print(f\"- {evidence['evidence_text']}\")\n",
    "                print(f\"  Strength: {evidence['strength']}\")\n",
    "                print(f\"  Limitations: {evidence['limitations']}\")\n",
    "            \n",
    "            print(\"\\nConclusion:\")\n",
    "            print(f\"Author's Conclusion: {analysis['conclusion']['author_conclusion']}\")\n",
    "            print(f\"Justified by Evidence: {'Yes' if analysis['conclusion']['conclusion_justified'] else 'No'}\")\n",
    "            print(f\"Robustness: {analysis['conclusion']['robustness_analysis']}\")\n",
    "            print(f\"Limitations: {analysis['conclusion']['limitations']}\")\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "    def save_results(self, results: Dict, base_filename: str):\n",
    "        \"\"\"Save analysis results to files\"\"\"\n",
    "        output_dir = Path('Gemini_all_at_once')\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "\n",
    "        results[\"execution_times\"] = {\n",
    "        \"single_pass_analysis_time\": f\"{self.execution_times['single_pass_analysis']:.2f} seconds\",\n",
    "        \"total_sleep_time\": f\"{self.execution_times['total_sleep_time']:.2f} seconds\",\n",
    "        \"actual_processing_time\": f\"{self.execution_times['actual_processing_time']:.2f} seconds\",\n",
    "        \"total_execution_time\": f\"{self.execution_times['total_time']:.2f} seconds\"\n",
    "        }\n",
    "        # Save full JSON results\n",
    "        json_path = output_dir / f'{base_filename}_analysis.json'\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "\n",
    "\n",
    "        # results[\"execution_times\"] = {\n",
    "        # \"single_pass_analysis_time\": f\"{self.execution_times['single_pass_analysis']:.2f} seconds\",\n",
    "        # \"total_execution_time\": f\"{self.execution_times['total_time']:.2f} seconds\"\n",
    "        #  }\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # Save readable text summary\n",
    "        text_path = output_dir / f'{base_filename}_summary.txt'\n",
    "        with open(text_path, 'w', encoding='utf-8') as f:\n",
    "            for analysis in results['analysis']:\n",
    "                f.write(f\"Claim {analysis['claim_id']}:\\n\")\n",
    "                f.write(f\"Type: {analysis['claim']['type']}\\n\")\n",
    "                f.write(f\"Statement: {analysis['claim']['text']}\\n\")\n",
    "                f.write(f\"Location: {analysis['claim']['location']}\\n\")\n",
    "                f.write(f\"Exact Quote: {analysis['claim']['exact_quote']}\\n\\n\")\n",
    "                \n",
    "                f.write(\"Evidence:\\n\")\n",
    "                for evidence in analysis['evidence']:\n",
    "                    f.write(f\"- Evidence Text: {evidence['evidence_text']}\\n\")\n",
    "                    f.write(f\"  Strength: {evidence['strength']}\\n\")\n",
    "                    f.write(f\"  Location: {evidence['location']}\\n\")\n",
    "                    f.write(f\"  Limitations: {evidence['limitations']}\\n\")\n",
    "                    f.write(f\"  Exact Quote: {evidence['exact_quote']}\\n\\n\")\n",
    "                \n",
    "                eval_data = analysis['evaluation']\n",
    "                f.write(\"Evaluation:\\n\")\n",
    "                f.write(f\"Conclusion Justified: {'Yes' if eval_data['conclusion_justified'] else 'No'}\\n\")\n",
    "                f.write(f\"Robustness: {eval_data['robustness']}\\n\")\n",
    "                f.write(f\"Confidence Level: {eval_data['confidence_level']}\\n\")\n",
    "                f.write(f\"Justification: {eval_data['justification']}\\n\")\n",
    "                f.write(f\"Key Limitations: {eval_data['key_limitations']}\\n\")\n",
    "                \n",
    "                f.write(\"\\n\" + \"-\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        stats_path = output_dir / f'{base_filename}_statistics.txt'\n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            total_claims = len(results['analysis'])\n",
    "            justified_claims = sum(1 for a in results['analysis'] \n",
    "                                 if a['evaluation']['conclusion_justified'])\n",
    "            \n",
    "            f.write(\"Analysis Statistics:\\n\")\n",
    "            f.write(f\"Total Claims Analyzed: {total_claims}\\n\")\n",
    "            f.write(f\"Justified Claims: {justified_claims}\\n\")\n",
    "            \n",
    "            # Evidence strength distribution\n",
    "            strength_levels = {}\n",
    "            for analysis in results['analysis']:\n",
    "                for evidence in analysis['evidence']:\n",
    "                    strength = evidence['strength']\n",
    "                    strength_levels[strength] = strength_levels.get(strength, 0) + 1\n",
    "            \n",
    "            f.write(\"\\nEvidence Strength Distribution:\\n\")\n",
    "            total_evidence = sum(strength_levels.values())\n",
    "            for strength, count in strength_levels.items():\n",
    "                f.write(f\"{strength}: {count} pieces ({count/total_evidence*100:.1f}%)\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        api_key = \"AIzaSyAxRZoijGYCA0EisBJTxm1KGs7KBD0Nppo\"\n",
    "        analyzer = SinglePassPaperAnalyzer(api_key)\n",
    "        \n",
    "        filename = \"ICLR_1.pdf\"\n",
    "        print(f\"Starting analysis of {filename}\")\n",
    "        \n",
    "\n",
    "        total_start_time = time.time()\n",
    "\n",
    "        # Extract text once at the beginning\n",
    "        print(\"Extracting text from PDF...\")\n",
    "        analyzer.extract_text_from_pdf(filename)\n",
    "        \n",
    "        # Perform single-pass analysis\n",
    "        print(\"Analyzing paper...\")\n",
    "        analysis_results = analyzer.analyze_paper(filename)\n",
    "\n",
    "        analyzer.execution_times[\"total_time\"] = time.time() - total_start_time\n",
    "\n",
    "        \n",
    "        # Restructure results into desired format\n",
    "        claims, evidence_results, conclusions, final_results = analyzer.combine_results(analysis_results)\n",
    "        \n",
    "        # Print results\n",
    "        analyzer.print_analysis_results(final_results)\n",
    "        \n",
    "        # # Save detailed results\n",
    "        # with open('detailed_analysis_results.json', 'w') as f:\n",
    "        #     json.dump(final_results, f, indent=4)\n",
    "        # print(\"Results saved to 'detailed_analysis_results.json'\")\n",
    "        \n",
    "        # Save intermediate results\n",
    "        # intermediate_results = {\n",
    "        #     \"claims\": claims,\n",
    "        #     \"evidence\": evidence_results,\n",
    "        #     \"conclusions\": conclusions,\n",
    "        #     \"execution_times\": final_results[\"execution_times\"]\n",
    "\n",
    "        # }\n",
    "        # with open('intermediate_results.json', 'w') as f:\n",
    "        #     json.dump(intermediate_results, f, indent=4)\n",
    "        # print(\"Intermediate results saved to 'intermediate_results.json'\")\n",
    "        \n",
    "        # Save additional analysis outputs\n",
    "        base_filename = Path(filename).stem\n",
    "        analyzer.save_results(analysis_results, base_filename)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing paper: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of ICLR_1.pdf\n",
      "Extracting text from PDF...\n",
      "Processing ICLR_1.pdf...\n",
      "[                                        ] (0/1===[====                                    ] ( 1/10===[========                                ] ( 2/10===[============                            ] ( 3/10===[================                        ] ( 4/10===[====================                    ] ( 5/10===[========================                ] ( 6/10===[============================            ] ( 7/10===[================================        ] ( 8/10===[====================================    ] ( 9/10===[========================================] (10/10]\n",
      "Extracting claims...\n",
      "Processing file: ICLR_1.pdf\n",
      "Parsing response...\n",
      "Raw response: ```json\n",
      "{\n",
      "  \"claims\": [\n",
      "    {\n",
      "      \"claim_id\": 1,\n",
      "      \"claim_text\": \"CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6% and 7.7%, respectively.\",\n",
      "      \"location\": \"Abstract\",\n",
      "      \"claim_type\": \"Improvement\",\n",
      "      \"exact_quote\": \"Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\"\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 2,\n",
      "      \"claim_text\": \"CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\",\n",
      "      \"location\": \"Abstract\",\n",
      "      \"claim_type\": \"Improvement\",\n",
      "      \"exact_quote\": \"Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\"\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 3,\n",
      "      \"claim_text\": \"The effectiveness of CQCC features against MFCC features are validated using LDA plots.\",\n",
      "      \"location\": \"Introduction\",\n",
      "      \"claim_type\": \"Validation\",\n",
      "      \"exact_quote\": \"These findings are validated using the Italian Parkinson’s database and the Minsk2019 database of Amyotrophic Lateral Sclerosis, underscoring the potential of CQCC to advance the classification of neurodegenerative disorders.\"\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 4,\n",
      "      \"claim_text\": \"CQCC features provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders.\",\n",
      "      \"location\": \"Introduction\",\n",
      "      \"claim_type\": \"Novelty\",\n",
      "      \"exact_quote\": \"Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\"\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 5,\n",
      "      \"claim_text\": \"CQCC features are robust against MFCC features in the classification of neurodegenerative disorders.\",\n",
      "      \"location\": \"Introduction\",\n",
      "      \"claim_type\": \"Improvement\",\n",
      "      \"exact_quote\": \"Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\"\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 6,\n",
      "      \"claim_text\": \"CQCC features leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution.\",\n",
      "      \"location\": \"Methods\",\n",
      "      \"claim_type\": \"Novelty\",\n",
      "      \"exact_quote\": \"In this research, we have employed the CQCC instead of the STFT-based feature sets. The Constant-Q Transform (CQT) offers superior frequency resolution in lower frequency regions.\"\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 7,\n",
      "      \"claim_text\": \"CQCC features are form-invariant, ensuring consistent feature representation across varying pitch and tonal conditions.\",\n",
      "      \"location\": \"Methods\",\n",
      "      \"claim_type\": \"Improvement\",\n",
      "      \"exact_quote\": \"The CQT of a signal wp(m) is given by: 2π � M (r) _[P m]_ 1 Wp[CQT] (r) = _M_ (r)−1 � _−j_ β β _|_ _|_ _[Y]_ indicating that scaling the time domain by a factor of β corresponds to scaling the frequency domain by the inverse factor _β[1]_ [. This shows that the structure of the energy spectral density (ESD) remains unchanged, which is why this property is referred to as \\\"form-invariance.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 8,\n",
      "      \"claim_text\": \"CQCC features are robust against MFCC features in the classification of neurodegenerative disorders.\",\n",
      "      \"location\": \"Experimental Discussion\",\n",
      "      \"claim_type\": \"Improvement\",\n",
      "      \"exact_quote\": \"As observed from Table 4, it can be observed that, Among the features analyzed, CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 63.4% accuracy achieved by the Support Vector Machine classifier.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully parsed JSON response\n",
      "Claims extraction completed\n",
      "Extracting evidence...\n",
      "Processing evidence for claims: Claim 1: CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6% and 7.7%, respectively.\n",
      "Claim 2: CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\n",
      "Claim 3: The effectiveness of CQCC features against MFCC features are validated using LDA plots.\n",
      "Claim 4: CQCC features provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders.\n",
      "Claim 5: CQCC features are robust against MFCC features in the classification of neurodegenerative disorders.\n",
      "Claim 6: CQCC features leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution.\n",
      "Claim 7: CQCC features are form-invariant, ensuring consistent feature representation across varying pitch and tonal conditions.\n",
      "Claim 8: CQCC features are robust against MFCC features in the classification of neurodegenerative disorders.\n",
      "Parsing response...\n",
      "Raw response: ```json\n",
      "{\n",
      "  \"evidence_sets\": [\n",
      "    {\n",
      "      \"claim_id\": 1,\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_id\": 1,\n",
      "          \"evidence_text\": \"CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6% and 7.7%, respectively.\",\n",
      "          \"strength\": \"strong\",\n",
      "          \"limitations\": \"None\",\n",
      "          \"location\": \"Abstract\",\n",
      "          \"exact_quote\": \"CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 2,\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_id\": 2,\n",
      "          \"evidence_text\": \"CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\",\n",
      "          \"strength\": \"strong\",\n",
      "          \"limitations\": \"None\",\n",
      "          \"location\": \"Abstract\",\n",
      "          \"exact_quote\": \" Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 3,\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_id\": 3,\n",
      "          \"evidence_text\": \"The effectiveness of CQCC features against MFCC features are validated using LDA plots.\",\n",
      "          \"strength\": \"strong\",\n",
      "          \"limitations\": \"None\",\n",
      "          \"location\": \"Abstract\",\n",
      "          \"exact_quote\": \"These findings are validated using the Italian Parkinson’s database and the Minsk2019 database of Amyotrophic Lateral Sclerosis, underscoring the potential of CQCC to advance the classification of neurodegenerative disorders.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 4,\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_id\": 4,\n",
      "          \"evidence_text\": \"CQCC features provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders.\",\n",
      "          \"strength\": \"moderate\",\n",
      "          \"limitations\": \"Not directly supported by experimental results\",\n",
      "          \"location\": \"Introduction\",\n",
      "          \"exact_quote\": \"Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 5,\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_id\": 5,\n",
      "          \"evidence_text\": \"CQCC features are robust against MFCC features in the classification of neurodegenerative disorders.\",\n",
      "          \"strength\": \"moderate\",\n",
      "          \"limitations\": \"Not directly supported by experimental results\",\n",
      "          \"location\": \"Related Work\",\n",
      "          \"exact_quote\": \"In (Vashkevich & Rushkevich, 2021), various acoustic features such as Jitter, Shimmer, Mel Frequency Cepstral Coefficients (MFCC), Formant Frequencies, and Pitch Period Entropy are used for the classification of Healthy individuals vs. those with neurodegenerative disease based on sustained vowels.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 6,\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_id\": 6,\n",
      "          \"evidence_text\": \"CQCC features leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution.\",\n",
      "          \"strength\": \"strong\",\n",
      "          \"limitations\": \"None\",\n",
      "          \"location\": \"Methodology\",\n",
      "          \"exact_quote\": \"The Discrete Fourier Transform (DFT) is essentially a sampled version of the Discrete-Time Fourier Transform (DTFT) applied to each frame of the speech signal (Brown, 1991).\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 7,\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_id\": 7,\n",
      "          \"evidence_text\": \"CQCC features are form-invariant, ensuring consistent feature representation across varying pitch and tonal conditions.\",\n",
      "          \"strength\": \"strong\",\n",
      "          \"limitations\": \"None\",\n",
      "          \"location\": \"Methodology\",\n",
      "          \"exact_quote\": \"For simplicity, we examine the continuous-time forms of the Fourier Transform (FT), Short-Time Fourier Transform (STFT), and Constant-Q Transform (CQT).\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"claim_id\": 8,\n",
      "      \"evidence\": [\n",
      "        {\n",
      "          \"evidence_id\": 8,\n",
      "          \"evidence_text\": \"CQCC features are robust against MFCC features in the classification of neurodegenerative disorders.\",\n",
      "          \"strength\": \"moderate\",\n",
      "          \"limitations\": \"Not directly supported by experimental results\",\n",
      "          \"location\": \"Conclusions\",\n",
      "          \"exact_quote\": \"Furthermore, the evaluation in new databases (D1 and D3) reaffirmed the robustness of CQCC in handling complex pathological classifications, providing further validation of their utility in clinical applications.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully parsed JSON response\n",
      "Evidence extraction completed\n",
      "Analyzing conclusions...\n",
      "Parsing response...\n",
      "Raw response: ```json\n",
      "{\n",
      "    \"conclusions\": [\n",
      "        {\n",
      "            \"claim_id\": 1,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"high\",\n",
      "            \"key_limitations\": \"Results may vary for different datasets and classification algorithms.\",\n",
      "            \"confidence_level\": \"high\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 2,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"medium\",\n",
      "            \"key_limitations\": \"Study only considered a limited number of traditional acoustic measures.\",\n",
      "            \"confidence_level\": \"medium\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 3,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"high\",\n",
      "            \"key_limitations\": \"LDA plots may not be reliable for all datasets.\",\n",
      "            \"confidence_level\": \"medium\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 4,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"high\",\n",
      "            \"key_limitations\": \"Robustness in capturing fundamental frequency and harmonics may depend on signal characteristics.\",\n",
      "            \"confidence_level\": \"high\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 5,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"high\",\n",
      "            \"key_limitations\": \"Robustness may vary depending on noise and other signal artifacts.\",\n",
      "            \"confidence_level\": \"high\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 6,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"high\",\n",
      "            \"key_limitations\": \"Geometric spacing of frequency bins may not be optimal for all applications.\",\n",
      "            \"confidence_level\": \"high\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 7,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"high\",\n",
      "            \"key_limitations\": \"Form-invariance may break down in extreme frequency ranges.\",\n",
      "            \"confidence_level\": \"high\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 8,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"high\",\n",
      "            \"key_limitations\": \"Robustness against MFCC features may depend on specific classification task and feature extraction parameters.\",\n",
      "            \"confidence_level\": \"high\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "Successfully parsed JSON response\n",
      "Conclusions analysis completed\n",
      "Results saved to analysis_outputs/:\n",
      "- Detailed analysis: Gemini_3_prompts/ICLR_1_analysis.json\n",
      "- Summary: Gemini_3_prompts/ICLR_1_summary.txt\n",
      "- Statistics: Gemini_3_prompts/ICLR_1_stats.txt\n",
      "Analysis completed successfully\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import datetime\n",
    "import pymupdf4llm\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "import traceback\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class PaperAnalyzer:\n",
    "    def __init__(self, api_key: str):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel('gemini-pro')\n",
    "        self.paper_text = None\n",
    "        self.execution_times = {\n",
    "        \"claims_analysis\": 0,\n",
    "        \"evidence_analysis\": 0,\n",
    "        \"conclusions_analysis\": 0,\n",
    "        \"total_time\": 0,\n",
    "        \"total_sleep_time\": 0,  # Track total sleep time\n",
    "        \"actual_processing_time\": 0  # Time without sleep delays\n",
    "            }\n",
    "        \n",
    "\n",
    "\n",
    "    def extract_text_from_pdf(self, filename: str) -> str:\n",
    "        \"\"\"Extract text from PDF file using PyMuPDF\"\"\"\n",
    "        try:\n",
    "            self.paper_text = pymupdf4llm.to_markdown(filename)\n",
    "            return self.paper_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from PDF: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def get_all_claims(self, filename: str) -> Dict:\n",
    "        \"\"\"Get all claims in one pass\"\"\"\n",
    "        try:\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            if not self.paper_text:\n",
    "                text = self.extract_text_from_pdf(filename)\n",
    "            else:\n",
    "                text = self.paper_text\n",
    "\n",
    "            print(f\"Processing file: {filename}\")\n",
    "            \n",
    "            claims_prompt = f\"\"\"\n",
    "            paper text: {text}\n",
    "            task is to identify all statements in the text that meet the following criteria for a claim:\n",
    "            1. Makes a specific, testable assertion about results, methods, or contributions\n",
    "            2. Represents a novel finding, improvement, or advancement\n",
    "            3. Presents a clear position or conclusion\n",
    "\n",
    "            Make sure to:\n",
    "            1. Include both major and minor claims\n",
    "            2. Don't miss any claims\n",
    "            3. Present each claim as a separate item\n",
    "            \n",
    "            Return ONLY the following JSON structure:\n",
    "            {{\n",
    "                \"claims\": [\n",
    "                    {{\n",
    "                        \"claim_id\": 1,\n",
    "                        \"claim_text\": \"statement of the claim\",\n",
    "                        \"location\": \"section/paragraph where this claim appears\",\n",
    "                        \"claim_type\": \"Nature of the claim\",\n",
    "                        \"exact_quote\": \"complete verbatim text containing the claim\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            time.sleep(45)  # Rate limiting\n",
    "            self.execution_times[\"total_sleep_time\"] += 45\n",
    "            response = self.model.generate_content(claims_prompt)\n",
    "            self.execution_times[\"claims_analysis\"] = time.time() - start_time\n",
    "\n",
    "            result = self._parse_json_response(response.text)\n",
    "            print(\"Claims extraction completed\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_all_claims: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_all_evidence(self, filename: str, claims: Dict) -> Dict:\n",
    "        \"\"\"Get evidence for all claims in one pass\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            if not self.paper_text:\n",
    "                text = self.extract_text_from_pdf(filename)\n",
    "            else:\n",
    "                text = self.paper_text\n",
    "            \n",
    "            claims_text = \"\\n\".join([f\"Claim {c['claim_id']}: {c['claim_text']}\" \n",
    "                                   for c in claims['claims']])\n",
    "            print(\"Processing evidence for claims:\", claims_text)\n",
    "            \n",
    "            evidence_prompt = f\"\"\"\n",
    "            Paper text: {text}\n",
    "\n",
    "            For these claims:\n",
    "            {claims_text}\n",
    "\n",
    "             Please identify relevant evidence that:\n",
    "            1. Directly supports or contradicts the claim's specific assertion\n",
    "            2. Is presented with experimental results, data, or concrete examples\n",
    "            3. Can be traced to specific methods, results, or discussion sections\n",
    "            4. Is not from the abstract or introduction\n",
    "\n",
    "            Return ONLY the following JSON:\n",
    "            {{\n",
    "                \"evidence_sets\": [\n",
    "                    {{\n",
    "                        \"claim_id\": number,\n",
    "                        \"evidence\": [\n",
    "                            {{\n",
    "                                \"evidence_id\": number,\n",
    "                                \"evidence_text\": \"specific evidence\",\n",
    "                                \"strength\": \"strong/moderate/weak\",\n",
    "                                \"limitations\": \"key limitations\",\n",
    "                                \"location\": \"section/paragraph\",\n",
    "                                \"exact_quote\": \"verbatim text\"\n",
    "                            }}\n",
    "                        ]\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            time.sleep(45)  # Rate limiting\n",
    "            self.execution_times[\"total_sleep_time\"] += 45\n",
    "            response = self.model.generate_content(evidence_prompt)\n",
    "            \n",
    "            result = self._parse_json_response(response.text)\n",
    "            self.execution_times[\"evidence_analysis\"] = time.time() - start_time\n",
    "            print(\"Evidence extraction completed\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_all_evidence: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_all_conclusions(self, filename: str, claims: Dict, evidence_sets: Dict) -> Dict:\n",
    "        \"\"\"Analyze conclusions for all claims and evidence in one pass\"\"\"\n",
    "        try:\n",
    "\n",
    "            start_time = time.time()\n",
    "            if not self.paper_text:\n",
    "                text = self.extract_text_from_pdf(filename)\n",
    "            else:\n",
    "                text = self.paper_text\n",
    "            \n",
    "            # Create summary of claims and evidence for the prompt\n",
    "            analysis_summary = []\n",
    "            for claim in claims['claims']:\n",
    "                claim_id = claim['claim_id']\n",
    "                claim_evidence = next((e['evidence'] for e in evidence_sets['evidence_sets'] \n",
    "                                    if e['claim_id'] == claim_id), [])\n",
    "                \n",
    "                summary = f\"\\nClaim {claim_id}: {claim['claim_text']}\\n\"\n",
    "                summary += \"Evidence:\\n\"\n",
    "                for evidence in claim_evidence:\n",
    "                    summary += f\"- {evidence['evidence_text']}\\n\"\n",
    "                analysis_summary.append(summary)\n",
    "            \n",
    "            analysis_text = \"\\n\".join(analysis_summary)\n",
    "            \n",
    "            conclusions_prompt = f\"\"\"\n",
    "            Paper text: {text}\n",
    "\n",
    "            Analyze these claims and their evidence:\n",
    "            {analysis_text}\n",
    "\n",
    "            For each claim-evidence pair, evaluate:\n",
    "            1. Whether the evidence justifies the claim\n",
    "            2. The overall strength of support\n",
    "            3. Any important limitations\n",
    "\n",
    "            Return ONLY the following JSON:\n",
    "            {{\n",
    "                \"conclusions\": [\n",
    "                    {{\n",
    "                        \"claim_id\": number,\n",
    "                        \"conclusion_justified\": true/false,\n",
    "                        \"robustness\": \"high/medium/low\",\n",
    "                        \"key_limitations\": \"specific limitations\",\n",
    "                        \"confidence_level\": \"high/medium/low\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            time.sleep(45)  # Rate limiting\n",
    "            self.execution_times[\"total_sleep_time\"] += 45\n",
    "            response = self.model.generate_content(conclusions_prompt)\n",
    "            \n",
    "            result = self._parse_json_response(response.text)\n",
    "\n",
    "            self.execution_times[\"conclusions_analysis\"] = time.time() - start_time\n",
    "\n",
    "            print(\"Conclusions analysis completed\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_all_conclusions: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _parse_json_response(self, response: str) -> Dict:\n",
    "        \"\"\"Parse JSON response with better error handling\"\"\"\n",
    "        try:\n",
    "            print(\"Parsing response...\")\n",
    "            print(\"Raw response:\", response)\n",
    "            \n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            \n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in response\")\n",
    "                \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            result = json.loads(json_str)\n",
    "            \n",
    "            print(\"Successfully parsed JSON response\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {str(e)}\")\n",
    "            print(\"Raw response:\", response)\n",
    "            raise\n",
    "\n",
    "    def analyze_paper(self, filename: str) -> Dict:\n",
    "        \"\"\"Complete paper analysis using three-prompt approach\"\"\"\n",
    "        try:\n",
    "\n",
    "            total_start_time = time.time()\n",
    "\n",
    "            # Extract text once at the beginning\n",
    "            print(\"Extracting text from PDF...\")\n",
    "            self.extract_text_from_pdf(filename)\n",
    "\n",
    "            # Get all claims\n",
    "            print(\"Extracting claims...\")\n",
    "            claims = self.get_all_claims(filename)\n",
    "            if not claims:\n",
    "                raise Exception(\"Failed to extract claims\")\n",
    "\n",
    "            # Get evidence for all claims\n",
    "            print(\"Extracting evidence...\")\n",
    "            evidence_sets = self.get_all_evidence(filename, claims)\n",
    "            if not evidence_sets:\n",
    "                raise Exception(\"Failed to extract evidence\")\n",
    "\n",
    "            # Get conclusions for all claim-evidence pairs\n",
    "            print(\"Analyzing conclusions...\")\n",
    "            conclusions = self.get_all_conclusions(filename, claims, evidence_sets)\n",
    "            if not conclusions:\n",
    "                raise Exception(\"Failed to generate conclusions\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate times\n",
    "            total_elapsed = time.time() - total_start_time\n",
    "            self.execution_times[\"total_time\"] = total_elapsed\n",
    "            self.execution_times[\"actual_processing_time\"] = (\n",
    "                total_elapsed - self.execution_times[\"total_sleep_time\"]\n",
    "            )\n",
    "\n",
    "            # Structure final results\n",
    "            final_results = {\n",
    "                \"paper_analysis\": []\n",
    "            }\n",
    "\n",
    "            for claim in claims['claims']:\n",
    "                claim_id = claim['claim_id']\n",
    "                \n",
    "                # Get evidence for this claim\n",
    "                evidence = next((e['evidence'] for e in evidence_sets['evidence_sets'] \n",
    "                            if e['claim_id'] == claim_id), [])\n",
    "                \n",
    "                # Get conclusion for this claim\n",
    "                conclusion = next((c for c in conclusions['conclusions'] \n",
    "                                if c['claim_id'] == claim_id), {})\n",
    "\n",
    "                analysis_item = {\n",
    "                    \"claim_id\": claim_id,\n",
    "                    \"claim\": {\n",
    "                        \"text\": claim['claim_text'],\n",
    "                        \"location\": claim['location'],\n",
    "                        \"type\": claim['claim_type'],\n",
    "                        \"exact_quote\": claim['exact_quote']\n",
    "                    },\n",
    "                    \"evidence\": evidence,\n",
    "                    \"conclusion\": {\n",
    "                        \"conclusion_justified\": conclusion.get('conclusion_justified', False),\n",
    "                        \"robustness\": conclusion.get('robustness', 'Not evaluated'),\n",
    "                        \"limitations\": conclusion.get('key_limitations', 'Not specified'),\n",
    "                        \"confidence_level\": conclusion.get('confidence_level', 'low')\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                final_results['paper_analysis'].append(analysis_item)\n",
    "\n",
    "            \n",
    "            # Add timing information\n",
    "            final_results[\"execution_times\"] = {\n",
    "                \"claims_analysis_time\": f\"{self.execution_times['claims_analysis']:.2f} seconds\",\n",
    "                \"evidence_analysis_time\": f\"{self.execution_times['evidence_analysis']:.2f} seconds\",\n",
    "                \"conclusions_analysis_time\": f\"{self.execution_times['conclusions_analysis']:.2f} seconds\",\n",
    "                \"total_time\": f\"{self.execution_times['total_time']:.2f} seconds\",\n",
    "                \"rate_limiting_sleep_time\": f\"{self.execution_times['total_sleep_time']:.2f} seconds\",\n",
    "                \"actual_processing_time\": f\"{self.execution_times['actual_processing_time']:.2f} seconds\"\n",
    "            }\n",
    "            \n",
    "            \n",
    "            \n",
    "            return final_results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in paper analysis: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def save_results(self, results: Dict, filename: str):\n",
    "        \"\"\"Save analysis results in multiple formats\"\"\"\n",
    "        try:\n",
    "            # timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            base_filename = Path(filename).stem\n",
    "\n",
    "            # Create output directory\n",
    "            os.makedirs('Gemini_3_prompts', exist_ok=True)\n",
    "            output_dir = \"Gemini_3_prompts\"\n",
    "            # Save detailed JSON results\n",
    "            json_filename = f'{output_dir}/{base_filename}_analysis.json'\n",
    "            with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            # Save human-readable summary\n",
    "            summary_filename = f'{output_dir}/{base_filename}_summary.txt'\n",
    "            with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"=== Paper Analysis Summary ===\\n\\n\")\n",
    "                \n",
    "                for analysis in results['paper_analysis']:\n",
    "                    f.write(f\"Claim {analysis['claim_id']}:\\n\")\n",
    "                    f.write(f\"Statement: {analysis['claim']['text']}\\n\")\n",
    "                    f.write(f\"Location: {analysis['claim']['location']}\\n\")\n",
    "                    f.write(f\"Type: {analysis['claim']['type']}\\n\")\n",
    "                    f.write(f\"Quote: {analysis['claim']['exact_quote']}\\n\\n\")\n",
    "                    \n",
    "                    f.write(\"Evidence:\\n\")\n",
    "                    for evidence in analysis['evidence']:\n",
    "                        f.write(f\"- {evidence['evidence_text']}\\n\")\n",
    "                        f.write(f\"  Strength: {evidence['strength']}\\n\")\n",
    "                        f.write(f\"  Location: {evidence['location']}\\n\")\n",
    "                        f.write(f\"  Limitations: {evidence['limitations']}\\n\")\n",
    "                        f.write(f\"  Quote: {evidence['exact_quote']}\\n\\n\")\n",
    "                    \n",
    "                    f.write(\"Conclusion:\\n\")\n",
    "                    f.write(f\"Justified: {analysis['conclusion']['conclusion_justified']}\\n\")\n",
    "                    f.write(f\"Robustness: {analysis['conclusion']['robustness']}\\n\")\n",
    "                    f.write(f\"Limitations: {analysis['conclusion']['limitations']}\\n\")\n",
    "                    f.write(f\"Confidence: {analysis['conclusion']['confidence_level']}\\n\")\n",
    "                    f.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "\n",
    "                    f.write(\"\\nExecution Times:\\n\")\n",
    "                    f.write(f\"Claims Analysis (with delays): {self.execution_times['claims_analysis']:.2f} seconds\\n\")\n",
    "                    f.write(f\"Evidence Analysis (with delays): {self.execution_times['evidence_analysis']:.2f} seconds\\n\")\n",
    "                    f.write(f\"Conclusions Analysis (with delays): {self.execution_times['conclusions_analysis']:.2f} seconds\\n\")\n",
    "                    f.write(f\"Total Rate Limiting Sleep Time: {self.execution_times['total_sleep_time']:.2f} seconds\\n\")\n",
    "                    f.write(f\"Actual Processing Time: {self.execution_times['actual_processing_time']:.2f} seconds\\n\")\n",
    "                    f.write(f\"Total Execution Time: {self.execution_times['total_time']:.2f} seconds\\n\")\n",
    "\n",
    "            # Save statistics\n",
    "            stats_filename = f'{output_dir}/{base_filename}_stats.txt'\n",
    "            with open(stats_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"Analysis Statistics:\\n\\n\")\n",
    "                f.write(f\"Total Claims Analyzed: {len(results['paper_analysis'])}\\n\")\n",
    "                \n",
    "                # Evidence statistics\n",
    "                total_evidence = sum(len(analysis['evidence']) for analysis in results['paper_analysis'])\n",
    "                f.write(f\"Total Evidence Pieces: {total_evidence}\\n\")\n",
    "                \n",
    "                # Confidence distribution\n",
    "                confidence_levels = {}\n",
    "                for analysis in results['paper_analysis']:\n",
    "                    level = analysis['conclusion']['confidence_level']\n",
    "                    confidence_levels[level] = confidence_levels.get(level, 0) + 1\n",
    "                \n",
    "                f.write(\"\\nConfidence Level Distribution:\\n\")\n",
    "                for level, count in confidence_levels.items():\n",
    "                    f.write(f\"{level}: {count} claims\\n\")\n",
    "\n",
    "            print(f\"Results saved to analysis_outputs/:\")\n",
    "            print(f\"- Detailed analysis: {json_filename}\")\n",
    "            print(f\"- Summary: {summary_filename}\")\n",
    "            print(f\"- Statistics: {stats_filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        api_key = \"AIzaSyAxRZoijGYCA0EisBJTxm1KGs7KBD0Nppo\"\n",
    "        analyzer = PaperAnalyzer(api_key)\n",
    "        \n",
    "        filename = \"ICLR_1.pdf\"\n",
    "        print(f\"Starting analysis of {filename}\")\n",
    "        \n",
    "        # Analyze paper\n",
    "        results = analyzer.analyze_paper(filename)\n",
    "        \n",
    "        if results:\n",
    "            # Save results in structured format\n",
    "            analyzer.save_results(results, filename)\n",
    "            print(\"Analysis completed successfully\")\n",
    "        else:\n",
    "            print(\"Analysis failed to produce results\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
