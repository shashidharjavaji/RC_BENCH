{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 156\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError analyzing paper: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 144\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2410.18764v1.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_paper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Save results to file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m, in \u001b[0;36mPaperAnalyzer.analyze_paper\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     58\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthread\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     59\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     content\u001b[38;5;241m=\u001b[39manalysis_prompt\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Run analysis\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_and_poll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43massistant_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massistant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalysis failed:\u001b[39m\u001b[38;5;124m\"\u001b[39m, run\u001b[38;5;241m.\u001b[39mstatus)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/resources/beta/threads/runs/runs.py:813\u001b[0m, in \u001b[0;36mRuns.create_and_poll\u001b[0;34m(self, assistant_id, include, additional_instructions, additional_messages, instructions, max_completion_tokens, max_prompt_tokens, metadata, model, parallel_tool_calls, response_format, temperature, tool_choice, tools, top_p, truncation_strategy, poll_interval_ms, thread_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;124;03mA helper to create a run an poll for a terminal state. More information on Run\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;124;03mlifecycles can be found here:\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;124;03mhttps://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    788\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    789\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread_id,\n\u001b[1;32m    790\u001b[0m     assistant_id\u001b[38;5;241m=\u001b[39massistant_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    811\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    812\u001b[0m )\n\u001b[0;32m--> 813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthread_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoll_interval_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoll_interval_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/resources/beta/threads/runs/runs.py:1000\u001b[0m, in \u001b[0;36mRuns.poll\u001b[0;34m(self, run_id, thread_id, extra_headers, extra_query, extra_body, timeout, poll_interval_ms)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    998\u001b[0m         poll_interval_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m-> 1000\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_interval_ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_resource.py:27\u001b[0m, in \u001b[0;36mSyncAPIResource._sleep\u001b[0;34m(self, seconds)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sleep\u001b[39m(\u001b[38;5;28mself\u001b[39m, seconds: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.beta.threads.message_create_params import (\n",
    "    Attachment,\n",
    "    AttachmentToolFileSearch,\n",
    ")\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Replace with your actual API key\n",
    "\n",
    "\n",
    "class PaperAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.assistant = None\n",
    "        self.thread = None\n",
    "        \n",
    "    def create_assistant(self):\n",
    "        self.assistant = self.client.beta.assistants.create(\n",
    "            model=\"gpt-4-turbo-preview\",\n",
    "            description=\"An assistant to analyze research papers and extract claims, evidence, and conclusions.\",\n",
    "            tools=[{\"type\": \"file_search\"}],\n",
    "            name=\"Research Paper Analyzer\"\n",
    "        )\n",
    "\n",
    "    def analyze_paper(self, filename):\n",
    "        # Create thread\n",
    "        self.thread = self.client.beta.threads.create()\n",
    "        \n",
    "        # Upload file\n",
    "        file = self.client.files.create(file=open(filename, \"rb\"), purpose=\"assistants\")\n",
    "        \n",
    "        # Analysis prompt\n",
    "        analysis_prompt = \"\"\"\n",
    "        Please analyze the research paper and provide the following information in JSON format:\n",
    "        1. Extract all claims made in the paper\n",
    "        2. For each claim, identify:\n",
    "           - The supporting evidence presented\n",
    "           - Whether the claim is adequately supported by evidence\n",
    "           - The authors' conclusions regarding the claim\n",
    "        3. Make sure that you don't miss any claims\n",
    "        \n",
    "Return ONLY the following JSON structure:\n",
    "        {\n",
    "            \"claims\": [\n",
    "                {\n",
    "                    \"claim\": \"statement of the claim\",\n",
    "                    \"evidence\": \"supporting evidence\",\n",
    "                    \"is_supported\": true/false,\n",
    "                    \"conclusion\": \"authors' conclusion\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        # Create message\n",
    "        self.client.beta.threads.messages.create(\n",
    "            thread_id=self.thread.id,\n",
    "            role=\"user\",\n",
    "            attachments=[\n",
    "                Attachment(\n",
    "                    file_id=file.id,\n",
    "                    tools=[AttachmentToolFileSearch(type=\"file_search\")]\n",
    "                )\n",
    "            ],\n",
    "            content=analysis_prompt\n",
    "        )\n",
    "\n",
    "        # Run analysis\n",
    "        run = self.client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=self.thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "            timeout=1000\n",
    "        )\n",
    "\n",
    "        if run.status != \"completed\":\n",
    "            raise Exception(\"Analysis failed:\", run.status)\n",
    "\n",
    "        # Get results\n",
    "        messages = list(self.client.beta.threads.messages.list(thread_id=self.thread.id))\n",
    "        analysis_result = messages[0].content[0].text.value\n",
    "        print(analysis_result)\n",
    "        return self._format_results(analysis_result)\n",
    "\n",
    "    def _format_results(self, analysis_result):\n",
    "        try:\n",
    "            # Try to extract JSON content from the text\n",
    "            # Find the first '{' and last '}' to extract the JSON portion\n",
    "            start_idx = analysis_result.find('{')\n",
    "            end_idx = analysis_result.rfind('}') + 1\n",
    "            \n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in the response\")\n",
    "                \n",
    "            json_str = analysis_result[start_idx:end_idx]\n",
    "            \n",
    "            # Clean the JSON string\n",
    "            # Remove any markdown formatting or extra characters\n",
    "            json_str = json_str.strip()\n",
    "            json_str = json_str.replace('\\n', '')\n",
    "            json_str = json_str.replace('```json', '')\n",
    "            json_str = json_str.replace('```', '')\n",
    "            \n",
    "            # Parse the cleaned JSON\n",
    "            results = json.loads(json_str)\n",
    "            \n",
    "            # Format and print results\n",
    "            print(\"\\n=== Paper Analysis Results ===\\n\")\n",
    "            \n",
    "            for idx, claim_data in enumerate(results['claims'], 1):\n",
    "                print(f\"Claim {idx}:\")\n",
    "                print(f\"Statement: {claim_data['claim']}\")\n",
    "                print(f\"Evidence: {claim_data['evidence']}\")\n",
    "                print(f\"Supported: {'Yes' if claim_data['is_supported'] else 'No'}\")\n",
    "                print(f\"Conclusion: {claim_data['conclusion']}\")\n",
    "                print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "                \n",
    "            return results\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {str(e)}\")\n",
    "            print(\"Raw response:\", analysis_result)\n",
    "            return None\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            print(\"Raw response:\", analysis_result)\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {str(e)}\")\n",
    "            print(\"Raw response:\", analysis_result)\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    # Initialize analyzer\n",
    "    # api_key = os.environ.get(\"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\")\n",
    "\n",
    "    api_key = \"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\"\n",
    "    analyzer = PaperAnalyzer(api_key)\n",
    "    analyzer.create_assistant()\n",
    "    \n",
    "    # Analyze paper\n",
    "    filename = \"2410.18764v1.pdf\"\n",
    "    try:\n",
    "        results = analyzer.analyze_paper(filename)\n",
    "        print(results)\n",
    "        # Save results to file\n",
    "        if results:\n",
    "            with open('analysis_results.json', 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "            print(\"Results have been saved to 'analysis_results.json'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing paper: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim once then for each claims get Evidence one by one and then for each pair get the Conclusion one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting claims...\n",
      "[Message(id='msg_xNXvErtgG9Wmf0c3LY0CXsr1', assistant_id='asst_rAb62R87rS7aMCejTSn19Kv3', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='```json\\n{\\n    \"claims\": [\\n        {\\n            \"claim_id\": 1,\\n            \"claim_text\": \"Constant Q Cepstral Coefficients significantly outperform Mel Frequency Cepstral Coefficients in classifying neurodegenerative disorders.\",\\n            \"location\": \"Abstract\",\\n            \"claim_type\": \"Result improvement\",\\n            \"exact_quote\": \"CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\"\\n        },\\n        {\\n            \"claim_id\": 2,\\n            \"claim_text\": \"CQCC features provide superior spectrotemporal resolution over traditional features for capturing fundamental frequency and its harmonics associated with neurodegenerative disorders.\",\\n            \"location\": \"Introduction\",\\n            \"claim_type\": \"Technical advancement\",\\n            \"exact_quote\": \"We propose the use of Constant Q Cepstral Coefficients (CQCC), which leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders.\"\\n        },\\n        {\\n            \"claim_id\": 3,\\n            \"claim_text\": \"This study is the first to utilize the form-invariance property of the CQT for multi neurodegenerative disorder classification and analysis on sustained vowel sounds.\",\\n            \"location\": \"Related Work\",\\n            \"claim_type\": \"Novelty of research\",\\n            \"exact_quote\": \"To the best of the authors’ knowledge, this is the first study of its kind on sustained vowel sounds for multi neurodegenerative disorder classification and analysis.\"\\n        }\\n    ]\\n}\\n```'), type='text')], created_at=1730930265, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_DuPwfeVpy5Y0ANgO018xyi6W', status=None, thread_id='thread_emv8Q8eYXCPkLGk2VgXaNNQi'), Message(id='msg_i1dusLKh4Dt7iOLuSXlyKxI3', assistant_id=None, attachments=[Attachment(file_id='file-Z81QUdxKZixgqHpCumnEzank', tools=[AttachmentToolAssistantToolsFileSearchTypeOnly(type='file_search')])], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='\\n        Please analyze the research paper and extract ALL possible claims made by the authors.\\n        Your task is to identify all statements in the text that meet the following criteria for a claim:\\n        1. Makes a specific, testable assertion about results, methods, or contributions\\n        2. Represents a novel finding, improvement, or advancement\\n        3. Presents a clear position or conclusion.\\n        4. Maximum of 3 claims only\\n\\n        Make sure to:\\n        1. Include both major and minor claims\\n        2. Don\\'t miss any claims\\n        3. Present each claim as a separate item\\n        \\n        Return ONLY the following JSON structure:\\n        ```{\\n            \"claims\": [\\n                {\\n                    \"claim_id\": 1,\\n                    \"claim_text\": \"statement of the claim\"\\n                    \"location\": \"section/paragraph where this claim appears\"\\n                    \"claim_type: \"Nature of the claim\" \\n                    \"exact_quote\": \"complete verbatim text containing the claim\"\\n                    \\n                }\\n            ]\\n        }```\\n        '), type='text')], created_at=1730930259, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_emv8Q8eYXCPkLGk2VgXaNNQi')]\n",
      "Analyzing evidence...\n",
      "[Message(id='msg_926bkiccDryF6MQwaK1BDZpc', assistant_id='asst_rAb62R87rS7aMCejTSn19Kv3', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='```json\\n{\\n    \"claim_id\": 1,\\n    \"evidence\": [\\n        {  \\n            \"evidence_id\": 1,\\n            \"evidence_text\": \"CQCC achieved the highest classification accuracy for binary classification of healthy vs. pathological speech, with RF classifier attaining a 99% accuracy, significantly higher than MFCC which achieved a 95.1% accuracy with RF.\",\\n            \"evidence_type\": \"primary\",\\n            \"strength\": \"strong\",\\n            \"limitations\": \"The results were specific to the datasets D1, D2, and D3, which might limit the generalizability of the findings.\",\\n            \"location\": \"Section 5.2.1 Overall Performance for Binary Classification & Table 4\",\\n            \"exact_quote\": \"Among the features analyzed, CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 95.1% accuracy achieved with MFCC.\"\\n        },\\n        {\\n            \"evidence_id\": 2,\\n            \"evidence_text\": \"For distinguishing between ALS and Parkinson\\'s patients, CQCC yielded the highest accuracy with SVM (86.1%) and consistently performed well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\",\\n            \"evidence_type\": \"primary\",\\n            \"strength\": \"strong\",\\n            \"limitations\": \"The analysis was conducted on specific datasets for ALS and Parkinson\\'s, and performance may vary with different datasets or conditions.\",\\n            \"location\": \"Section 5.2.2 Classification Between Different Pathologies & Table 6\",\\n            \"exact_quote\": \"CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\"\\n        }\\n    ]\\n}\\n```'), type='text')], created_at=1730930299, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_gAliyHGIhuGhLZHjDznSMDCO', status=None, thread_id='thread_vzeBhbIQNvSTlbm11JYQvasB'), Message(id='msg_28IVPNzT6j0WVWIHM6YQdG77', assistant_id=None, attachments=[Attachment(file_id='file-FWJvEtwEEWXYisN6PAyFWDNK', tools=[AttachmentToolAssistantToolsFileSearchTypeOnly(type='file_search')])], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='\\n            For the following claim from the paper:\\n            \"Constant Q Cepstral Coefficients significantly outperform Mel Frequency Cepstral Coefficients in classifying neurodegenerative disorders.\"\\n            \\n            Please:\\n\\n            For the given claim, identify relevant evidence that:\\n            1. Directly supports or contradicts the claim\\'s specific assertion\\n            2. Is presented with experimental results, data, or concrete examples\\n            3. Can be traced to specific methods, results, or discussion sections\\n            4. Is not from the abstract or introduction\\n\\n            For each piece of evidence:\\n            1. Extract the specific experimental results, metrics, or data points\\n            2. Evaluate the methodological rigor and statistical significance \\n            3. Note any stated limitations or assumptions\\n            4. Identify if it\\'s primary evidence (authors\\' own work) or secondary (cited work)\\n\\n            If NO evidence is found for the given Claim, return:\\n            ```{\\n                \"claim_id\": 1,\\n                \"evidence\": [],\\n                \"no_evidence_reason\": \"Explain why no evidence was found (e.g., \\'Claim is unsupported\\', \\'Claim is theoretical without empirical evidence\\', etc.)\"\\n            }```\\n                ELSE:\\n            Return ONLY the following JSON structure:\\n            ```{\\n                \"claim_id\": 1,\\n                \"evidence\": [\\n                    {  \\n                            \"evidence_id\": 1,\\n                            \"evidence_text\": \"specific experimental result/data point\",\\n                            \"evidence_type\": \"primary/secondary\",\\n                            \"strength\": \"strong/moderate/weak\",\\n                            \"limitations\": \"stated limitations or assumptions\",\\n                            \"location\": \"specific section & paragraph\",\\n                            \"exact_quote\": \"verbatim text from paper\"\\n\\n                    }\\n                ]\\n            }```\\n            '), type='text')], created_at=1730930287, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_vzeBhbIQNvSTlbm11JYQvasB')]\n",
      "[Message(id='msg_qjKznD9AqdmZ6PaEATdDynbh', assistant_id='asst_rAb62R87rS7aMCejTSn19Kv3', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='```json\\n{\\n    \"claim_id\": 2,\\n    \"evidence\": [\\n        {\\n            \"evidence_id\": 1,\\n            \"evidence_text\": \"CQCC achieved the highest classification accuracy in binary classification for healthy vs. pathological speech with Random Forest classifier reaching 99%, contrasting with 63.4% accuracy for Support Vector Machine classifier.\",\\n            \"evidence_type\": \"primary\",\\n            \"strength\": \"strong\",\\n            \"limitations\": \"Comparison limited to the classifiers RF and SVM, focusing on binary classification for a specific dataset (D2).\",\\n            \"location\": \"Experimental Results and Discussion section & Paragraph on Overall Performance for Binary Classification\",\\n            \"exact_quote\": \"Among the features analyzed, CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 63.4% accuracy achieved by the Support Vector Machine classifier.\"\\n        },\\n        {\\n            \"evidence_id\": 2,\\n            \"evidence_text\": \"In the classification between ALS and Parkinson\\'s patients, CQCC features outperformed MFCC, Jitter, Shimmer, and Teager Energy features, illustrating its superior capability in capturing nuanced differences in vocal characteristics associated with these diseases.\",\\n            \"evidence_type\": \"primary\",\\n            \"strength\": \"strong\",\\n            \"limitations\": \"Focuses on ALS and Parkinson’s, may not generalize to other neurodegenerative disorders. Only SVM and RF classifiers were tested.\",\\n            \"location\": \"Experimental Results and Discussion section & Paragraph on Classification Between Different Pathologies\",\\n            \"exact_quote\": \"CQCC yields the highest accuracy with SVM (86.1%)...indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\"\\n        }\\n    ]\\n}\\n```'), type='text')], created_at=1730930328, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_DlwA02eFh2hUm9II5KkFkzFd', status=None, thread_id='thread_jQE7ft1nXgCpTqeBSpTEMqGH'), Message(id='msg_jJbBJPOmL9nWdvBL6XcS1xms', assistant_id=None, attachments=[Attachment(file_id='file-FWJvEtwEEWXYisN6PAyFWDNK', tools=[AttachmentToolAssistantToolsFileSearchTypeOnly(type='file_search')])], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='\\n            For the following claim from the paper:\\n            \"CQCC features provide superior spectrotemporal resolution over traditional features for capturing fundamental frequency and its harmonics associated with neurodegenerative disorders.\"\\n            \\n            Please:\\n\\n            For the given claim, identify relevant evidence that:\\n            1. Directly supports or contradicts the claim\\'s specific assertion\\n            2. Is presented with experimental results, data, or concrete examples\\n            3. Can be traced to specific methods, results, or discussion sections\\n            4. Is not from the abstract or introduction\\n\\n            For each piece of evidence:\\n            1. Extract the specific experimental results, metrics, or data points\\n            2. Evaluate the methodological rigor and statistical significance \\n            3. Note any stated limitations or assumptions\\n            4. Identify if it\\'s primary evidence (authors\\' own work) or secondary (cited work)\\n\\n            If NO evidence is found for the given Claim, return:\\n            ```{\\n                \"claim_id\": 2,\\n                \"evidence\": [],\\n                \"no_evidence_reason\": \"Explain why no evidence was found (e.g., \\'Claim is unsupported\\', \\'Claim is theoretical without empirical evidence\\', etc.)\"\\n            }```\\n                ELSE:\\n            Return ONLY the following JSON structure:\\n            ```{\\n                \"claim_id\": 2,\\n                \"evidence\": [\\n                    {  \\n                            \"evidence_id\": 1,\\n                            \"evidence_text\": \"specific experimental result/data point\",\\n                            \"evidence_type\": \"primary/secondary\",\\n                            \"strength\": \"strong/moderate/weak\",\\n                            \"limitations\": \"stated limitations or assumptions\",\\n                            \"location\": \"specific section & paragraph\",\\n                            \"exact_quote\": \"verbatim text from paper\"\\n\\n                    }\\n                ]\\n            }```\\n            '), type='text')], created_at=1730930321, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_jQE7ft1nXgCpTqeBSpTEMqGH')]\n",
      "[Message(id='msg_jywiFYNZVQbOYnmBHwNVTbjS', assistant_id='asst_rAb62R87rS7aMCejTSn19Kv3', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='```json\\n{\\n    \"claim_id\": 3,\\n    \"evidence\": [\\n        {\\n            \"evidence_id\": 1,\\n            \"evidence_text\": \"CQCC outperforming MFCC, Jitter, Shimmer, and Teager Energy in classification accuracy for different neurodegenerative diseases.\",\\n            \"evidence_type\": \"primary\",\\n            \"strength\": \"strong\",\\n            \"limitations\": \"Limited by dataset size and diversity; primarily tested on Italian Parkinson’s and Minsk2019 ALS datasets.\",\\n            \"location\": \"Experimental Results and Discussion Section, Paragraphs on Overall Performance for Binary Classification & Classification Between Different Pathologies\",\\n            \"exact_quote\": \"Among the features analyzed, CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 63.4% accuracy achieved by the Support Vector Machine classifier. ... CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\"\\n        },\\n        {\\n            \"evidence_id\": 2,\\n            \"evidence_text\": \"The study utilized CQCC for capturing the form-invariance property in the frequency analysis of sustained vowel sounds for neurodegenerative disease classification.\",\\n            \"evidence_type\": \"primary\",\\n            \"strength\": \"strong\",\\n            \"limitations\": \"Specific to sustained vowel sounds and the particular types of neurodegenerative diseases explored in the study.\",\\n            \"location\": \"Methodology Section & Form-Invariance Property of CQT Subsection\",\\n            \"exact_quote\": \"The Constant-Q Transform (CQT) offers superior frequency resolution in lower frequency regions... making it a function of both time (m) and frequency (r), thereby leveraging the form-invariance property to enhance classification accuracy.\"\\n        }\\n    ]\\n}\\n```'), type='text')], created_at=1730930352, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_MuU9nPUurM5lwh44ORbZc98B', status=None, thread_id='thread_khusYnppOv9hU9lx7GQMSD2l'), Message(id='msg_kyxEyp9HfDdYJMqIrTfWpu5K', assistant_id=None, attachments=[Attachment(file_id='file-FWJvEtwEEWXYisN6PAyFWDNK', tools=[AttachmentToolAssistantToolsFileSearchTypeOnly(type='file_search')])], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='\\n            For the following claim from the paper:\\n            \"This study is the first to utilize the form-invariance property of the CQT for multi neurodegenerative disorder classification and analysis on sustained vowel sounds.\"\\n            \\n            Please:\\n\\n            For the given claim, identify relevant evidence that:\\n            1. Directly supports or contradicts the claim\\'s specific assertion\\n            2. Is presented with experimental results, data, or concrete examples\\n            3. Can be traced to specific methods, results, or discussion sections\\n            4. Is not from the abstract or introduction\\n\\n            For each piece of evidence:\\n            1. Extract the specific experimental results, metrics, or data points\\n            2. Evaluate the methodological rigor and statistical significance \\n            3. Note any stated limitations or assumptions\\n            4. Identify if it\\'s primary evidence (authors\\' own work) or secondary (cited work)\\n\\n            If NO evidence is found for the given Claim, return:\\n            ```{\\n                \"claim_id\": 3,\\n                \"evidence\": [],\\n                \"no_evidence_reason\": \"Explain why no evidence was found (e.g., \\'Claim is unsupported\\', \\'Claim is theoretical without empirical evidence\\', etc.)\"\\n            }```\\n                ELSE:\\n            Return ONLY the following JSON structure:\\n            ```{\\n                \"claim_id\": 3,\\n                \"evidence\": [\\n                    {  \\n                            \"evidence_id\": 1,\\n                            \"evidence_text\": \"specific experimental result/data point\",\\n                            \"evidence_type\": \"primary/secondary\",\\n                            \"strength\": \"strong/moderate/weak\",\\n                            \"limitations\": \"stated limitations or assumptions\",\\n                            \"location\": \"specific section & paragraph\",\\n                            \"exact_quote\": \"verbatim text from paper\"\\n\\n                    }\\n                ]\\n            }```\\n            '), type='text')], created_at=1730930345, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_khusYnppOv9hU9lx7GQMSD2l')]\n",
      "[{'claim_id': 1, 'evidence': [{'evidence_id': 1, 'evidence_text': 'CQCC achieved the highest classification accuracy for binary classification of healthy vs. pathological speech, with RF classifier attaining a 99% accuracy, significantly higher than MFCC which achieved a 95.1% accuracy with RF.', 'evidence_type': 'primary', 'strength': 'strong', 'limitations': 'The results were specific to the datasets D1, D2, and D3, which might limit the generalizability of the findings.', 'location': 'Section 5.2.1 Overall Performance for Binary Classification & Table 4', 'exact_quote': 'Among the features analyzed, CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 95.1% accuracy achieved with MFCC.'}, {'evidence_id': 2, 'evidence_text': \"For distinguishing between ALS and Parkinson's patients, CQCC yielded the highest accuracy with SVM (86.1%) and consistently performed well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\", 'evidence_type': 'primary', 'strength': 'strong', 'limitations': \"The analysis was conducted on specific datasets for ALS and Parkinson's, and performance may vary with different datasets or conditions.\", 'location': 'Section 5.2.2 Classification Between Different Pathologies & Table 6', 'exact_quote': 'CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.'}]}, {'claim_id': 2, 'evidence': [{'evidence_id': 1, 'evidence_text': 'CQCC achieved the highest classification accuracy in binary classification for healthy vs. pathological speech with Random Forest classifier reaching 99%, contrasting with 63.4% accuracy for Support Vector Machine classifier.', 'evidence_type': 'primary', 'strength': 'strong', 'limitations': 'Comparison limited to the classifiers RF and SVM, focusing on binary classification for a specific dataset (D2).', 'location': 'Experimental Results and Discussion section & Paragraph on Overall Performance for Binary Classification', 'exact_quote': 'Among the features analyzed, CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 63.4% accuracy achieved by the Support Vector Machine classifier.'}, {'evidence_id': 2, 'evidence_text': \"In the classification between ALS and Parkinson's patients, CQCC features outperformed MFCC, Jitter, Shimmer, and Teager Energy features, illustrating its superior capability in capturing nuanced differences in vocal characteristics associated with these diseases.\", 'evidence_type': 'primary', 'strength': 'strong', 'limitations': 'Focuses on ALS and Parkinson’s, may not generalize to other neurodegenerative disorders. Only SVM and RF classifiers were tested.', 'location': 'Experimental Results and Discussion section & Paragraph on Classification Between Different Pathologies', 'exact_quote': 'CQCC yields the highest accuracy with SVM (86.1%)...indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.'}]}, {'claim_id': 3, 'evidence': [{'evidence_id': 1, 'evidence_text': 'CQCC outperforming MFCC, Jitter, Shimmer, and Teager Energy in classification accuracy for different neurodegenerative diseases.', 'evidence_type': 'primary', 'strength': 'strong', 'limitations': 'Limited by dataset size and diversity; primarily tested on Italian Parkinson’s and Minsk2019 ALS datasets.', 'location': 'Experimental Results and Discussion Section, Paragraphs on Overall Performance for Binary Classification & Classification Between Different Pathologies', 'exact_quote': 'Among the features analyzed, CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 63.4% accuracy achieved by the Support Vector Machine classifier. ... CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.'}, {'evidence_id': 2, 'evidence_text': 'The study utilized CQCC for capturing the form-invariance property in the frequency analysis of sustained vowel sounds for neurodegenerative disease classification.', 'evidence_type': 'primary', 'strength': 'strong', 'limitations': 'Specific to sustained vowel sounds and the particular types of neurodegenerative diseases explored in the study.', 'location': 'Methodology Section & Form-Invariance Property of CQT Subsection', 'exact_quote': 'The Constant-Q Transform (CQT) offers superior frequency resolution in lower frequency regions... making it a function of both time (m) and frequency (r), thereby leveraging the form-invariance property to enhance classification accuracy.'}]}]\n",
      "Analyzing conclusions...\n",
      "[Message(id='msg_ngJXo69aNNtW7XxOkijZJT37', assistant_id='asst_rAb62R87rS7aMCejTSn19Kv3', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='To provide a detailed analysis based on the claims and evidence summaries provided, we\\'ll consider each claim separately, evaluating the evidence and drawing conclusions based on the guidelines.\\n\\n### Claim 1 Analysis\\n\\n- **Evidence Assessment**: The evidence provided for Claim 1 is strong, showing high classification accuracy of CQCC over MFCC using RF and SVM classifiers across different datasets. The methodology is reliable, focusing on specific datasets for binary classification and distinguishing between ALS and Parkinson\\'s disease.\\n- **Conclusion Analysis**: The authors likely concluded that CQCC features are more effective than MFCC in classifying neurodegenerative disorders based on the elevated accuracy ratings.\\n- **Robustness Evaluation**: The evidence is robust, showcasing consistent high performance across datasets and classification tasks. However, the focus on specific datasets and classifiers raises questions about broader applicability.\\n- **Limitations Analysis**: The major limitation is the specificity of the datasets and potential variability in results across different datasets or neurodegenerative conditions.\\n\\n### Claim 2 Analysis\\n\\n- **Evidence Assessment**: The evidence for Claim 2, though strong in demonstrating the superiority of CQCC for spectrotemporal analysis, is limited to comparisons between a few classifiers and focused on specific types of neurodegenerative disorders.\\n- **Conclusion Analysis**: The conclusion that CQCC provides superior spectrotemporal resolution over traditional features is well-supported by the evidence; however, it\\'s drawn from a narrow dataset and classifier focus.\\n- **Robustness Evaluation**: Methodologically, the evidence is strong but not diverse, leaning on specific cases and comparisons to illustrate broader claims.\\n- **Limitations Analysis**: The primary limitations here are the restricted focus on ALS and Parkinson’s and reliance on specific classifiers for demonstration, which could affect generalizability.\\n\\n### Claim 3 Analysis\\n\\n- **Evidence Assessment**: Evidence for Claim 3 is strong regarding CQCC’s performance but is constrained by the specificity of the sustained vowel sounds and the datasets used.\\n- **Conclusion Analysis**: The conclusion that the study is pioneering in using CQCC’s form-invariance property for this application is likely justified, given the distinct approach and findings reported.\\n- **Robustness Evaluation**: While strong within its scope, the evidence’s methodological diversity is narrow, relying on specific datasets and disease types, limiting broad applicability.\\n- **Limitations Analysis**: The evidence and conclusions are limited by dataset diversity and the scope of neurodegenerative disorders investigated, potentially affecting the claim’s strength outside these conditions.\\n\\nBased on these analyses, the following JSON summarizes the conclusions:\\n\\n```json\\n{\\n    \"conclusions\": [\\n        {\\n            \"claim_id\": 1,\\n            \"author_conclusion\": \"CQCC features significantly outperform MFCC in classifying neurodegenerative disorders, with higher classification accuracy.\",\\n            \"conclusion_justified\": true,\\n            \"justification_explanation\": \"High classification accuracies in comparative tests and consistent superiority over MFCC justify the conclusion.\",\\n            \"robustness_analysis\": \"Evidence shows high classification accuracy and consistency, although it’s based on specific datasets and conditions.\",\\n            \"limitations\": \"Specific to datasets D1, D2, D3, and may not generalize across all datasets or neurodegenerative disorders.\",\\n            \"location\": \"Abstract; Section 5.2.1; Table 4; Section 5.2.2; Table 6\",\\n            \"evidence_alignment\": \"Evidence directly supports the conclusion with high accuracies and comparative effectiveness.\",\\n            \"confidence_level\": \"high\"\\n        },\\n        {\\n            \"claim_id\": 2,\\n            \"author_conclusion\": \"CQCC offers superior spectrotemporal resolution for capturing fundamental frequency and harmonics in neurodegenerative disorders.\",\\n            \"conclusion_justified\": true,\\n            \"justification_explanation\": \"Deduced from high classification accuracies and detailed comparison against traditional features in specific contexts.\",\\n            \"robustness_analysis\": \"Evidence is strong within its scope but lacks broader methodological variety or dataset diversity.\",\\n            \"limitations\": \"Comparisons limited to RF and SVM classifiers, specific to binary classification and ALS vs. Parkinson\\'s.\",\\n            \"location\": \"Introduction; Experimental Results and Discussion\",\\n            \"evidence_alignment\": \"Evidence directly supports superior capabilities of CQCC in the highlighted applications.\",\\n            \"confidence_level\": \"medium\"\\n        },\\n        {\\n            \"claim_id\": 3,\\n            \"author_conclusion\": \"The study is the first to apply CQCC using the form-invariance property of CQT for multifaceted analysis of neurodegenerative disorders from sustained vowel sounds.\",\\n            \"conclusion_justified\": true,\\n            \"justification_explanation\": \"Unique application of CQCC for this specific purpose, with evidence proving outperformance over other features.\",\\n            \"robustness_analysis\": \"Specific and pioneering use case supported by detailed evidence, though limited by dataset and disease scope.\",\\n            \"limitations\": \"Findings are specific to sustained vowel sounds and examined diseases, limiting general applicability.\",\\n            \"location\": \"Related Work; Methodology\",\\n            \"evidence_alignment\": \"Evidence showcases successful application and distinct advantages in targeted classification tasks.\",\\n            \"confidence_level\": \"medium\"\\n        }\\n    ]\\n}\\n```\\n\\nThis analysis assesses the presented evidence, conclusions drawn, and considers both the strengths and limitations inherent in the research.'), type='text')], created_at=1730930380, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_nCe94g2yytQWNr79gBLAWyU3', status=None, thread_id='thread_V7IMSrI9bp4GcUVqR1l6BlfX'), Message(id='msg_C8EMT4PAzlR3aYzHDU0t3NFx', assistant_id=None, attachments=[Attachment(file_id='file-OsbC4vXJwh8zDivAMTfJPFEC', tools=[AttachmentToolAssistantToolsFileSearchTypeOnly(type='file_search')])], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='\\n        Analyze the following claims and their supporting evidence from the research paper:\\n\\n        \\nClaim 1:\\nStatement: Constant Q Cepstral Coefficients significantly outperform Mel Frequency Cepstral Coefficients in classifying neurodegenerative disorders.\\nLocation: Abstract\\n\\nEvidence Summary:\\n  Evidence 1:\\n    - Text: CQCC achieved the highest classification accuracy for binary classification of healthy vs. pathological speech, with RF classifier attaining a 99% accuracy, significantly higher than MFCC which achieved a 95.1% accuracy with RF.\\n    - Strength: strong\\n    - Limitations: The results were specific to the datasets D1, D2, and D3, which might limit the generalizability of the findings.\\n    - Location: Section 5.2.1 Overall Performance for Binary Classification & Table 4\\n  Evidence 2:\\n    - Text: For distinguishing between ALS and Parkinson\\'s patients, CQCC yielded the highest accuracy with SVM (86.1%) and consistently performed well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\\n    - Strength: strong\\n    - Limitations: The analysis was conducted on specific datasets for ALS and Parkinson\\'s, and performance may vary with different datasets or conditions.\\n    - Location: Section 5.2.2 Classification Between Different Pathologies & Table 6\\n\\nClaim 2:\\nStatement: CQCC features provide superior spectrotemporal resolution over traditional features for capturing fundamental frequency and its harmonics associated with neurodegenerative disorders.\\nLocation: Introduction\\n\\nEvidence Summary:\\n  Evidence 1:\\n    - Text: CQCC achieved the highest classification accuracy in binary classification for healthy vs. pathological speech with Random Forest classifier reaching 99%, contrasting with 63.4% accuracy for Support Vector Machine classifier.\\n    - Strength: strong\\n    - Limitations: Comparison limited to the classifiers RF and SVM, focusing on binary classification for a specific dataset (D2).\\n    - Location: Experimental Results and Discussion section & Paragraph on Overall Performance for Binary Classification\\n  Evidence 2:\\n    - Text: In the classification between ALS and Parkinson\\'s patients, CQCC features outperformed MFCC, Jitter, Shimmer, and Teager Energy features, illustrating its superior capability in capturing nuanced differences in vocal characteristics associated with these diseases.\\n    - Strength: strong\\n    - Limitations: Focuses on ALS and Parkinson’s, may not generalize to other neurodegenerative disorders. Only SVM and RF classifiers were tested.\\n    - Location: Experimental Results and Discussion section & Paragraph on Classification Between Different Pathologies\\n\\nClaim 3:\\nStatement: This study is the first to utilize the form-invariance property of the CQT for multi neurodegenerative disorder classification and analysis on sustained vowel sounds.\\nLocation: Related Work\\n\\nEvidence Summary:\\n  Evidence 1:\\n    - Text: CQCC outperforming MFCC, Jitter, Shimmer, and Teager Energy in classification accuracy for different neurodegenerative diseases.\\n    - Strength: strong\\n    - Limitations: Limited by dataset size and diversity; primarily tested on Italian Parkinson’s and Minsk2019 ALS datasets.\\n    - Location: Experimental Results and Discussion Section, Paragraphs on Overall Performance for Binary Classification & Classification Between Different Pathologies\\n  Evidence 2:\\n    - Text: The study utilized CQCC for capturing the form-invariance property in the frequency analysis of sustained vowel sounds for neurodegenerative disease classification.\\n    - Strength: strong\\n    - Limitations: Specific to sustained vowel sounds and the particular types of neurodegenerative diseases explored in the study.\\n    - Location: Methodology Section & Form-Invariance Property of CQT Subsection\\n\\n        For each claim, provide a comprehensive conclusion analysis following these guidelines:\\n\\n        1. Evidence Assessment:\\n        - Evaluate the strength and quality of ALL evidence presented\\n        - Consider both supporting and contradicting evidence\\n        - Assess the methodology and reliability of evidence\\n\\n        2. Conclusion Analysis:\\n        - Determine what the authors concluded about each claim\\n        - Evaluate if conclusions are justified by the evidence\\n        - Consider the relationship between evidence quality and conclusion strength\\n\\n        3. Robustness Evaluation:\\n        - Assess how well the evidence supports the conclusions\\n        - Consider methodological strengths and weaknesses\\n        - Evaluate the consistency of evidence across different sources\\n\\n        4. Limitations Analysis:\\n        - Identify specific limitations in both evidence and conclusions\\n        - Consider gaps in methodology or data\\n        - Note any potential biases or confounding factors\\n\\n        Return ONLY the following JSON structure:\\n        {\\n            \"conclusions\": [\\n                {\\n                    \"claim_id\": number,\\n                    \"author_conclusion\": \"detailed description of authors\\' conclusion based on evidence\",\\n                    \"conclusion_justified\": true/false,\\n                    \"justification_explanation\": \"detailed explanation of why conclusion is/isn\\'t justified\",\\n                    \"robustness_analysis\": \"comprehensive analysis of evidence strength and reliability\",\\n                    \"limitations\": \"specific limitations and caveats\",\\n                    \"location\": \"section/paragraph where conclusion appears\",\\n                    \"evidence_alignment\": \"analysis of how well evidence aligns with conclusion\",\\n                    \"confidence_level\": \"high/medium/low based on evidence quality\",\\n                }\\n            ]\\n        }\\n        '), type='text')], created_at=1730930373, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_V7IMSrI9bp4GcUVqR1l6BlfX')]\n",
      "\n",
      "=== Complete Paper Analysis ===\n",
      "\n",
      "Claim 1:\n",
      "Statement: Constant Q Cepstral Coefficients significantly outperform Mel Frequency Cepstral Coefficients in classifying neurodegenerative disorders.\n",
      "\n",
      "Evidence:\n",
      "- CQCC achieved the highest classification accuracy for binary classification of healthy vs. pathological speech, with RF classifier attaining a 99% accuracy, significantly higher than MFCC which achieved a 95.1% accuracy with RF.\n",
      "  Strength: strong\n",
      "  Limitations: The results were specific to the datasets D1, D2, and D3, which might limit the generalizability of the findings.\n",
      "- For distinguishing between ALS and Parkinson's patients, CQCC yielded the highest accuracy with SVM (86.1%) and consistently performed well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\n",
      "  Strength: strong\n",
      "  Limitations: The analysis was conducted on specific datasets for ALS and Parkinson's, and performance may vary with different datasets or conditions.\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC features significantly outperform MFCC in classifying neurodegenerative disorders, with higher classification accuracy.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: Evidence shows high classification accuracy and consistency, although it’s based on specific datasets and conditions.\n",
      "Limitations: Specific to datasets D1, D2, D3, and may not generalize across all datasets or neurodegenerative disorders.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 2:\n",
      "Statement: CQCC features provide superior spectrotemporal resolution over traditional features for capturing fundamental frequency and its harmonics associated with neurodegenerative disorders.\n",
      "\n",
      "Evidence:\n",
      "- CQCC achieved the highest classification accuracy in binary classification for healthy vs. pathological speech with Random Forest classifier reaching 99%, contrasting with 63.4% accuracy for Support Vector Machine classifier.\n",
      "  Strength: strong\n",
      "  Limitations: Comparison limited to the classifiers RF and SVM, focusing on binary classification for a specific dataset (D2).\n",
      "- In the classification between ALS and Parkinson's patients, CQCC features outperformed MFCC, Jitter, Shimmer, and Teager Energy features, illustrating its superior capability in capturing nuanced differences in vocal characteristics associated with these diseases.\n",
      "  Strength: strong\n",
      "  Limitations: Focuses on ALS and Parkinson’s, may not generalize to other neurodegenerative disorders. Only SVM and RF classifiers were tested.\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC offers superior spectrotemporal resolution for capturing fundamental frequency and harmonics in neurodegenerative disorders.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: Evidence is strong within its scope but lacks broader methodological variety or dataset diversity.\n",
      "Limitations: Comparisons limited to RF and SVM classifiers, specific to binary classification and ALS vs. Parkinson's.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 3:\n",
      "Statement: This study is the first to utilize the form-invariance property of the CQT for multi neurodegenerative disorder classification and analysis on sustained vowel sounds.\n",
      "\n",
      "Evidence:\n",
      "- CQCC outperforming MFCC, Jitter, Shimmer, and Teager Energy in classification accuracy for different neurodegenerative diseases.\n",
      "  Strength: strong\n",
      "  Limitations: Limited by dataset size and diversity; primarily tested on Italian Parkinson’s and Minsk2019 ALS datasets.\n",
      "- The study utilized CQCC for capturing the form-invariance property in the frequency analysis of sustained vowel sounds for neurodegenerative disease classification.\n",
      "  Strength: strong\n",
      "  Limitations: Specific to sustained vowel sounds and the particular types of neurodegenerative diseases explored in the study.\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: The study is the first to apply CQCC using the form-invariance property of CQT for multifaceted analysis of neurodegenerative disorders from sustained vowel sounds.\n",
      "Justified by Evidence: Yes\n",
      "Robustness: Specific and pioneering use case supported by detailed evidence, though limited by dataset and disease scope.\n",
      "Limitations: Findings are specific to sustained vowel sounds and examined diseases, limiting general applicability.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Results have been saved to 'detailed_analysis_results.json'\n",
      "Intermediate results saved to 'intermediate_results.json'\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.beta.threads.message_create_params import (\n",
    "    Attachment,\n",
    "    AttachmentToolFileSearch,\n",
    ")\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import datetime\n",
    "\n",
    "## openreview scrape\n",
    "\n",
    "\n",
    "class PaperAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.assistant = None\n",
    "        # self.thread = None\n",
    "        \n",
    "    def create_assistant(self):\n",
    "        self.assistant = self.client.beta.assistants.create(\n",
    "            model=\"gpt-4-turbo-preview\",\n",
    "            description=\"An assistant to analyze research papers and extract claims, evidence, and conclusions.\",\n",
    "            tools=[{\"type\": \"file_search\"}],\n",
    "            name=\"Research Paper Analyzer\"\n",
    "        )\n",
    "\n",
    "    def get_claims(self, filename):\n",
    "        \"\"\"Extract all claims from the paper\"\"\"\n",
    "        # self.thread = self.client.beta.threads.create()\n",
    "        file = self.client.files.create(file=open(filename, \"rb\"), purpose=\"assistants\")\n",
    "\n",
    "        #constraint the claim types: to work on. \n",
    "        # one-shot prompting\n",
    "        \n",
    "        claims_prompt = \"\"\" \n",
    "        Please analyze the research paper and extract ALL possible claims made by the authors.\n",
    "        Your task is to identify all statements in the text that meet the following criteria for a claim:\n",
    "        1. Makes a specific, testable assertion about results, methods, or contributions\n",
    "        2. Represents a novel finding, improvement, or advancement\n",
    "        3. Presents a clear position or conclusion.\n",
    "        4. Maximum of 3 claims only\n",
    "\n",
    "        Make sure to:\n",
    "        1. Include both major and minor claims\n",
    "        2. Don't miss any claims\n",
    "        3. Present each claim as a separate item\n",
    "        \n",
    "        Return ONLY the following JSON structure:\n",
    "        ```{\n",
    "            \"claims\": [\n",
    "                {\n",
    "                    \"claim_id\": 1,\n",
    "                    \"claim_text\": \"statement of the claim\"\n",
    "                    \"location\": \"section/paragraph where this claim appears\"\n",
    "                    \"claim_type: \"Nature of the claim\" \n",
    "                    \"exact_quote\": \"complete verbatim text containing the claim\"\n",
    "                    \n",
    "                }\n",
    "            ]\n",
    "        }```\n",
    "        \"\"\"\n",
    "                            # \"Exact_claim_text\": \"Exact text from the document as it is\"\n",
    "# \n",
    "        return self._execute_analysis(None, file.id, claims_prompt)\n",
    "\n",
    "    def analyze_evidence(self, filename, claims):\n",
    "        \"\"\"Find evidence for each claim\"\"\"\n",
    "        # self.thread = self.client.beta.threads.create()\n",
    "        file = self.client.files.create(file=open(filename, \"rb\"), purpose=\"assistants\")\n",
    "        \n",
    "        evidence_results = []\n",
    "        for claim in claims['claims']:\n",
    "            evidence_prompt = f\"\"\"\n",
    "            For the following claim from the paper:\n",
    "            \"{claim['claim_text']}\"\n",
    "            \n",
    "            Please:\n",
    "\n",
    "            For the given claim, identify relevant evidence that:\n",
    "            1. Directly supports or contradicts the claim's specific assertion\n",
    "            2. Is presented with experimental results, data, or concrete examples\n",
    "            3. Can be traced to specific methods, results, or discussion sections\n",
    "            4. Is not from the abstract or introduction\n",
    "\n",
    "            For each piece of evidence:\n",
    "            1. Extract the specific experimental results, metrics, or data points\n",
    "            2. Evaluate the methodological rigor and statistical significance \n",
    "            3. Note any stated limitations or assumptions\n",
    "            4. Identify if it's primary evidence (authors' own work) or secondary (cited work)\n",
    "\n",
    "            If NO evidence is found for the given Claim, return:\n",
    "            ```{{\n",
    "                \"claim_id\": {claim['claim_id']},\n",
    "                \"evidence\": [],\n",
    "                \"no_evidence_reason\": \"Explain why no evidence was found (e.g., 'Claim is unsupported', 'Claim is theoretical without empirical evidence', etc.)\"\n",
    "            }}```\n",
    "                ELSE:\n",
    "            Return ONLY the following JSON structure:\n",
    "            ```{{\n",
    "                \"claim_id\": {claim['claim_id']},\n",
    "                \"evidence\": [\n",
    "                    {{  \n",
    "                            \"evidence_id\": 1,\n",
    "                            \"evidence_text\": \"specific experimental result/data point\",\n",
    "                            \"evidence_type\": \"primary/secondary\",\n",
    "                            \"strength\": \"strong/moderate/weak\",\n",
    "                            \"limitations\": \"stated limitations or assumptions\",\n",
    "                            \"location\": \"specific section & paragraph\",\n",
    "                            \"exact_quote\": \"verbatim text from paper\"\n",
    "\n",
    "                    }}\n",
    "                ]\n",
    "            }}```\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "                                    # \"Exact_evidence_text\": \"Exact text from the document as it is\"\n",
    "            result = self._execute_analysis(None, file.id, evidence_prompt)\n",
    "            if result:\n",
    "                evidence_results.append(result)\n",
    "                \n",
    "        return evidence_results\n",
    "\n",
    "\n",
    "    def analyze_conclusions(self, filename, claims, evidence_results):\n",
    "        \"\"\"\n",
    "        Analyze final decisions and conclusions by considering both claims and their evidence\n",
    "        \n",
    "        Args:\n",
    "            filename: PDF file to analyze\n",
    "            claims: Dictionary containing claims data\n",
    "            evidence_results: List of dictionaries containing evidence for each claim\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing structured conclusions\n",
    "        \"\"\"\n",
    "        # self.thread = self.client.beta.threads.create()\n",
    "        file = self.client.files.create(file=open(filename, \"rb\"), purpose=\"assistants\")\n",
    "        \n",
    "        # Build comprehensive analysis summary\n",
    "        def build_evidence_summary(claim_id):\n",
    "            \"\"\"Helper function to build evidence summary for a claim\"\"\"\n",
    "            claim_evidence = next((e['evidence'] for e in evidence_results if e.get('claim_id') == claim_id), [])\n",
    "            evidence_text = []\n",
    "            for idx, evidence in enumerate(claim_evidence, 1):\n",
    "                evidence_text.append(\n",
    "                    f\"  Evidence {idx}:\\n\"\n",
    "                    f\"    - Text: {evidence.get('evidence_text', 'No text provided')}\\n\"\n",
    "                    f\"    - Strength: {evidence.get('strength', 'Not specified')}\\n\"\n",
    "                    f\"    - Limitations: {evidence.get('limitations', 'None specified')}\\n\"\n",
    "                    f\"    - Location: {evidence.get('location', 'Location not specified')}\"\n",
    "                )\n",
    "            return \"\\n\".join(evidence_text)\n",
    "\n",
    "        # Create comprehensive analysis summary\n",
    "        analysis_sections = []\n",
    "        for claim in claims.get('claims', []):\n",
    "            claim_id = claim.get('claim_id')\n",
    "            claim_section = (\n",
    "                f\"\\nClaim {claim_id}:\\n\"\n",
    "                f\"Statement: {claim.get('claim_text', 'No text provided')}\\n\"\n",
    "                f\"Location: {claim.get('location', 'Location not specified')}\\n\"\n",
    "                f\"\\nEvidence Summary:\\n{build_evidence_summary(claim_id)}\"\n",
    "            )\n",
    "            analysis_sections.append(claim_section)\n",
    "\n",
    "        full_analysis = \"\\n\".join(analysis_sections)\n",
    "\n",
    "        # Create detailed prompt incorporating claims and evidence\n",
    "        conclusions_prompt = f\"\"\"\n",
    "        Analyze the following claims and their supporting evidence from the research paper:\n",
    "\n",
    "        {full_analysis}\n",
    "\n",
    "        For each claim, provide a comprehensive conclusion analysis following these guidelines:\n",
    "\n",
    "        1. Evidence Assessment:\n",
    "        - Evaluate the strength and quality of ALL evidence presented\n",
    "        - Consider both supporting and contradicting evidence\n",
    "        - Assess the methodology and reliability of evidence\n",
    "\n",
    "        2. Conclusion Analysis:\n",
    "        - Determine what the authors concluded about each claim\n",
    "        - Evaluate if conclusions are justified by the evidence\n",
    "        - Consider the relationship between evidence quality and conclusion strength\n",
    "\n",
    "        3. Robustness Evaluation:\n",
    "        - Assess how well the evidence supports the conclusions\n",
    "        - Consider methodological strengths and weaknesses\n",
    "        - Evaluate the consistency of evidence across different sources\n",
    "\n",
    "        4. Limitations Analysis:\n",
    "        - Identify specific limitations in both evidence and conclusions\n",
    "        - Consider gaps in methodology or data\n",
    "        - Note any potential biases or confounding factors\n",
    "\n",
    "        Return ONLY the following JSON structure:\n",
    "        {{\n",
    "            \"conclusions\": [\n",
    "                {{\n",
    "                    \"claim_id\": number,\n",
    "                    \"author_conclusion\": \"detailed description of authors' conclusion based on evidence\",\n",
    "                    \"conclusion_justified\": true/false,\n",
    "                    \"justification_explanation\": \"detailed explanation of why conclusion is/isn't justified\",\n",
    "                    \"robustness_analysis\": \"comprehensive analysis of evidence strength and reliability\",\n",
    "                    \"limitations\": \"specific limitations and caveats\",\n",
    "                    \"location\": \"section/paragraph where conclusion appears\",\n",
    "                    \"evidence_alignment\": \"analysis of how well evidence aligns with conclusion\",\n",
    "                    \"confidence_level\": \"high/medium/low based on evidence quality\",\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute analysis\n",
    "        result = self._execute_analysis(None, file.id, conclusions_prompt)\n",
    "\n",
    "        # Validate and process results\n",
    "        if not result or not isinstance(result, dict) or 'conclusions' not in result:\n",
    "            print(\"Warning: Invalid conclusions format received\")\n",
    "            return {\"conclusions\": []}\n",
    "\n",
    "        # Ensure complete coverage of all claims\n",
    "        all_conclusions = result.get('conclusions', [])\n",
    "        claims_ids = set(claim['claim_id'] for claim in claims.get('claims', []))\n",
    "        \n",
    "        # Create complete conclusions list with defaults for missing entries\n",
    "        complete_conclusions = []\n",
    "        for claim_id in claims_ids:\n",
    "            existing_conclusion = next(\n",
    "                (c for c in all_conclusions if c.get('claim_id') == claim_id),\n",
    "                None\n",
    "            )\n",
    "            \n",
    "            if existing_conclusion:\n",
    "                complete_conclusions.append(existing_conclusion)\n",
    "            else:\n",
    "                # Default structure for missing conclusions\n",
    "                complete_conclusions.append({\n",
    "                    \"claim_id\": claim_id,\n",
    "                    \"author_conclusion\": \"No conclusion available\",\n",
    "                    \"conclusion_justified\": False,\n",
    "                    \"justification_explanation\": \"Analysis not available\",\n",
    "                    \"robustness_analysis\": \"No robustness analysis available\",\n",
    "                    \"limitations\": \"No limitations analysis available\",\n",
    "                    \"location\": \"Location not specified\",\n",
    "                    \"evidence_alignment\": \"No alignment analysis available\",\n",
    "                    \"confidence_level\": \"low\",\n",
    "                    \"distance_between_claim_and_evidence\": []\n",
    "                })\n",
    "\n",
    "        return {\n",
    "            \"conclusions\": complete_conclusions,\n",
    "            \"analysis_metadata\": {\n",
    "                \"total_claims_analyzed\": len(claims_ids),\n",
    "                \"claims_with_conclusions\": len(all_conclusions),\n",
    "                \"analysis_timestamp\": str(datetime.datetime.now())\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    def _execute_analysis(self, thread_id, file_id, prompt):\n",
    "        \"\"\"Execute analysis with given prompt and return results\"\"\"\n",
    "        # Create a new thread for each analysis\n",
    "        thread = self.client.beta.threads.create()\n",
    "        \n",
    "        # Create message\n",
    "        self.client.beta.threads.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            attachments=[\n",
    "                Attachment(\n",
    "                    file_id=file_id,\n",
    "                    tools=[AttachmentToolFileSearch(type=\"file_search\")]\n",
    "                )\n",
    "            ],\n",
    "            content=prompt\n",
    "        )\n",
    "\n",
    "        # Run analysis\n",
    "        run = self.client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "            timeout=5000\n",
    "        )\n",
    "\n",
    "        if run.status != \"completed\":\n",
    "            raise Exception(\"Analysis failed:\", run.status)\n",
    "\n",
    "        # Get messages\n",
    "        messages = list(self.client.beta.threads.messages.list(thread_id=thread.id))\n",
    "        print(messages)\n",
    "        \n",
    "        # Clean up\n",
    "        try:\n",
    "            self.client.beta.threads.delete(thread.id)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting thread: {e}\")\n",
    "            \n",
    "        return self._parse_json_response(messages[0].content[0].text.value)\n",
    "\n",
    "    def _parse_json_response(self, response):\n",
    "        \"\"\"Parse JSON response and handle errors\"\"\"\n",
    "        try:\n",
    "            # Look for JSON content between curly braces\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in response\")\n",
    "                \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            return json.loads(json_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {e}\")\n",
    "            print(\"Raw response:\", response)\n",
    "            return None\n",
    "\n",
    "\n",
    "    def combine_results(self, claims, evidence_results, conclusions):\n",
    "        \"\"\"Combine all analysis results into a final structured format\"\"\"\n",
    "        final_results = {\n",
    "            \"paper_analysis\": []\n",
    "        }\n",
    "        \n",
    "        # Get conclusions dict\n",
    "        conclusions_dict = {\n",
    "            c['claim_id']: c \n",
    "            for c in conclusions.get('conclusions', [])\n",
    "        } if conclusions else {}\n",
    "        \n",
    "        # Get evidence dict\n",
    "        evidence_dict = {\n",
    "            e['claim_id']: e.get('evidence', [])\n",
    "            for e in evidence_results if isinstance(e, dict)\n",
    "        }\n",
    "        \n",
    "        for claim in claims.get('claims', []):\n",
    "            claim_id = claim['claim_id']\n",
    "            conclusion = conclusions_dict.get(claim_id, {})\n",
    "            evidence = evidence_dict.get(claim_id, [])\n",
    "            \n",
    "            analysis = {\n",
    "                \"claim_id\": claim_id,\n",
    "                \"claim\": claim.get('claim_text', ''),\n",
    "                \"claim_location\": claim.get('location', 'Location not specified'),  # Add claim location\n",
    "                \"evidence\": evidence,\n",
    "                \"evidence_locations\": [ev.get('location', 'Location not specified') for ev in evidence],  # Add evidence locations\n",
    "                \"conclusion\": {\n",
    "                    \"author_conclusion\": conclusion.get('author_conclusion', 'No conclusion available'),\n",
    "                    \"conclusion_justified\": conclusion.get('conclusion_justified', False),\n",
    "                    \"robustness_analysis\": conclusion.get('robustness_analysis', 'No robustness analysis available'),\n",
    "                    \"limitations\": conclusion.get('limitations', 'No limitations analysis available'),\n",
    "                    \"conclusion_location\": conclusion.get('location', 'Location not specified')  # Add conclusion location\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            final_results['paper_analysis'].append(analysis)\n",
    "        \n",
    "        return final_results\n",
    "\n",
    "    def print_analysis_results(self, final_results):\n",
    "        \"\"\"Print the analysis results in a readable format\"\"\"\n",
    "        print(\"\\n=== Complete Paper Analysis ===\\n\")\n",
    "        \n",
    "        for analysis in final_results['paper_analysis']:\n",
    "            print(f\"Claim {analysis['claim_id']}:\")\n",
    "            print(f\"Statement: {analysis['claim']}\")\n",
    "            print(\"\\nEvidence:\")\n",
    "            for evidence in analysis['evidence']:\n",
    "                print(f\"- {evidence['evidence_text']}\")\n",
    "                print(f\"  Strength: {evidence['strength']}\")\n",
    "                print(f\"  Limitations: {evidence['limitations']}\")\n",
    "            \n",
    "            print(\"\\nConclusion:\")\n",
    "            print(f\"Author's Conclusion: {analysis['conclusion']['author_conclusion']}\")\n",
    "            print(f\"Justified by Evidence: {'Yes' if analysis['conclusion']['conclusion_justified'] else 'No'}\")\n",
    "            print(f\"Robustness: {analysis['conclusion']['robustness_analysis']}\")\n",
    "            print(f\"Limitations: {analysis['conclusion']['limitations']}\")\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "def main():\n",
    "    # Initialize analyzer\n",
    "    openai.api_key = \"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\"\n",
    "    # api_key = \"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\"\n",
    "    analyzer = PaperAnalyzer(openai.api_key)\n",
    "    analyzer.create_assistant()\n",
    "    \n",
    "    # Analyze paper\n",
    "    filename = \"ICLR_1.pdf\"\n",
    "    try:\n",
    "        # Step 1: Extract claims\n",
    "        print(\"Extracting claims...\")\n",
    "        claims = analyzer.get_claims(filename)\n",
    "\n",
    "        #noise-addition code using some model or human.\n",
    "        #without noise-addition.\n",
    "        \n",
    "        # Step 2: Analyze evidence for each claim\n",
    "        print(\"Analyzing evidence...\")\n",
    "        evidence_results = analyzer.analyze_evidence(filename, claims)\n",
    "        print(evidence_results)\n",
    "        \n",
    "        #noise-addition code using some model or human.\n",
    "        #without noise-addition.\n",
    "\n",
    "        # Step 3: Analyze conclusions\n",
    "        print(\"Analyzing conclusions...\")\n",
    "        conclusions = analyzer.analyze_conclusions(filename, claims, evidence_results)\n",
    "        \n",
    "        # Combine all results\n",
    "        final_results = analyzer.combine_results(claims, evidence_results, conclusions)\n",
    "        \n",
    "        # Print results\n",
    "        analyzer.print_analysis_results(final_results)\n",
    "        \n",
    "        # Save results to file\n",
    "        with open('detailed_analysis_results.json', 'w') as f:\n",
    "            json.dump(final_results, f, indent=4)\n",
    "        print(\"Results have been saved to 'detailed_analysis_results.json'\")\n",
    "        \n",
    "        # Save intermediate results for reference\n",
    "        intermediate_results = {\n",
    "            \"claims\": claims,\n",
    "            \"evidence\": evidence_results,\n",
    "            \"conclusions\": conclusions\n",
    "        }\n",
    "        with open('intermediate_results.json', 'w') as f:\n",
    "            json.dump(intermediate_results, f, indent=4)\n",
    "        print(\"Intermediate results saved to 'intermediate_results.json'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing paper: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim, Evidence and Conclusion all at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing paper...\n",
      "\n",
      "=== Paper Analysis Results ===\n",
      "\n",
      "Claim 1:\n",
      "Type: performance\n",
      "Statement: Constant Q Cepstral Coefficients (CQCC) significantly outperform Mel Frequency Cepstral Coefficients (MFCC) in the classification of neurodegenerative disorders.\n",
      "Location: Conclusions/paragraph 1\n",
      "Exact Quote: CQCCs emerged as the most effective feature, achieving the highest accuracy in classification tasks.\n",
      "\n",
      "Evidence:\n",
      "- Evidence Text: CQCC achieved the highest classification accuracy of 99.0% using Random Forest and 80.7% with SVM, demonstrating superior performance over MFCC and other traditional acoustic measures.\n",
      "  Strength: strong\n",
      "  Location: Experimental Results and Discussion/paragraph 3\n",
      "  Limitations: Results specific to the data sets used and may not generalize across all neurodegenerative disorders or vocal datasets.\n",
      "  Exact Quote: Among the features analyzed, CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 63.4% accuracy achieved by the Support Vector Machine classifier.\n",
      "- Evidence Text: CQCC features lead to clearer class separability in LDA plots compared to MFCC, indicating more robust feature set for classification tasks.\n",
      "  Strength: strong\n",
      "  Location: Feature Visualization using LDA plots/paragraph 2\n",
      "  Limitations: Visualization-based evidence, may need further statistical analysis to quantify differences conclusively.\n",
      "  Exact Quote: The LDA plot of CQCC features exhibits a clearer separation, especially between the ALS and Parkinson’s disease classes.\n",
      "\n",
      "Evaluation:\n",
      "Conclusion Justified: Yes\n",
      "Robustness: high\n",
      "Confidence Level: high\n",
      "Justification: Supported by quantitative results in classification accuracy improvements and qualitative improvements in feature visualization.\n",
      "Key Limitations: Need for external validation on different datasets; evidence from specific classifiers might not generalize.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 2:\n",
      "Type: methodology\n",
      "Statement: CQCC provides a superior spectrotemporal resolution which is critical for capturing essential speech signal characteristics related to neurodegenerative disorders.\n",
      "Location: Abstract\n",
      "Exact Quote: leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution\n",
      "\n",
      "Evidence:\n",
      "- Evidence Text: The design of CQCC through the use of the Constant Q Transform allows for the geometric spacing of frequency bins, enhancing the ability to capture the fundamental frequency and its harmonics.\n",
      "  Strength: moderate\n",
      "  Location: Methodology/paragraph 2\n",
      "  Limitations: Theoretical improvement, actual impact may depend on the specificities of the speech signal and pathology.\n",
      "  Exact Quote: The Constant-Q Transform (CQT) offers superior frequency resolution in lower frequency regions... leading to geometrically spaced frequency bins.\n",
      "\n",
      "Evaluation:\n",
      "Conclusion Justified: Yes\n",
      "Robustness: medium\n",
      "Confidence Level: medium\n",
      "Justification: The underlying theory of CQCC design supports the claim but would benefit from direct experimental comparisons to other feature extraction methods.\n",
      "Key Limitations: Lacks comparative analysis with alternative feature extraction methods which may offer similar benefits.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Analysis results saved to analysis_outputs:\n",
      "- Full analysis: analysis_outputs/ICLR_1_analysis.json\n",
      "- Summary: analysis_outputs/ICLR_1_summary.txt\n",
      "- Statistics: analysis_outputs/ICLR_1_statistics.txt\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.beta.threads.message_create_params import (\n",
    "    Attachment,\n",
    "    AttachmentToolFileSearch,\n",
    ")\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class SinglePassPaperAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.assistant = None\n",
    "        \n",
    "    def create_assistant(self):\n",
    "        self.assistant = self.client.beta.assistants.create(\n",
    "            model=\"gpt-4-turbo-preview\",\n",
    "            description=\"Assistant for comprehensive research paper analysis\",\n",
    "            tools=[{\"type\": \"file_search\"}],\n",
    "            name=\"Research Paper Analyzer\"\n",
    "        )\n",
    "\n",
    "    def analyze_paper(self, filename):\n",
    "        # thread = self.client.beta.threads.create()\n",
    "        file = self.client.files.create(file=open(filename, \"rb\"), purpose=\"assistants\")\n",
    "        \n",
    "        comprehensive_prompt = \"\"\"\n",
    "        Analyze the research paper and provide a comprehensive evaluation following these guidelines:\n",
    "\n",
    "        1. Identify ALL claims in the paper where each claim:\n",
    "           - Makes a specific, verifiable assertion\n",
    "           - Is supported by concrete evidence\n",
    "           - Represents findings, contributions, or methodological advantages\n",
    "           - Can be from any section except abstract\n",
    "\n",
    "        2. For each identified claim:\n",
    "           - Extract ALL supporting evidence (experimental results, data, or methodology)\n",
    "           - Evaluate the evidence strength and limitations\n",
    "           - Assess how well conclusions align with evidence\n",
    "\n",
    "        Return ONLY the following JSON structure:\n",
    "        {\n",
    "            \"analysis\": [\n",
    "                {\n",
    "                    \"claim_id\": number,\n",
    "                    \"claim\": {\n",
    "                        \"text\": \"statement of the claim\",\n",
    "                        \"type\": \"methodology/result/contribution/performance\",\n",
    "                        \"location\": \"section/paragraph\",\n",
    "                        \"exact_quote\": \"verbatim text from paper\"\n",
    "                    },\n",
    "                    \"evidence\": [\n",
    "                        {\n",
    "                            \"evidence_text\": \"specific experimental result/data\",\n",
    "                            \"strength\": \"strong/moderate/weak\",\n",
    "                            \"limitations\": \"specific limitations\",\n",
    "                            \"location\": \"section/paragraph\",\n",
    "                            \"exact_quote\": \"verbatim text from paper\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"evaluation\": {\n",
    "                        \"conclusion_justified\": true/false,\n",
    "                        \"robustness\": \"high/medium/low\",\n",
    "                        \"justification\": \"explanation of evidence-conclusion alignment\",\n",
    "                        \"key_limitations\": \"critical limitations affecting validity\",\n",
    "                        \"confidence_level\": \"high/medium/low\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        Ensure:\n",
    "        - ALL substantive claims are captured\n",
    "        - Each claim has specific, verifiable evidence\n",
    "        - Evidence directly relates to its claim\n",
    "        - Evaluations are objective and well-reasoned\n",
    "        - All locations and quotes are precise\n",
    "        - Multiple pieces of evidence per claim are included when present\n",
    "        \"\"\"\n",
    "        \n",
    "        return self._execute_analysis(None, file.id, comprehensive_prompt)\n",
    "\n",
    "    def _execute_analysis(self, thread_id, file_id, prompt):\n",
    "        \"\"\"Execute the analysis and return results\"\"\"\n",
    "        self.client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            attachments=[\n",
    "                Attachment(\n",
    "                    file_id=file_id,\n",
    "                    tools=[AttachmentToolFileSearch(type=\"file_search\")]\n",
    "                )\n",
    "            ],\n",
    "            content=prompt\n",
    "        )\n",
    "\n",
    "        run = self.client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread_id,\n",
    "            assistant_id=self.assistant.id,\n",
    "            timeout=5000\n",
    "        )\n",
    "\n",
    "        if run.status != \"completed\":\n",
    "            raise Exception(f\"Analysis failed: {run.status}\")\n",
    "\n",
    "        messages = list(self.client.beta.threads.messages.list(thread_id=thread_id))\n",
    "        return self._parse_json_response(messages[0].content[0].text.value)\n",
    "\n",
    "    def _parse_json_response(self, response):\n",
    "        try:\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in response\")\n",
    "            json_str = response[start_idx:end_idx]\n",
    "            return json.loads(json_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {e}\")\n",
    "            print(\"Raw response:\", response)\n",
    "            return None\n",
    "\n",
    "    def print_analysis_results(self, results):\n",
    "        if not results or 'analysis' not in results:\n",
    "            print(\"No valid analysis results to display\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n=== Paper Analysis Results ===\\n\")\n",
    "        \n",
    "        for analysis in results['analysis']:\n",
    "            print(f\"Claim {analysis['claim_id']}:\")\n",
    "            print(f\"Type: {analysis['claim']['type']}\")\n",
    "            print(f\"Statement: {analysis['claim']['text']}\")\n",
    "            print(f\"Location: {analysis['claim']['location']}\")\n",
    "            print(f\"Exact Quote: {analysis['claim']['exact_quote']}\")\n",
    "            \n",
    "            print(\"\\nEvidence:\")\n",
    "            for evidence in analysis['evidence']:\n",
    "                print(f\"- Evidence Text: {evidence['evidence_text']}\")\n",
    "                print(f\"  Strength: {evidence['strength']}\")\n",
    "                print(f\"  Location: {evidence['location']}\")\n",
    "                print(f\"  Limitations: {evidence['limitations']}\")\n",
    "                print(f\"  Exact Quote: {evidence['exact_quote']}\")\n",
    "            \n",
    "            eval_data = analysis['evaluation']\n",
    "            print(\"\\nEvaluation:\")\n",
    "            print(f\"Conclusion Justified: {'Yes' if eval_data['conclusion_justified'] else 'No'}\")\n",
    "            print(f\"Robustness: {eval_data['robustness']}\")\n",
    "            print(f\"Confidence Level: {eval_data['confidence_level']}\")\n",
    "            print(f\"Justification: {eval_data['justification']}\")\n",
    "            print(f\"Key Limitations: {eval_data['key_limitations']}\")\n",
    "            \n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "    def save_results(self, results, base_filename):\n",
    "        output_dir = Path('analysis_outputs')\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save full JSON results\n",
    "        json_path = output_dir / f'{base_filename}_analysis.json'\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        \n",
    "        # Save readable text summary\n",
    "        text_path = output_dir / f'{base_filename}_summary.txt'\n",
    "        with open(text_path, 'w', encoding='utf-8') as f:\n",
    "            for analysis in results['analysis']:\n",
    "                f.write(f\"Claim {analysis['claim_id']}:\\n\")\n",
    "                f.write(f\"Type: {analysis['claim']['type']}\\n\")\n",
    "                f.write(f\"Statement: {analysis['claim']['text']}\\n\")\n",
    "                f.write(f\"Location: {analysis['claim']['location']}\\n\")\n",
    "                f.write(f\"Exact Quote: {analysis['claim']['exact_quote']}\\n\\n\")\n",
    "                \n",
    "                f.write(\"Evidence:\\n\")\n",
    "                for evidence in analysis['evidence']:\n",
    "                    f.write(f\"- Evidence Text: {evidence['evidence_text']}\\n\")\n",
    "                    f.write(f\"  Strength: {evidence['strength']}\\n\")\n",
    "                    f.write(f\"  Location: {evidence['location']}\\n\")\n",
    "                    f.write(f\"  Limitations: {evidence['limitations']}\\n\")\n",
    "                    f.write(f\"  Exact Quote: {evidence['exact_quote']}\\n\\n\")\n",
    "                \n",
    "                eval_data = analysis['evaluation']\n",
    "                f.write(\"Evaluation:\\n\")\n",
    "                f.write(f\"Conclusion Justified: {'Yes' if eval_data['conclusion_justified'] else 'No'}\\n\")\n",
    "                f.write(f\"Robustness: {eval_data['robustness']}\\n\")\n",
    "                f.write(f\"Confidence Level: {eval_data['confidence_level']}\\n\")\n",
    "                f.write(f\"Justification: {eval_data['justification']}\\n\")\n",
    "                f.write(f\"Key Limitations: {eval_data['key_limitations']}\\n\")\n",
    "                \n",
    "                f.write(\"\\n\" + \"-\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        stats_path = output_dir / f'{base_filename}_statistics.txt'\n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            total_claims = len(results['analysis'])\n",
    "            justified_claims = sum(1 for a in results['analysis'] \n",
    "                                 if a['evaluation']['conclusion_justified'])\n",
    "            \n",
    "            f.write(\"Analysis Statistics:\\n\")\n",
    "            f.write(f\"Total Claims Analyzed: {total_claims}\\n\")\n",
    "            f.write(f\"Justified Claims: {justified_claims}\\n\")\n",
    "            \n",
    "            # Evidence strength distribution\n",
    "            strength_levels = {}\n",
    "            for analysis in results['analysis']:\n",
    "                for evidence in analysis['evidence']:\n",
    "                    strength = evidence['strength']\n",
    "                    strength_levels[strength] = strength_levels.get(strength, 0) + 1\n",
    "            \n",
    "            f.write(\"\\nEvidence Strength Distribution:\\n\")\n",
    "            total_evidence = sum(strength_levels.values())\n",
    "            for strength, count in strength_levels.items():\n",
    "                f.write(f\"{strength}: {count} pieces ({count/total_evidence*100:.1f}%)\\n\")\n",
    "\n",
    "        print(f\"Analysis results saved to {output_dir}:\")\n",
    "        print(f\"- Full analysis: {json_path}\")\n",
    "        print(f\"- Summary: {text_path}\")\n",
    "        print(f\"- Statistics: {stats_path}\")\n",
    "\n",
    "def main():\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    load_dotenv()\n",
    "    api_key = \"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\"   \n",
    "    \n",
    "    if not api_key:\n",
    "        raise ValueError(\"OpenAI API key not found. Please set OPENAI_API_KEY in your environment variables.\")\n",
    "\n",
    "    try:\n",
    "        analyzer = SinglePassPaperAnalyzer(api_key)\n",
    "        analyzer.create_assistant()\n",
    "        \n",
    "        input_file = \"ICLR_1.pdf\"\n",
    "        if not os.path.exists(input_file):\n",
    "            raise FileNotFoundError(f\"File not found: {input_file}\")\n",
    "        \n",
    "        base_filename = Path(input_file).stem\n",
    "        \n",
    "        print(\"\\nAnalyzing paper...\")\n",
    "        results = analyzer.analyze_paper(input_file)\n",
    "        \n",
    "        analyzer.print_analysis_results(results)\n",
    "        analyzer.save_results(results, base_filename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim once, Evidence Once, Conclusion Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant created successfully\n",
      "Starting analysis of ICLR_1.pdf\n",
      "Extracting claims...\n",
      "Processing file: ICLR_1.pdf\n",
      "Creating message...\n",
      "Message created successfully\n",
      "Starting analysis run...\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: completed\n",
      "Retrieving messages...\n",
      "Parsing response...\n",
      "Raw response: ```json\n",
      "{\n",
      "    \"claims\": [\n",
      "        {\n",
      "            \"claim_id\": 1,\n",
      "            \"claim_text\": \"CQCC significantly outperforms MFCC in classifying neurodegenerative disorders using vocal signals.\",\n",
      "            \"location\": \"Experimental Results and Discussion\",\n",
      "            \"claim_type\": \"result\",\n",
      "            \"exact_quote\": \"CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 63.4% accuracy achieved by the Support Vector Machine classifier.\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 2,\n",
      "            \"claim_text\": \"CQCC features provide a robust framework for identifying subtle speech abnormalities related to neurodegenerative disorders.\",\n",
      "            \"location\": \"Conclusions\",\n",
      "            \"claim_type\": \"contribution\",\n",
      "            \"exact_quote\": \"CQCCs emerged as the most effective feature, achieving the highest accuracy in classification tasks.\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 3,\n",
      "            \"claim_text\": \"CQCC captures nuanced differences in vocal characteristics associated with neurodegenerative diseases better than traditional acoustic measures.\",\n",
      "            \"location\": \"Experimental Results and Discussion\",\n",
      "            \"claim_type\": \"methodology\",\n",
      "            \"exact_quote\": \"CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "Successfully parsed JSON response\n",
      "Claims extraction completed\n",
      "Extracting evidence...\n",
      "Processing evidence for claims: Claim 1: CQCC significantly outperforms MFCC in classifying neurodegenerative disorders using vocal signals.\n",
      "Claim 2: CQCC features provide a robust framework for identifying subtle speech abnormalities related to neurodegenerative disorders.\n",
      "Claim 3: CQCC captures nuanced differences in vocal characteristics associated with neurodegenerative diseases better than traditional acoustic measures.\n",
      "Creating message...\n",
      "Message created successfully\n",
      "Starting analysis run...\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: completed\n",
      "Retrieving messages...\n",
      "Parsing response...\n",
      "Raw response: ```json\n",
      "{\n",
      "    \"evidence_sets\": [\n",
      "        {\n",
      "            \"claim_id\": 1,\n",
      "            \"evidence\": [\n",
      "                {\n",
      "                    \"evidence_id\": 1,\n",
      "                    \"evidence_text\": \"CQCC outperforms MFCC by achieving absolute improvements of 5.6% and 7.7% using Random Forest and Support Vector Machine classifiers, respectively.\",\n",
      "                    \"strength\": \"strong\",\n",
      "                    \"limitations\": \"Further validation in diverse pathological datasets is needed.\",\n",
      "                    \"location\": \"Conclusions\",\n",
      "                    \"exact_quote\": \"CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperforms MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively.\"\n",
      "                },\n",
      "                {\n",
      "                    \"evidence_id\": 2,\n",
      "                    \"evidence_text\": \"CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%) in classifying ALS and Parkinson's patients, indicating superior capability in capturing vocal differences.\",\n",
      "                    \"strength\": \"strong\",\n",
      "                    \"limitations\": \"Does not compare across all types of neurodegenerative disorders.\",\n",
      "                    \"location\": \"Experimental Results\",\n",
      "                    \"exact_quote\": \"CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%)\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 2,\n",
      "            \"evidence\": [\n",
      "                {\n",
      "                    \"evidence_id\": 1,\n",
      "                    \"evidence_text\": \"CQCC combined with Random Forest classifier achieved a high classification accuracy of 99% for binary classification of healthy vs. pathological speech, indicating a robust framework for identifying speech abnormalities.\",\n",
      "                    \"strength\": \"strong\",\n",
      "                    \"limitations\": \"Accuracy for SVM classifier was significantly lower, suggesting potential classifier dependency.\",\n",
      "                    \"location\": \"Overall performance for Binary Classification\",\n",
      "                    \"exact_quote\": \"CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 3,\n",
      "            \"evidence\": [\n",
      "                {\n",
      "                    \"evidence_id\": 1,\n",
      "                    \"evidence_text\": \"LDA plots demonstrate CQCC's stronger discriminative power in separating ALS and Parkinson's disease samples compared to MFCC, attributing to its capability in capturing nuanced vocal differences.\",\n",
      "                    \"strength\": \"strong\",\n",
      "                    \"limitations\": \"Focused primarily on ALS and Parkinson's disease, may not generalize to all neurodegenerative disorders.\",\n",
      "                    \"location\": \"Feature Visualization using LDA plots\",\n",
      "                    \"exact_quote\": \"the LDA plot of CQCC features exhibits a clearer separation, especially between the ALS and Parkinson’s disease classes\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "Successfully parsed JSON response\n",
      "Evidence extraction completed\n",
      "Analyzing conclusions...\n",
      "Creating message...\n",
      "Message created successfully\n",
      "Starting analysis run...\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: in_progress\n",
      "Run status: completed\n",
      "Retrieving messages...\n",
      "Parsing response...\n",
      "Raw response: {\n",
      "    \"conclusions\": [\n",
      "        {\n",
      "            \"claim_id\": 1,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"high\",\n",
      "            \"key_limitations\": \"The evidence does not provide details on the size and demographics of the sample population, or on whether these findings have been replicated in different studies or cohorts.\",\n",
      "            \"confidence_level\": \"medium\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 2,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"medium\",\n",
      "            \"key_limitations\": \"Lacks comparison with other feature extraction techniques beyond MFCC, and it's unclear if the 99% classification accuracy is consistent across various datasets or if it has been validated externally.\",\n",
      "            \"confidence_level\": \"medium\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 3,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"medium\",\n",
      "            \"key_limitations\": \"The evidence is based on visual inspection (LDA plots) rather than quantitative analysis, and the claim does not account for the potential variability in vocal characteristics within the ALS and Parkinson's disease groups.\",\n",
      "            \"confidence_level\": \"medium\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Successfully parsed JSON response\n",
      "Conclusions analysis completed\n",
      "Results saved to analysis_outputs/:\n",
      "- Detailed analysis: analysis_outputs/ICLR_1_analysis_20241106_153015.json\n",
      "- Summary: analysis_outputs/ICLR_1_summary_20241106_153015.txt\n",
      "- Statistics: analysis_outputs/ICLR_1_stats_20241106_153015.txt\n",
      "Analysis completed successfully\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import time\n",
    "import os \n",
    "import json \n",
    "class PaperAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.assistant = None\n",
    "        \n",
    "    def create_assistant(self):\n",
    "        try:\n",
    "            self.assistant = self.client.beta.assistants.create(\n",
    "                model=\"gpt-4-turbo-preview\",\n",
    "                description=\"Assistant for analyzing research papers\",\n",
    "                tools=[{\"type\": \"file_search\"}],\n",
    "                name=\"Research Paper Analyzer\"\n",
    "            )\n",
    "            print(\"Assistant created successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating assistant: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_all_claims(self, filename):\n",
    "        \"\"\"Get all claims in one pass\"\"\"\n",
    "        try:\n",
    "            # thread = self.client.beta.threads.create()\n",
    "            file = self.client.files.create(file=open(filename, \"rb\"), purpose=\"assistants\")\n",
    "            print(f\"Processing file: {filename}\")\n",
    "            \n",
    "            claims_prompt = \"\"\"\n",
    "            Analyze the research paper and identify the top 3 most significant claims where each claim:\n",
    "            1. Makes a specific, testable assertion\n",
    "            3. Represents a key finding or contribution\n",
    "\n",
    "            Return ONLY the following JSON:\n",
    "            {\n",
    "                \"claims\": [\n",
    "                    {\n",
    "                        \"claim_id\": number,\n",
    "                        \"claim_text\": \"statement of claim\",\n",
    "                        \"location\": \"section/paragraph\",\n",
    "                        \"claim_type\": \"methodology/result/contribution\",\n",
    "                        \"exact_quote\": \"verbatim text from paper\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            \"\"\"\n",
    "            \n",
    "            result = self._execute_analysis(None, file.id, claims_prompt)\n",
    "            print(\"Claims extraction completed\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_all_claims: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_all_evidence(self, filename, claims):\n",
    "        \"\"\"Get evidence for all claims in one pass\"\"\"\n",
    "        try:\n",
    "            # thread = self.client.beta.threads.create()\n",
    "            file = self.client.files.create(file=open(filename, \"rb\"), purpose=\"assistants\")\n",
    "            \n",
    "            # Format claims for prompt\n",
    "            claims_text = \"\\n\".join([f\"Claim {c['claim_id']}: {c['claim_text']}\" for c in claims['claims']])\n",
    "            print(\"Processing evidence for claims:\", claims_text)\n",
    "            \n",
    "            evidence_prompt = f\"\"\"\n",
    "            For these claims:\n",
    "            {claims_text}\n",
    "\n",
    "            Find the strongest supporting evidence for each claim. Evidence should:\n",
    "            1. Directly support the claim\n",
    "            2. Include specific results or data\n",
    "            3. Come from the paper's results or evaluation\n",
    "            4. Each claim can have multiple evidence, give each evidence as a seperate item\n",
    "\n",
    "            Return ONLY the following JSON:\n",
    "            {{\n",
    "                \"evidence_sets\": [\n",
    "                    {{\n",
    "                        \"claim_id\": number,\n",
    "                        \"evidence\": [\n",
    "                            {{\n",
    "                                \"evidence_id\": number,\n",
    "                                \"evidence_text\": \"specific evidence\",\n",
    "                                \"strength\": \"strong/moderate/weak\",\n",
    "                                \"limitations\": \"key limitations\",\n",
    "                                \"location\": \"section/paragraph\",\n",
    "                                \"exact_quote\": \"verbatim text\"\n",
    "                            }}\n",
    "                        ]\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            result = self._execute_analysis(None, file.id, evidence_prompt)\n",
    "            print(\"Evidence extraction completed\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_all_evidence: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_all_conclusions(self, filename, claims, evidence_sets):\n",
    "        \"\"\"Analyze conclusions for all claims and evidence in one pass\"\"\"\n",
    "        try:\n",
    "            # thread = self.client.beta.threads.create()\n",
    "            file = self.client.files.create(file=open(filename, \"rb\"), purpose=\"assistants\")\n",
    "            \n",
    "            # Create summary of claims and evidence for the prompt\n",
    "            analysis_summary = []\n",
    "            for claim in claims['claims']:\n",
    "                claim_id = claim['claim_id']\n",
    "                claim_evidence = next((e['evidence'] for e in evidence_sets['evidence_sets'] \n",
    "                                    if e['claim_id'] == claim_id), [])\n",
    "                \n",
    "                summary = f\"\\nClaim {claim_id}: {claim['claim_text']}\\n\"\n",
    "                summary += \"Evidence:\\n\"\n",
    "                for evidence in claim_evidence:\n",
    "                    summary += f\"- {evidence['evidence_text']}\\n\"\n",
    "                analysis_summary.append(summary)\n",
    "            \n",
    "            analysis_text = \"\\n\".join(analysis_summary)\n",
    "            \n",
    "            conclusions_prompt = f\"\"\"\n",
    "            Analyze these claims and their evidence:\n",
    "            {analysis_text}\n",
    "\n",
    "            For each claim-evidence pair, evaluate:\n",
    "            1. Whether the evidence justifies the claim\n",
    "            2. The overall strength of support\n",
    "            3. Any important limitations\n",
    "\n",
    "            Return ONLY the following JSON:\n",
    "            {{\n",
    "                \"conclusions\": [\n",
    "                    {{\n",
    "                        \"claim_id\": number,\n",
    "                        \"conclusion_justified\": true/false,\n",
    "                        \"robustness\": \"high/medium/low\",\n",
    "                        \"key_limitations\": \"specific limitations\",\n",
    "                        \"confidence_level\": \"high/medium/low\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            result = self._execute_analysis(None, file.id, conclusions_prompt)\n",
    "            print(\"Conclusions analysis completed\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_all_conclusions: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def _execute_analysis(self, thread_id, file_id, prompt):\n",
    "        \"\"\"Execute analysis with enhanced error handling\"\"\"\n",
    "        try:\n",
    "            print(\"Creating message...\")\n",
    "            message = self.client.beta.threads.messages.create(\n",
    "                thread_id=thread_id,\n",
    "                role=\"user\",\n",
    "                attachments=[\n",
    "                    Attachment(\n",
    "                        file_id=file_id,\n",
    "                        tools=[AttachmentToolFileSearch(type=\"file_search\")]\n",
    "                    )\n",
    "                ],\n",
    "                content=prompt\n",
    "            )\n",
    "            print(\"Message created successfully\")\n",
    "\n",
    "            print(\"Starting analysis run...\")\n",
    "            run = self.client.beta.threads.runs.create(\n",
    "                thread_id=thread_id,\n",
    "                assistant_id=self.assistant.id\n",
    "            )\n",
    "\n",
    "            # Poll for completion with timeout\n",
    "            timeout = 300  # 5 minutes timeout\n",
    "            start_time = time.time()\n",
    "            while True:\n",
    "                if time.time() - start_time > timeout:\n",
    "                    raise Exception(\"Analysis timed out\")\n",
    "\n",
    "                run_status = self.client.beta.threads.runs.retrieve(\n",
    "                    thread_id=thread_id,\n",
    "                    run_id=run.id\n",
    "                )\n",
    "                \n",
    "                print(f\"Run status: {run_status.status}\")\n",
    "                \n",
    "                if run_status.status == 'completed':\n",
    "                    break\n",
    "                elif run_status.status in ['failed', 'cancelled', 'expired']:\n",
    "                    raise Exception(f\"Run failed with status: {run_status.status}\")\n",
    "                \n",
    "                time.sleep(5)  # Wait 5 seconds before checking again\n",
    "\n",
    "            print(\"Retrieving messages...\")\n",
    "            messages = list(self.client.beta.threads.messages.list(thread_id=thread_id))\n",
    "            if not messages:\n",
    "                raise Exception(\"No messages received\")\n",
    "\n",
    "            return self._parse_json_response(messages[0].content[0].text.value)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in _execute_analysis: {str(e)}\")\n",
    "            print(f\"Thread ID: {thread_id}\")\n",
    "            print(f\"File ID: {file_id}\")\n",
    "            raise\n",
    "\n",
    "    def _parse_json_response(self, response):\n",
    "        \"\"\"Parse JSON response with better error handling\"\"\"\n",
    "        try:\n",
    "            print(\"Parsing response...\")\n",
    "            print(\"Raw response:\", response)\n",
    "            \n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            \n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in response\")\n",
    "                \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            result = json.loads(json_str)\n",
    "            \n",
    "            print(\"Successfully parsed JSON response\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {str(e)}\")\n",
    "            print(\"Raw response:\", response)\n",
    "            raise\n",
    "\n",
    "    def analyze_paper(self, filename):\n",
    "        \"\"\"Complete paper analysis using three-prompt approach\"\"\"\n",
    "        try:\n",
    "            # Get all claims\n",
    "            print(\"Extracting claims...\")\n",
    "            claims = self.get_all_claims(filename)\n",
    "            if not claims:\n",
    "                raise Exception(\"Failed to extract claims\")\n",
    "\n",
    "            # Get evidence for all claims\n",
    "            print(\"Extracting evidence...\")\n",
    "            evidence_sets = self.get_all_evidence(filename, claims)\n",
    "            if not evidence_sets:\n",
    "                raise Exception(\"Failed to extract evidence\")\n",
    "\n",
    "            # Get conclusions for all claim-evidence pairs\n",
    "            print(\"Analyzing conclusions...\")\n",
    "            conclusions = self.get_all_conclusions(filename, claims, evidence_sets)\n",
    "            if not conclusions:\n",
    "                raise Exception(\"Failed to generate conclusions\")\n",
    "\n",
    "            # Structure final results\n",
    "            final_results = {\n",
    "                \"paper_analysis\": []\n",
    "            }\n",
    "\n",
    "            for claim in claims['claims']:\n",
    "                claim_id = claim['claim_id']\n",
    "                \n",
    "                # Get evidence for this claim\n",
    "                evidence = next((e['evidence'] for e in evidence_sets['evidence_sets'] \n",
    "                            if e['claim_id'] == claim_id), [])\n",
    "                \n",
    "                # Get conclusion for this claim\n",
    "                conclusion = next((c for c in conclusions['conclusions'] \n",
    "                                if c['claim_id'] == claim_id), {})\n",
    "\n",
    "                analysis_item = {\n",
    "                    \"claim_id\": claim_id,\n",
    "                    \"claim\": {\n",
    "                        \"text\": claim['claim_text'],\n",
    "                        \"location\": claim['location'],\n",
    "                        \"type\": claim['claim_type'],\n",
    "                        \"exact_quote\": claim['exact_quote']\n",
    "                    },\n",
    "                    \"evidence\": evidence,\n",
    "                    \"conclusion\": {\n",
    "                        \"conclusion_justified\": conclusion.get('conclusion_justified', False),\n",
    "                        \"robustness\": conclusion.get('robustness', 'Not evaluated'),\n",
    "                        \"limitations\": conclusion.get('key_limitations', 'Not specified'),\n",
    "                        \"confidence_level\": conclusion.get('confidence_level', 'low')\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                final_results['paper_analysis'].append(analysis_item)\n",
    "\n",
    "            return final_results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in paper analysis: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def save_results(self, results, filename):\n",
    "        \"\"\"Save analysis results in multiple formats\"\"\"\n",
    "        try:\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            base_filename = Path(filename).stem\n",
    "\n",
    "            # Save detailed JSON results\n",
    "            json_filename = f'analysis_outputs/{base_filename}_analysis_{timestamp}.json'\n",
    "            os.makedirs('analysis_outputs', exist_ok=True)\n",
    "            \n",
    "            with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            # Save human-readable summary\n",
    "            summary_filename = f'analysis_outputs/{base_filename}_summary_{timestamp}.txt'\n",
    "            with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"=== Paper Analysis Summary ===\\n\\n\")\n",
    "                \n",
    "                for analysis in results['paper_analysis']:\n",
    "                    f.write(f\"Claim {analysis['claim_id']}:\\n\")\n",
    "                    f.write(f\"Statement: {analysis['claim']['text']}\\n\")\n",
    "                    f.write(f\"Location: {analysis['claim']['location']}\\n\")\n",
    "                    f.write(f\"Type: {analysis['claim']['type']}\\n\")\n",
    "                    f.write(f\"Quote: {analysis['claim']['exact_quote']}\\n\\n\")\n",
    "                    \n",
    "                    f.write(\"Evidence:\\n\")\n",
    "                    for evidence in analysis['evidence']:\n",
    "                        f.write(f\"- {evidence['evidence_text']}\\n\")\n",
    "                        f.write(f\"  Strength: {evidence['strength']}\\n\")\n",
    "                        f.write(f\"  Location: {evidence['location']}\\n\")\n",
    "                        f.write(f\"  Limitations: {evidence['limitations']}\\n\")\n",
    "                        f.write(f\"  Quote: {evidence['exact_quote']}\\n\\n\")\n",
    "                    \n",
    "                    f.write(\"Conclusion:\\n\")\n",
    "                    f.write(f\"Justified: {analysis['conclusion']['conclusion_justified']}\\n\")\n",
    "                    f.write(f\"Robustness: {analysis['conclusion']['robustness']}\\n\")\n",
    "                    f.write(f\"Limitations: {analysis['conclusion']['limitations']}\\n\")\n",
    "                    f.write(f\"Confidence: {analysis['conclusion']['confidence_level']}\\n\")\n",
    "                    f.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "            # Save statistics\n",
    "            stats_filename = f'analysis_outputs/{base_filename}_stats_{timestamp}.txt'\n",
    "            with open(stats_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"Analysis Statistics:\\n\\n\")\n",
    "                f.write(f\"Total Claims Analyzed: {len(results['paper_analysis'])}\\n\")\n",
    "                \n",
    "                # Evidence statistics\n",
    "                total_evidence = sum(len(analysis['evidence']) for analysis in results['paper_analysis'])\n",
    "                f.write(f\"Total Evidence Pieces: {total_evidence}\\n\")\n",
    "                \n",
    "                # Confidence distribution\n",
    "                confidence_levels = {}\n",
    "                for analysis in results['paper_analysis']:\n",
    "                    level = analysis['conclusion']['confidence_level']\n",
    "                    confidence_levels[level] = confidence_levels.get(level, 0) + 1\n",
    "                \n",
    "                f.write(\"\\nConfidence Level Distribution:\\n\")\n",
    "                for level, count in confidence_levels.items():\n",
    "                    f.write(f\"{level}: {count} claims\\n\")\n",
    "\n",
    "            print(f\"Results saved to analysis_outputs/:\")\n",
    "            print(f\"- Detailed analysis: {json_filename}\")\n",
    "            print(f\"- Summary: {summary_filename}\")\n",
    "            print(f\"- Statistics: {stats_filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        api_key = \"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\"   \n",
    "        analyzer = PaperAnalyzer(api_key)\n",
    "        analyzer.create_assistant()\n",
    "        \n",
    "        filename = \"ICLR_1.pdf\"\n",
    "        print(f\"Starting analysis of {filename}\")\n",
    "        \n",
    "        # Analyze paper\n",
    "        results = analyzer.analyze_paper(filename)\n",
    "        \n",
    "        if results:\n",
    "            # Save results in structured format\n",
    "            analyzer.save_results(results, filename)\n",
    "            print(\"Analysis completed successfully\")\n",
    "        else:\n",
    "            print(\"Analysis failed to produce results\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall, Precision and F-1 Score\n",
    "## Correctness and relevance of the claims and evidence identifies by each method\n",
    "## Comparing the number of claims in each case, comparing the number of evidences,average number of evidences for each claim in each case, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction: \"Identify all claims in this text that meet the following criteria:\n",
    "1. Makes a specific, verifiable assertion\n",
    "2. Can be supported or challenged with evidence\n",
    "3. Presents a clear position or conclusion\n",
    "\n",
    "For each claim:\n",
    "- Extract the exact claim statement\n",
    "- Classify the type of claim (factual/causal/policy/comparative)\n",
    "- Indicate the key elements that make it a verifiable claim\"\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "CopyInput: [Claim] + [Context]\n",
    "Instruction: \"For the given claim, identify relevant evidence that:\n",
    "1. Directly relates to the claim's main assertion\n",
    "2. Comes from verifiable sources\n",
    "3. Provides specific, concrete support or contradiction\n",
    "\n",
    "For each piece of evidence:\n",
    "- Extract the specific evidence\n",
    "- Indicate its type (statistical/expert/research/historical)\n",
    "- Explain how it relates to the claim\n",
    "- Rate its strength (strong/moderate/weak) with justification\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.13-cp39-abi3-macosx_11_0_arm64.whl (18.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.4 MB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.13\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # Import PyMuPDF\n",
    "import json\n",
    "\n",
    "def load_annotations(json_file):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def annotate_pdf(input_pdf, output_pdf, annotations):\n",
    "    document = fitz.open(input_pdf)\n",
    "    colors = {'claim': (0, 0, 1), 'evidence': (0, 1, 0), 'conclusion': (1, 1, 0)}  # RGB: blue, green, yellow\n",
    "\n",
    "    for claim in annotations['claims']['claims']:\n",
    "        for page in document:\n",
    "            text_instances = page.search_for(claim['claim_text'])\n",
    "            for inst in text_instances:\n",
    "                highlight = page.add_highlight_annot(inst)\n",
    "                highlight.set_colors(stroke=colors['claim'])\n",
    "                highlight.update()\n",
    "\n",
    "    for evidence_item in annotations['evidence']:\n",
    "        for evidence in evidence_item['evidence']:\n",
    "            for page in document:\n",
    "                text_instances = page.search_for(evidence['evidence_text'])\n",
    "                for inst in text_instances:\n",
    "                    highlight = page.add_highlight_annot(inst)\n",
    "                    highlight.set_colors(stroke=colors['evidence'])\n",
    "                    highlight.update()\n",
    "\n",
    "    for conclusion in annotations['conclusions']['conclusions']:\n",
    "        for page in document:\n",
    "            text_instances = page.search_for(conclusion['author_conclusion'])\n",
    "            for inst in text_instances:\n",
    "                highlight = page.add_highlight_annot(inst)\n",
    "                highlight.set_colors(stroke=colors['conclusion'])\n",
    "                highlight.update()\n",
    "\n",
    "    document.save(output_pdf)\n",
    "    document.close()\n",
    "\n",
    "# Example Usage\n",
    "annotations = load_annotations('intermediate_results.json')  # Load your JSON data\n",
    "annotate_pdf('2410.18764v1.pdf', 'annotated_output_1.pdf', annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def load_annotations(json_file):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def annotate_pdf(input_pdf, output_pdf, annotations):\n",
    "    document = fitz.open(input_pdf)\n",
    "    colors = {'claim': (0, 0, 1), 'evidence': (0, 1, 0), 'connection': (1, 0, 0)}  # RGB: blue, green, red\n",
    "\n",
    "    claim_rects = {}  # Stores the last rect of claim and corresponding page for drawing connections later\n",
    "\n",
    "    for claim in annotations['claims']['claims']:\n",
    "        claim_text = claim['Exact_claim_text']\n",
    "        for page in document:\n",
    "            text_instances = page.search_for(claim_text)\n",
    "            for inst in text_instances:\n",
    "                highlight = page.add_highlight_annot(inst)\n",
    "                highlight.set_colors(stroke=colors['claim'])\n",
    "                highlight.update()\n",
    "                claim_rects[claim['claim_id']] = (inst, page.number)\n",
    "\n",
    "    for evidence_set in annotations['evidence']:\n",
    "        claim_id = evidence_set['claim_id']\n",
    "        for evidence in evidence_set['evidence']:\n",
    "            evidence_text = evidence['Exact_evidence_text']\n",
    "            for page in document:\n",
    "                text_instances = page.search_for(evidence_text)\n",
    "                for inst in text_instances:\n",
    "                    highlight = page.add_highlight_annot(inst)\n",
    "                    highlight.set_colors(stroke=colors['evidence'])\n",
    "                    highlight.update()\n",
    "                    if claim_id in claim_rects and claim_rects[claim_id][1] == page.number:\n",
    "                        claim_rect = claim_rects[claim_id][0]\n",
    "                        start = claim_rect.br  # Bottom-right corner of claim\n",
    "                        end = inst.tl  # Top-left corner of evidence\n",
    "                        line = page.add_line_annot(start, end)\n",
    "                        line.set_colors(stroke=colors['connection'])\n",
    "                        line.set_border(width=1.5)\n",
    "                        line.set_line_ends(1, 1)  # Assuming 1 is the code for arrowheads\n",
    "                        line.update()\n",
    "\n",
    "    document.save(output_pdf)\n",
    "    document.close()\n",
    "\n",
    "annotations = load_annotations('intermediate_results.json')\n",
    "annotate_pdf('2410.18764v1.pdf', 'annotated_output_2.pdf', annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # Import PyMuPDF\n",
    "\n",
    "def load_annotations(json_file):\n",
    "    \"\"\" Load JSON data from a file. \"\"\"\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def annotate_pdf_with_colors(input_pdf, output_pdf, annotations):\n",
    "    document = fitz.open(input_pdf)\n",
    "    # Define a set of light colors for highlighting, using RGB tuples\n",
    "    colors = [(0.9, 0.7, 0.7), (0.7, 0.9, 0.7), (0.7, 0.7, 0.9), (0.9, 0.9, 0.7), (0.7, 0.9, 0.9)]\n",
    "\n",
    "    claim_annotations = {}  # Store annotations for quick access and modification\n",
    "\n",
    "    # Process each claim and its evidence\n",
    "    for index, claim in enumerate(annotations['claims']['claims']):\n",
    "        claim_text = claim['Exact_claim_text']\n",
    "        color_index = index % len(colors)  # Cycle through colors if there are more claims than colors\n",
    "        for page in document:\n",
    "            text_instances = page.search_for(claim_text)\n",
    "            for inst in text_instances:\n",
    "                annot = page.add_highlight_annot(inst)\n",
    "                annot.set_colors(stroke=colors[color_index])\n",
    "                annot.update()\n",
    "                claim_annotations[claim['claim_id']] = (annot, index + 1)  # Store annotation and index\n",
    "\n",
    "    # Process evidence and match colors with claims\n",
    "    for evidence_set in annotations['evidence']:\n",
    "        claim_id = evidence_set['claim_id']\n",
    "        if claim_id in claim_annotations:\n",
    "            annot, claim_number = claim_annotations[claim_id]\n",
    "            color = annot.colors['stroke']  # Get the color used for the claim\n",
    "            for evidence in evidence_set['evidence']:\n",
    "                evidence_text = evidence['Exact_evidence_text']\n",
    "                for page in document:\n",
    "                    text_instances = page.search_for(evidence_text)\n",
    "                    for inst in text_instances:\n",
    "                        annot = page.add_highlight_annot(inst)\n",
    "                        annot.set_colors(stroke=color)\n",
    "                        # Add text labels to the evidence to indicate claim number\n",
    "                        annot_info = f\"Evidence for Claim {claim_number}\"\n",
    "                        label = page.insert_text(inst.bl, annot_info, fontsize=10, color=color)\n",
    "                        annot.update()\n",
    "\n",
    "    document.save(output_pdf)\n",
    "    document.close()\n",
    "\n",
    "# Example usage\n",
    "# annotations = load_annotations('annotations.json')  # Ensure the JSON path is correct\n",
    "# annotate_pdf_with_colors('input.pdf', 'annotated_output.pdf', annotations)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "annotations = load_annotations('intermediate_results.json')\n",
    "annotate_pdf_with_colors('2410.18764v1.pdf', 'annotated_output_2.pdf', annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def add_line_numbers(pdf_path, output_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        line_number = 1\n",
    "        block_list = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in block_list:\n",
    "            if block['type'] == 0:  # This is a text block\n",
    "                for line in block[\"lines\"]:\n",
    "                    first_span = line[\"spans\"][0]\n",
    "                    x = first_span[\"bbox\"][0]  # x-coordinate of the first span in the line\n",
    "                    y = first_span[\"bbox\"][1]  # y-coordinate of the first span in the line\n",
    "                    text = f\"{line_number}. \"\n",
    "                    line_number += 1\n",
    "                    page.insert_text((x - 50, y), text, fontsize=11, color=(0, 0, 0))\n",
    "    doc.save(output_path)\n",
    "    doc.close()\n",
    "\n",
    "# Usage\n",
    "add_line_numbers(\"2410.18764v1.pdf\", \"2410.18764v1_with_lines.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
