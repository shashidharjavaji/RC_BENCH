Claim 1:
Type: contribution
Statement: LLMs cannot be used as planners or plan verifiers themselves.
Location: Section 2
Exact Quote: LLMs cannot be used as planners or plan verifiers themselves

Evidence:
- Evidence Text: On average, only about 12% of the plans that the best LLM (GPT-4) generates are actually executable without errors and goal-reaching.
  Strength: strong
  Location: Section 2.1/Results Table
  Limitations: Limited to specific planning problem instances and LLMs examined.
  Exact Quote: On average, only about 12% of the plans that the best LLM (GPT-4) generates are actually executable without errors and goal-reaching.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is strongly supported by empirical data demonstrating the inadequacy of LLMs in generating executable plans autonomously.
Key Limitations: Evaluation context limited to planning problems from IPC and tested LLMs might not generalize.

--------------------------------------------------

Claim 2:
Type: result
Statement: LLMs' performance on planning tasks does not improve significantly with iterative prompting.
Location: Section 2.2
Exact Quote: The strategy of LLMs self-critiquing their solutions does not improve over the baseline.

Evidence:
- Evidence Text: LLMs fail to recognize correct coloring, resulting in worse performance than baseline.
  Strength: strong
  Location: Section 2.2
  Limitations: Focused on graph coloring and planning problems; results may not generalize to all types of reasoning tasks.
  Exact Quote: The strategy of LLMs self-critiquing their solutions does not improve over the baseline.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is based on consistent findings across different experimental setups that demonstrate LLM's inability to improve through self-critique.
Key Limitations: Experiments limited to specific tasks; applications to other domains need further validation.

--------------------------------------------------

Claim 3:
Type: contribution
Statement: The LLM-Modulo Framework enables leveraging LLMs effectively in planning tasks.
Location: Introduction/Section 3
Exact Quote: We will propose a framework that allows us to leverage LLMs effectively in planning tasks.

Evidence:
- Evidence Text: Preliminary results show significant performance improvements using LLM-Modulo in tasks such as travel planning.
  Strength: moderate
  Location: Case Studies/Results
  Limitations: Preliminary findings; requires broader evaluation across varied planning tasks for generalizability.
  Exact Quote: Our preliminary results show that LLM-Modulo based agentification with automated critics in the loop significantly improves the performance.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: Empirical evidence from case studies supports the effective use of LLM-Modulo for planning tasks, though additional comprehensive tests are necessary for wider validation.
Key Limitations: Evidence primarily from controlled experiments and case studies; extensive application and testing in real-world scenarios needed.

--------------------------------------------------

