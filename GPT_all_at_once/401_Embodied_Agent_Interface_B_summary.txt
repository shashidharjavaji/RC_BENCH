Claim 1:
Type: contribution
Statement: EMBODIED AGENT INTERFACE systematically evaluates LLMs for embodied decision-making, focusing on standardizing goal specifications, unifying decision-making tasks, and providing evaluation metrics.
Location: Conclusions and Future Work
Exact Quote: We propose a systematic evaluation framework EMBODIED AGENT INTERFACE to benchmark LLMs for embodied decision-making. It focuses on 1) standardizing goal specifications using LTL formulas, 2) unifying decision-making tasks through a standard interface and four fundamental ability modules, and 3) providing comprehensive fine-grained evaluation metrics and automatic error identification.

Evidence:
- Evidence Text: EMBODIED AGENT INTERFACE implements goal specifications using LTL formulas and evaluates LLMs using a structured interface across four ability modules.
  Strength: strong
  Location: Conclusions and Future Work
  Limitations: Evaluation limited to abstract language terms for states, actions, and goals.
  Exact Quote: It focuses on 1) standardizing goal specifications using LTL formulas, 2) unifying decision-making tasks through a standard interface and four fundamental ability modules, and 3) providing comprehensive fine-grained evaluation metrics and automatic error identification.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is directly supported by the detailed description of the framework's focus areas and methodology.
Key Limitations: Limited applicability to non-abstract aspects of embodied decision-making, such as sensory inputs and actuations.

--------------------------------------------------

Claim 2:
Type: result
Statement: Current LLMs exhibit limitations in interpreting complex goals and various reasoning errors attributing to trajectory length, goal complexity, and spatial relation goals among others.
Location: Conclusions and Future Work
Exact Quote: We highlight the limitations of current LLMs in interpreting complex goals and different errors in reasoning, further attributing errors to various cofactors, including trajectory length, goal complexity, spatial relation goals, etc.

Evidence:
- Evidence Text: Proprietary LLMs make few grammar errors; top open-source LLMs suffer from format/parsing errors and object/state hallucination.
  Strength: moderate
  Location: Goal Interpretation
  Limitations: Insufficient comparison across a wide range of LLMs.
  Exact Quote: State-of-the-art proprietary LLMs make few to no grammar errors, while top open-source LLMs like Llama 3 70B Instruct suffer more from format/parsing errors and object/state hallucination.

- Evidence Text: o1-preview model demonstrates superior performance across multiple evaluation aspects in BEHAVIOR and VirtualHome simulators.
  Strength: strong
  Location: Results
  Limitations: Performance comparison narrowly focuses on top models.
  Exact Quote: o1-preview shows a clear advantage over other models, particularly on the BEHAVIOR simulator, where it achieves 74.9% compared to 64.2%.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: While the claim is supported by evidence of specific LLMs' performance and qualitative assessment of errors, the analysis does not comprehensively cover all evaluated LLMs.
Key Limitations: Generalization of LLMsâ€™ limitations may not hold across all models.

--------------------------------------------------

