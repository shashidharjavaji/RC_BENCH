{
    "analysis": [
        {
            "claim_id": 1,
            "claim": {
                "text": "WebAgent, an LLM-driven agent that learns from self-experience to complete user instructions on real websites by combining canonical web actions in a program space, significantly outperforms single LLM agent.",
                "type": "Novel finding",
                "location": "Introduction",
                "exact_quote": "We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete user instructions on real websites by combining canonical web actions in a program space (Figure 3). WebAgent (i) plans sub-instructions for each step by decomposing natural language instructions, (ii) summarizes long HTML documents into task-relevant snippets, and (iii) acts on websites via programming generated from those.  We empirically demonstrate that our modular recipe improves the success on real websites by over 50%, and that HTML-T5 is the best model to solve various HTML understanding tasks; achieving 18.7% higher success than the prior method on MiniWoB++, and SoTA performance on Mind2Web, an offline task planning evaluation."
            },
            "evidence": [
                {
                    "evidence_text": "We empirically demonstrate that our modular recipe improves the success on real websites by over 50%.",
                    "strength": "Strong",
                    "limitations": "None",
                    "location": "Introduction",
                    "exact_quote": "We empirically demonstrate that our modular recipe improves the success on real websites by over 50%"
                },
                {
                    "evidence_text": "We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete user instructions on real websites by combining canonical web actions in a program space (Figure 3).",
                    "strength": "Moderate",
                    "limitations": "Does not provide specific experimental results or data",
                    "location": "Introduction",
                    "exact_quote": "We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete user instructions on real websites by combining canonical web actions in a program space (Figure 3)."
                }
            ],
            "evaluation": {
                "conclusion_justified": true,
                "robustness": "high",
                "justification": "",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 2,
            "claim": {
                "text": "HTML-T5, a language model with local-global attention mechanisms that is pre-trained with a mixture of long-span denoising objective on a large-scale HTML corpus, outperforms prior language model agent by 18.7%  in MiniWoB++, and achieves SoTA performance on Mind2Web, even surpassing GPT-4.",
                "type": "Novel finding",
                "location": "Introduction",
                "exact_quote": "We newly introduce HTML-T5 \u2013 a language model with local-global attention mechanism that is pre-trained with a mixture of long-span denoising objective on a large-scale HTML corpus, curated from CommonCrawl. HTML-T5 has an encoder-decoder architecture and is specialized to capture the structure of long HTML documents better by adopting localand global attention mechanisms (Guo et al., 2022). It is pre-trained using a mixture of long-span denoising objective (Tay et al., 2022) on a large-scale HTML corpus extracted from CommonCrawl. To ground language model agents into real websites, we introduce self-experience supervision, where the domain-expert language models are finetuned with data generated by scripted planning/summarization and self-generated programming.\n\nExisting LLM-driven agents often solve decision making tasks with a single LLM conditioned on different prompts per role (Kim et al., 2023; Sun et al., 2023; Zheng et al., 2023), which is, however, not enough for real-world tasks whose complexity is higher than that of simulators. The empirical evaluations reveal that our method incorporating self-bootstrapped specialist language models improves HTML understanding and grounding, and achieves better generalization than single LLM agent. In real-world web automation, WebAgent significantly increases the success rate by 50%, and error analysis emphasizes that coupling task planning with HTML summarization in specialized language models is essential for task success. Moreover, HTML-T5 not only works as a core module for WebAgent but also achieves strong results by itself on the web-based tasks. On MiniWoB++ (Liu et al., 2018; Shi et al., 2017), HTML-T5 achieves 18.7% higher success than previous language model agent (Gur et al., 2022) while also outperforming competitive baselines, such as naive localglobal attention models (Guo et al., 2022) and its instruction-finetuned ones (Chung et al., 2022). On the Mind2Web (Deng et al., 2023), an offline task planning dataset, HTML-T5 achieves SoTA performance among Synapse (Zheng et al., 2023) with GPT-3.5, and MindAct with FLan-T5-XL and GPT-4 (OpenAI, 2023)."
            },
            "evidence": [
                {
                    "evidence_text": "On MiniWoB++ (Liu et al., 2018; Shi et al., 2017), HTML-T5 achieves 18.7% higher success than previous language model agent (Gur et al., 2022) while also outperforming competitive baselines, such as naive localglobal attention models (Guo et al., 2022) and its instruction-finetuned ones (Chung et al., 2022).",
                    "strength": "Strong",
                    "limitations": "None",
                    "location": "Introduction",
                    "exact_quote": "On MiniWoB++ (Liu et al., 2018; Shi et al., 2017), HTML-T5 achieves 18.7% higher success than previous language model agent (Gur et al., 2022) while also outperforming competitive baselines, such as naive localglobal attention models (Guo et al., 2022) and its instruction-finetuned ones (Chung et al., 2022)."
                },
                {
                    "evidence_text": "On the Mind2Web (Deng et al., 2023), an offline task planning dataset, HTML-T5 achieves SoTA performance among Synapse (Zheng et al., 2023) with GPT-3.5, and MindAct with FLan-T5-XL and GPT-4 (OpenAI, 2023).",
                    "strength": "Strong",
                    "limitations": "None",
                    "location": "Introduction",
                    "exact_quote": "On the Mind2Web (Deng et al., 2023), an offline task planning dataset, HTML-T5 achieves SoTA performance among Synapse (Zheng et al., 2023) with GPT-3.5, and MindAct with FLan-T5-XL and GPT-4 (OpenAI, 2023)."
                }
            ],
            "evaluation": {
                "conclusion_justified": true,
                "robustness": "high",
                "justification": "",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        }
    ],
    "execution_times": {
        "single_pass_analysis_time": "105.68 seconds",
        "total_execution_time": "312.02 seconds"
    }
}