{
    "analysis": [
        {
            "claim_id": 1,
            "claim": {
                "text": "LLMs do not think step-by-step in implicit reasoning.",
                "type": "Novel finding",
                "location": "Abstract",
                "exact_quote": "It has been well-known that Chain-of-Thought can remarkably enhance LLMs\u2019 performance on complex tasks. However, because it also introduces slower inference speeds and higher computational costs, many researches have attempted to use implicit CoT, which does not need LLMs to explicitly generate the intermediate steps. But there is still gap between their efficacy and typical explicit CoT methods. This leaves us a doubt that, does implicit CoT really equal to explicit CoT? Therefore, in this study, we address this question through experiments. We probe the information of intermediate steps from the model\u2019s hidden states when it is performing implicit CoT. The results surprisingly indicate that LLMs hardly think about intermediate steps, suggesting they may just rely on experience rather than strict step-by-step reasoning. Moreover, we find LLMs\u2019 implicit reasoning capabilities are susceptible and unstable, reaffirming the necessity of explicit CoT to effectively support complex tasks."
            },
            "evidence": [
                {
                    "evidence_text": "We probe the information of intermediate steps from the model\u2019s hidden states when it is performing implicit CoT. The results surprisingly indicate that LLMs hardly think about intermediate steps, suggesting they may just rely on experience rather than strict step-by-step reasoning.",
                    "strength": "Strong",
                    "limitations": "None",
                    "location": "Abstract",
                    "exact_quote": "We probe the information of intermediate steps from the model\u2019s hidden states when it is performing implicit CoT. The results surprisingly indicate that LLMs hardly think about intermediate steps, suggesting they may just rely on experience rather than strict step-by-step reasoning."
                },
                {
                    "evidence_text": "However, because it also introduces slower inference speeds and higher computational costs, many researches have attempted to use implicit CoT, which does not need LLMs to explicitly generate the intermediate steps. But there is still gap between their efficacy and typical explicit CoT methods. This leaves us a doubt that, does implicit CoT really equal to explicit CoT?",
                    "strength": "Moderate",
                    "limitations": "May not be directly relevant to the claim",
                    "location": "Abstract",
                    "exact_quote": "However, because it also introduces slower inference speeds and higher computational costs, many researches have attempted to use implicit CoT, which does not need LLMs to explicitly generate the intermediate steps. But there is still gap between their efficacy and typical explicit CoT methods. This leaves us a doubt that, does implicit CoT really equal to explicit CoT?"
                }
            ],
            "evaluation": {
                "conclusion_justified": true,
                "robustness": "medium",
                "justification": "",
                "key_limitations": "May not generalize to all LLMs or tasks",
                "confidence_level": "medium"
            }
        },
        {
            "claim_id": 2,
            "claim": {
                "text": "Implicit reasoning in LLMs is less robust and less reliable than explicit reasoning.",
                "type": "Novel finding",
                "location": "Section 2.3",
                "exact_quote": "To further show the difference between implicit reasoning and explicit reasoning, we slightly modify the problem by 2 methods: 1. reversing the order of the equations; 2. dividing all values by 10. For humans, such modifications hardly increase any difficulty of the problem. The examples of the modified problem are as follows:\u2026From the results in Table 1, we can clearly see that, compare to the original problems, the modified problems significantly degrade the performance when using implicit reasoning. While the performance of explicit reasoning is always perfect. This contrast further demonstrate our inference that, in implicit reasoning, the model is actually answering directly by experience and intuition, but not by reasoning step-by-step. This cause the way of implicit reasoning less robust and less reliable."
            },
            "evidence": [
                {
                    "evidence_text": "From the results in Table 1, we can clearly see that, compare to the original problems, the modified problems significantly degrade the performance when using implicit reasoning. While the performance of explicit reasoning is always perfect.",
                    "strength": "Strong",
                    "limitations": "None",
                    "location": "Section 2.3",
                    "exact_quote": "From the results in Table 1, we can clearly see that, compare to the original problems, the modified problems significantly degrade the performance when using implicit reasoning. While the performance of explicit reasoning is always perfect."
                },
                {
                    "evidence_text": "This contrast further demonstrate our inference that, in implicit reasoning, the model is actually answering directly by experience and intuition, but not by reasoning step-by-step. This cause the way of implicit reasoning less robust and less reliable.",
                    "strength": "Moderate",
                    "limitations": "May not be directly relevant to the claim",
                    "location": "Section 2.3",
                    "exact_quote": "This contrast further demonstrate our inference that, in implicit reasoning, the model is actually answering directly by experience and intuition, but not by reasoning step-by-step. This cause the way of implicit reasoning less robust and less reliable."
                }
            ],
            "evaluation": {
                "conclusion_justified": true,
                "robustness": "high",
                "justification": "",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 3,
            "claim": {
                "text": "Scaling the test-time by using explicit CoT may still be the most feasible method to further propel the capabilities of LLMs at present.",
                "type": "Improvement or advancement",
                "location": "Section 3",
                "exact_quote": "In this study, we investigate the mechanism of LLMs doing implicit reasoning, and get a nontrivial finding that, unlike some previous studies which envisioned implicit reasoning as a substitute for explicit reasoning, implicit reasoning cannot be on par with explicit reasoning methods because it actually does not follow a step-by-step process but just intuitively thinks of the answer, which makes it less reliable. This finding remind us that there is no free lunch, that is, under current technological conditions, there may not be a perfect solution that can make LLMs output very few tokens while keeping the accuracy on solving complex problems. When you ask LLMs to give the answer directly, you should know that it has not actually undergone a real reasoning. Scaling the test-time by using explicit CoT may still be the most feasible method to further propel the capabilities of LLMs at present."
            },
            "evidence": [
                {
                    "evidence_text": "We investigate the mechanism of LLMs doing implicit reasoning, and get a nontrivial finding that, unlike some previous studies which envisioned implicit reasoning as a substitute for explicit reasoning, implicit reasoning cannot be on par with explicit reasoning methods because it actually does not follow a step-by-step process but just intuitively thinks of the answer, which makes it less reliable. This finding remind us that there is no free lunch, that is, under current technological conditions, there may not be a perfect solution that can make LLMs output very few tokens while keeping the accuracy on solving complex problems.",
                    "strength": "Moderate",
                    "limitations": "May not be directly relevant to the claim",
                    "location": "Section 3",
                    "exact_quote": "We investigate the mechanism of LLMs doing implicit reasoning, and get a nontrivial finding that, unlike some previous studies which envisioned implicit reasoning as a substitute for explicit reasoning, implicit reasoning cannot be on par with explicit reasoning methods because it actually does not follow a step-by-step process but just intuitively thinks of the answer, which makes it less reliable. This finding remind us that there is no free lunch, that is, under current technological conditions, there may not be a perfect solution that can make LLMs output very few tokens while keeping the accuracy on solving complex problems."
                },
                {
                    "evidence_text": "When you ask LLMs to give the answer directly, you should know that it has not actually undergone a real reasoning. Scaling the test-time by using explicit CoT may still be the most feasible method to further propel the capabilities of LLMs at present.",
                    "strength": "Strong",
                    "limitations": "None",
                    "location": "Section 3",
                    "exact_quote": "When you ask LLMs to give the answer directly, you should know that it has not actually undergone a real reasoning. Scaling the test-time by using explicit CoT may still be the most feasible method to further propel the capabilities of LLMs at present."
                }
            ],
            "evaluation": {
                "conclusion_justified": true,
                "robustness": "medium",
                "justification": "",
                "key_limitations": "May not be the only feasible method",
                "confidence_level": "medium"
            }
        }
    ],
    "execution_times": {
        "single_pass_analysis_time": "297.67 seconds",
        "total_execution_time": "297.67 seconds"
    }
}