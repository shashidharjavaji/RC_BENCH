{
    "analysis": [
        {
            "claim_id": 1,
            "claim": {
                "text": "We propose Query-Relevant Neuron Cluster Attribution (QRNCA), a novel architecture-agnostic framework capable of identifying query-relevant neurons in LLMs.",
                "type": "primary",
                "location": "Introduction",
                "exact_quote": "We propose Query-Relevant Neuron Cluster Attribution (QRNCA), a novel architecture-agnostic framework capable of identifying query-relevant neurons in LLMs."
            },
            "evidence": [
                {
                    "evidence_text": "We introduce Query-Relevant Neuron Cluster Attribution (QRNCA), a novel architecture-agnostic framework capable of identifying query-relevant neurons in LLMs.",
                    "strength": "strong",
                    "limitations": "None stated.",
                    "location": "Section 1 Introduction, Paragraph 2",
                    "exact_quote": "We propose Query-Relevant Neuron Cluster Attribution (QRNCA), a novel architecture-agnostic framework capable of identifying query-relevant neurons in LLMs."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "No robustness analysis available",
                "justification": "No conclusion available",
                "key_limitations": "No limitations analysis available",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 2,
            "claim": {
                "text": "QRNCA allows for the examination of long-form answers beyond triplet facts by employing the proxy task of multi-choice question answering.",
                "type": "primary",
                "location": "Introduction",
                "exact_quote": ""
            },
            "evidence": [
                {
                    "evidence_text": "To evaluate the effectiveness of our detected neurons, we build two multi-choice QA datasets spanning diverse domains and languages. Empirical evaluations demonstrate that our method outperforms baseline methods significantly.",
                    "strength": "strong",
                    "limitations": "only evaluated on multiple-choice QA datasets",
                    "location": "Section 5.2, Paragraph 2.",
                    "exact_quote": "To evaluate the effectiveness of our detected neurons, we build two multi-choice QA datasets spanning diverse domains and languages. Empirical evaluations demonstrate that our method outperforms baseline methods significantly."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "No robustness analysis available",
                "justification": "No conclusion available",
                "key_limitations": "No limitations analysis available",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 3,
            "claim": {
                "text": "Empirical evaluations demonstrate that our method outperforms baseline methods significantly.",
                "type": "primary",
                "location": "Introduction",
                "exact_quote": ""
            },
            "evidence": [
                {
                    "evidence_text": "Table 3 presents the overall performance of various methods. Our QRNCA method consistently outperforms other baselines, evidenced by its higher PCR.",
                    "strength": "strong",
                    "limitations": "None stated.",
                    "location": "Section 5.3",
                    "exact_quote": "Table 3 presents the overall performance of various methods. Our QRNCA method consistently outperforms other baselines, evidenced by its higher PCR."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "No robustness analysis available",
                "justification": "No conclusion available",
                "key_limitations": "No limitations analysis available",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 4,
            "claim": {
                "text": "Analysis of neuron distributions reveals the presence of visible localized regions, particularly within different domains.",
                "type": "primary",
                "location": "Introduction",
                "exact_quote": ""
            },
            "evidence": [
                {
                    "evidence_text": "Figure displays heatmaps of detected QR neurons across various academic domains and languages. The heatmaps show brighter colors indicating higher naica values and the distribution of QR neurons appears sparse but with distinct regions, particularly for different domains.",
                    "strength": "strong",
                    "limitations": "Qualitative analysis of the heatmaps",
                    "location": "Results, section 5.4",
                    "exact_quote": ""
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "Analysis failed",
                "justification": "Error in analysis",
                "key_limitations": "Analysis failed",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 5,
            "claim": {
                "text": "Our contributions are four-fold: (1) A scalable method: we propose QRNCA to detect query-relevant neurons in LLMs; the QRNCA method is architecture-agnostic and can deal with long-form generations.",
                "type": "primary",
                "location": "Related Work",
                "exact_quote": ""
            },
            "evidence": [
                {
                    "evidence_text": "The proposed method outperforms baseline approaches.",
                    "strength": "strong",
                    "limitations": "No specific limitations are mentioned.",
                    "location": "Section 5 Analyzing Detected QR Neurons -> Paragraph 4",
                    "exact_quote": "Our QRNCA method consistently outperforms other baseline methods, evidenced by its higher PCR."
                },
                {
                    "evidence_text": "QRNCA method is applicable to long-form texts because it employs a proxy task of multi-choice question answering",
                    "strength": "strong",
                    "limitations": "No specific limitations are mentioned.",
                    "location": "Section 4 Locating Query-Relevant (QR) Neurons in Autoregressive LLMs -> Paragraph 3",
                    "exact_quote": "To deal with long-form texts, we advocate for the transformation of questions and their corresponding answers into a multiple-choice framework, as illustrated in Figure 1."
                },
                {
                    "evidence_text": "QRNCA allows for the examination of long-form generation beyond single tokens.",
                    "strength": "moderate",
                    "limitations": "No specific limitations are mentioned.",
                    "location": "Section 4 Locating Query-Relevant (QR) Neurons in Autoregressive LLMs -> Paragraph 3",
                    "exact_quote": "By employing prompt engineering, we constrain LLMs to generate only the option letter rather than the complete answer. This approach allows for the examination of long-form generation beyond single tokens."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "Analysis failed",
                "justification": "Error in analysis",
                "key_limitations": "Analysis failed",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 6,
            "claim": {
                "text": "Two new datasets: we curate two multi-choice QA datasets that contain different types of knowledge, namely Domain Knowledge and Language knowledge.",
                "type": "primary",
                "location": "Related Work",
                "exact_quote": ""
            },
            "evidence": [
                {
                    "evidence_text": "We construct two datasets to locate knowledge neurons that cover two different categories: subject domains and languages.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Section 5",
                    "exact_quote": "We construct two datasets to locate knowledge neurons that cover two different categories: subject domains and languages."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "No robustness analysis available",
                "justification": "No conclusion available",
                "key_limitations": "No limitations analysis available",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 7,
            "claim": {
                "text": "In-depth studies: we visualize distributions of detected neurons and we are the first to show that there are visible localized regions in Llama.",
                "type": "primary",
                "location": "Related Work",
                "exact_quote": ""
            },
            "evidence": [
                {
                    "evidence_text": "The distribution of QR neurons appears sparse but with distinct regions, particularly for different domains.",
                    "strength": "strong",
                    "limitations": "The finding is based on the geographical heatmap visualization of QR neurons.",
                    "location": "Section 5.4",
                    "exact_quote": "Figure 4 displays the geographical locations of QR neurons in Llama-2-7B across various academic domains and languages. The distribution of QR neurons appears sparse but with distinct regions, particularly for different subject domains."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "No robustness analysis available",
                "justification": "No conclusion available",
                "key_limitations": "No limitations analysis available",
                "confidence_level": ""
            }
        },
        {
            "claim_id": 8,
            "claim": {
                "text": "Potential applications: we show that QRNCA might be useful for knowledge editing and neuron-based prediction.",
                "type": "primary",
                "location": "Related Work",
                "exact_quote": ""
            },
            "evidence": [
                {
                    "evidence_text": "Apart from using the metric of PCR in Section 5.3, we are also interested in whether the detected QR neurons can be used for knowledge editing. For this goal, we adjust the values of QR neurons by either boosting or suppressing them to determine if we can change the prediction of a query from incorrect to correct or vice versa. Table 5 presents the successful rates of knowledge editing on our constructed language datasets. Our observations indicate that QRNCA achieves higher success rates than other baselines.",
                    "strength": "strong",
                    "limitations": "Results are limited to the constructed language datasets",
                    "location": "Section 6.1 Knowledge Editing",
                    "exact_quote": "Apart from using the metric of PCR in Section 5.3, we are also interested in whether the detected QR neurons can be used for knowledge editing. For this goal, we adjust the values of QR neurons by either boosting or suppressing them to determine if we can change the prediction of a query from incorrect to correct or vice versa. Table 5 presents the successful rates of knowledge editing on our constructed language datasets. Our observations indicate that QRNCA achieves higher success rates than other baselines."
                },
                {
                    "evidence_text": "The intuition behind neuron-based prediction is that for a domain-specific question, if the corresponding localized regions are properly activated, the LLM is more likely to generate truthful answers. Otherwise, the LLM may produce hallucinated answers. To this end, we test whether the correct answers to domain-specific questions can be predicted solely based on the activity of the associated neurons. Since we harvest QR neurons for queries in different subject domains, we can group all neurons for a domain to obtain a set of domain-specific neurons. We experiment on a specifically constructed MMLU (Hendrycks et al. 2020) validation set with a different set of questions than those used to determine the QR neurons (see Section B in the SM for details on our experimental strategy). The results are summarised in Table 6. We observe that the accuracy of the neuron-based predictions is very close to the accuracy of the prompt-based method of using the entire model (the used templates are shown in Table A3 in the SM). This suggests that the activity of identified neurons can reflect the model\u2019s reasoning process to some extent.",
                    "strength": "strong",
                    "limitations": "Results are limited to MMLU (Hendrycks et al. 2020) dataset and specific set of questions",
                    "location": "Section 6.2 Neuron-Based Prediction",
                    "exact_quote": "The intuition behind neuron-based prediction is that for a domain-specific question, if the corresponding localized regions are properly activated, the LLM is more likely to generate truthful answers. Otherwise, the LLM may produce hallucinated answers. To this end, we test whether the correct answers to domain-specific questions can be predicted solely based on the activity of the associated neurons. Since we harvest QR neurons for queries in different subject domains, we can group all neurons for a domain to obtain a set of domain-specific neurons. We experiment on a specifically constructed MMLU (Hendrycks et al. 2020) validation set with a different set of questions than those used to determine the QR neurons (see Section B in the SM for details on our experimental strategy). The results are summarised in Table 6. We observe that the accuracy of the neuron-based predictions is very close to the accuracy of the prompt-based method of using the entire model (the used templates are shown in Table A3 in the SM). This suggests that the activity of identified neurons can reflect the model\u2019s reasoning process to some extent."
                }
            ],
            "evaluation": {
                "conclusion_justified": false,
                "robustness": "No robustness analysis available",
                "justification": "No conclusion available",
                "key_limitations": "No limitations analysis available",
                "confidence_level": ""
            }
        }
    ],
    "execution_times": {
        "single_pass_analysis_time": "105.90 seconds",
        "total_execution_time": "9197.35 seconds"
    }
}