Claim 1:
Type: methodology
Statement: It is straightforward to inject preference votes for a target model using a simple attack methodology due to the lack of quality controls.
Location: Section 3.2
Exact Quote: We argue\nthat due to the lack of quality controls (e.g. user\nverification, attention checks, etc.), it is straightforward to inject preference votes for mT using a\nsimple attack methodology.

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The lack of quality controls makes it easier to manipulate the voting system.
Key Limitations: The conclusion is based on the assumption that there are no other factors that could prevent the attack from being successful.

--------------------------------------------------

Claim 2:
Type: performance
Statement: The proposed target model attribution algorithm can detect whether a given output is sampled from a target model with high accuracy.
Location: Section 3.2
Exact Quote: We find that our detector algorithm reports very high performance (e.g.\nTPR=91.13%, and TNR=88.46% for Llama-2-7b-\nchat).

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The algorithm achieves high TPR and TNR on the arena dataset.
Key Limitations: The evaluation is conducted on a single dataset, and the performance may be different on other datasets.

--------------------------------------------------

Claim 3:
Type: result
Statement: Adversarial attacks can substantially change leaderboard rankings if adversaries get to contribute 10% votes for their model.
Location: Section 3.2
Exact Quote: Across all models,\nwe show that adversarial attacks can substantially\nchange leaderboard rankings if adversaries get to\ncontribute 10% votes for their model.

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The experiments show that adversarial attacks can significantly change the rankings of models on the leaderboard.
Key Limitations: The experiments are conducted on a single dataset, and the results may be different on other datasets.

--------------------------------------------------

Claim 4:
Type: contribution
Statement: Holistically rating a response to an open-ended and inherently subjective query is ill-defined and liable to always be arbitrary.
Location: Section 3.3
Exact Quote: We argue that holistically rating\na response to an open-ended and inherently subjective query is ill-defined and liable to always\nbe arbitrary.

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by the results of the annotation study, which show that there is low agreement between annotators on the ratings of model outputs.
Key Limitations: The annotation study is conducted on a small dataset, and the results may be different on other datasets.

--------------------------------------------------

Claim 5:
Type: contribution
Statement: Arbitrary votes are not “noise” and provide useful signals about models’\nrelative performance.
Location: Section 3.3
Exact Quote: We argue that arbitrary votes are not\n“noise” and provide useful signals about models’\nrelative performance.

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by the fact that arbitrary votes can help to identify models that perform similarly well on a substantial fraction of real-world queries.
Key Limitations: The claim is based on the assumption that there are no other factors that could influence the ratings of model outputs.

--------------------------------------------------

Claim 6:
Type: result
Statement: Establishing stronger guardrails around annotation quality can ensure higher agreement between annotators.
Location: section 3
Exact Quote: ation to encourage higher agreement between annotators (Malaviya et al., 2024).

Evidence:
Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is based on a reference to another work (Malaviya et al., 2024), but the findings of that work are not provided in the text.
Key Limitations: Lack of specific evidence to support the claim.

--------------------------------------------------

Claim 7:
Type: contribution
Statement: Open access to collected datasets can spur research to address annotation issues.
Location: section 3
Exact Quote: Public release of the collected data on open platforms will spur research to address the annotation issues we discuss in this work.

Evidence:
Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is speculative and not supported by concrete evidence.
Key Limitations: Lack of empirical data or examples to demonstrate the impact of open access on research.

--------------------------------------------------

Claim 8:
Type: result
Statement: Extending the analysis to other similar platforms can lead to added insights specific to vision language model evaluation.
Location: section 3
Exact Quote: Extending this analysis to such platforms can lead to added insights specific to vision language model evaluation.

Evidence:
Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is based on speculation and does not provide specific evidence or examples of how extending the analysis to other platforms will yield added insights.
Key Limitations: Lack of empirical data or analysis to support the claim.

--------------------------------------------------

