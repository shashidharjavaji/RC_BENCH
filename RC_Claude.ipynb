{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Processing ICLR_1.pdf...\n",
      "[                                        ] (0/1===[====                                    ] ( 1/10===[========                                ] ( 2/10===[============                            ] ( 3/10===[================                        ] ( 4/10===[====================                    ] ( 5/10===[========================                ] ( 6/10===[============================            ] ( 7/10===[================================        ] ( 8/10===[====================================    ] ( 9/10===[========================================] (10/10]\n",
      "Extracting claims...\n",
      "Analyzing evidence...\n",
      "Analyzing conclusions...\n",
      "\n",
      "=== Complete Paper Analysis ===\n",
      "\n",
      "Claim 1:\n",
      "Statement: CQCC features significantly outperform MFCC features in classifying neurodegenerative disorders with absolute improvements of 5.6% and 7.7% for Random Forest and SVM classifiers respectively\n",
      "\n",
      "Evidence:\n",
      "- CQCC features outperform baseline MFCC features with absolute increment of 5.6% and 7.7% on RF and SVM classifiers for multiple pathological classifications\n",
      "  Strength: strong\n",
      "  Limitations: Limited to specific databases D1 and D3 with two different pathologies and healthy controls\n",
      "- Numerical results showing CQCC vs MFCC performance differences across classifiers\n",
      "  Strength: strong\n",
      "  Limitations: Specific to the dataset and classifiers used\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC features provide superior performance over MFCC with specific percentage improvements for both RF and SVM classifiers in neurodegenerative disorder classification\n",
      "Justified by Evidence: Yes\n",
      "Robustness: Evidence is robust, with results demonstrated across multiple classifiers (RF and SVM) and validated on different datasets (D1 and D3). The improvements are consistent and quantifiable.\n",
      "Limitations: Testing limited to specific datasets and classifiers. No cross-validation results presented. Statistical significance of improvements not explicitly tested.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 2:\n",
      "Statement: This is the first study using sustained vowel sounds for multi neurodegenerative disorder classification and analysis\n",
      "\n",
      "Evidence:\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: No conclusion available\n",
      "Justified by Evidence: No\n",
      "Robustness: No robustness analysis available\n",
      "Limitations: No limitations analysis available\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 3:\n",
      "Statement: CQCC achieved highest classification accuracy of 99% with Random Forest classifier compared to 63.4% with SVM for binary classification\n",
      "\n",
      "Evidence:\n",
      "- CQCC achieved 99% accuracy with Random Forest classifier and 63.4% with SVM for binary classification of healthy vs pathological speech\n",
      "  Strength: strong\n",
      "  Limitations: Results only shown for one dataset (D2)\n",
      "- Numerical results shown in classification accuracy table\n",
      "  Strength: strong\n",
      "  Limitations: Raw accuracy numbers without statistical significance testing\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC achieves significantly better performance with RF (99%) compared to SVM (63.4%) for binary classification of healthy vs pathological speech\n",
      "Justified by Evidence: Yes\n",
      "Robustness: Strong quantitative evidence with clear performance metrics. Results presented in standardized format with direct comparisons across multiple feature types.\n",
      "Limitations: Limited to single dataset (D2). No cross-validation or statistical significance testing. Potential overfitting not addressed.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 4:\n",
      "Statement: CQCC features show superior classification performance between different pathologies, achieving 90.3% accuracy with RF and 80.7% with SVM\n",
      "\n",
      "Evidence:\n",
      "- Classification results between pathologies showing CQCC achieves 90.3% accuracy with RF and 80.7% with SVM\n",
      "  Strength: strong\n",
      "  Limitations: Results are shown specifically for database D1 and D3 with multiple pathologies\n",
      "- Table showing exact accuracy values for CQCC with RF and SVM\n",
      "  Strength: strong\n",
      "  Limitations: Limited to specific experimental setup and datasets used\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC demonstrates superior classification performance between different pathologies with RF and SVM classifiers\n",
      "Justified by Evidence: Yes\n",
      "Robustness: Strong quantitative evidence across multiple classifiers and pathologies. Results consistent with other performance metrics in the study.\n",
      "Limitations: Limited to specific databases D1 and D3. No cross-validation results. Generalizability to other pathologies not demonstrated.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 5:\n",
      "Statement: CQCC features show clearer separation between neurodegenerative disorders in LDA plots compared to MFCC\n",
      "\n",
      "Evidence:\n",
      "- The LDA plot shows MFCC features have moderate overlap between classes while CQCC features exhibit clearer separation between disorders\n",
      "  Strength: strong\n",
      "  Limitations: Visual interpretation of plot data\n",
      "- MFCC shows only moderate separation between classes\n",
      "  Strength: moderate\n",
      "  Limitations: Qualitative observation\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC features provide better class separation in LDA plots compared to MFCC features\n",
      "Justified by Evidence: Yes\n",
      "Robustness: Visual evidence supported by detailed analysis of separation patterns. Consistent with numerical performance results.\n",
      "Limitations: Relies heavily on visual interpretation. Quantitative metrics of separation not provided. Subjective nature of visual analysis.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 6:\n",
      "Statement: CQCC features outperform traditional acoustic measures like Jitter, Shimmer and Teager Energy\n",
      "\n",
      "Evidence:\n",
      "- Classification accuracy comparison between CQCC and traditional measures using RF classifier shows CQCC at 99.0% vs Jitter (63.4%), Shimmer (62.9%), and Teager Energy (65.3%)\n",
      "  Strength: strong\n",
      "  Limitations: Results specific to binary classification between healthy and pathological speech\n",
      "- Multi-pathological classification results showing CQCC outperforming traditional measures\n",
      "  Strength: strong\n",
      "  Limitations: Results specific to classification between multiple pathologies\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: CQCC features significantly outperform traditional acoustic measures across multiple classification tasks\n",
      "Justified by Evidence: Yes\n",
      "Robustness: Strong quantitative evidence across multiple feature types and classification tasks. Consistent performance patterns observed.\n",
      "Limitations: Limited to specific datasets and classifiers. No cross-validation or statistical significance testing.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "from anthropic import Anthropic\n",
    "import json\n",
    "import datetime\n",
    "import pymupdf4llm\n",
    "from typing import Dict, List, Any\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import os \n",
    "\n",
    "class PaperAnalyzer:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-3-5-sonnet-20241022\"\n",
    "        self.paper_text = None\n",
    "        self.execution_times = {\n",
    "        \"claims_analysis\": 0,\n",
    "        \"evidence_analysis\": 0,\n",
    "        \"conclusions_analysis\": 0,\n",
    "        \"total_time\": 0\n",
    "        }\n",
    "\n",
    "\n",
    "    def extract_text_from_pdf(self, filename: str) -> str:\n",
    "        \"\"\"Extract text from PDF file using PyMuPDF\"\"\"\n",
    "        try:\n",
    "            self.paper_text = pymupdf4llm.to_markdown(filename)\n",
    "            return self.paper_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from PDF: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _get_claude_response(self, prompt: str) -> str:\n",
    "        \"\"\"Helper method to get response from Claude\"\"\"\n",
    "        # time.sleep(45)  # Rate limiting\n",
    "        message = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            system=\"You are a helpful assistant specialized in analyzing research papers.\",\n",
    "            max_tokens=8192,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "\n",
    "    def get_claims(self, filename: str) -> Dict:\n",
    "        \"\"\"Extract all claims from the paper\"\"\"\n",
    "        if not self.paper_text:\n",
    "            text = self.extract_text_from_pdf(filename)\n",
    "        else:\n",
    "            text = self.paper_text\n",
    "        \n",
    "        if not self.paper_text:\n",
    "            raise Exception(\"Failed to extract text from PDF\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        claims_prompt = f\"\"\"\n",
    "        Analyze this research paper and extract ALL possible claims made by the authors.\n",
    "        Paper text: {text}\n",
    "        \n",
    "        Your task is to identify all statements in the text that meet the following criteria for a claim:\n",
    "        1. Makes a specific, testable assertion about results, methods, or contributions\n",
    "        2. Represents a novel finding, improvement, or advancement\n",
    "        3. Presents a clear position or conclusion\n",
    "\n",
    "        Make sure to:\n",
    "        1. Include both major and minor claims\n",
    "        2. Don't miss any claims\n",
    "        3. Present each claim as a separate item\n",
    "        \n",
    "        Return ONLY the following JSON structure:\n",
    "        {{\n",
    "            \"claims\": [\n",
    "                {{\n",
    "                    \"claim_id\": 1,\n",
    "                    \"claim_text\": \"statement of the claim\",\n",
    "                    \"location\": \"section/paragraph where this claim appears\",\n",
    "                    \"claim_type\": \"Nature of the claim\",\n",
    "                    \"exact_quote\": \"complete verbatim text containing the claim\"\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        response = self._get_claude_response(claims_prompt)\n",
    "        self.execution_times[\"claims_analysis\"] = time.time() - start_time\n",
    "\n",
    "        return self._parse_json_response(response)\n",
    "\n",
    "    def analyze_evidence(self, filename: str, claims: Dict) -> List[Dict]:\n",
    "        \"\"\"Find evidence for each claim\"\"\"\n",
    "        if not self.paper_text:\n",
    "            text = self.extract_text_from_pdf(filename)\n",
    "        else:\n",
    "            text = self.paper_text\n",
    "        start_time = time.time()\n",
    "\n",
    "        evidence_results = []\n",
    "        \n",
    "        for claim in claims['claims']:\n",
    "            evidence_prompt = f\"\"\"\n",
    "            Paper text: {text}\n",
    "            \n",
    "            For the following claim from the paper:\n",
    "            \"{claim['claim_text']}\"\n",
    "            \n",
    "            Please identify relevant evidence that:\n",
    "            1. Directly supports or contradicts the claim's specific assertion\n",
    "            2. Is presented with experimental results, data, or concrete examples\n",
    "            3. Can be traced to specific methods, results, or discussion sections\n",
    "            4. Is not from the abstract or introduction\n",
    "\n",
    "            If NO evidence is found for the given Claim, return:\n",
    "            {{\n",
    "                \"claim_id\": {claim['claim_id']},\n",
    "                \"evidence\": [],\n",
    "                \"no_evidence_reason\": \"Explain why no evidence was found (e.g., 'Claim is unsupported', 'Claim is theoretical without empirical evidence', etc.)\"\n",
    "            }}\n",
    "            ELSE:\n",
    "            Return ONLY the following JSON structure:\n",
    "            {{\n",
    "                \"claim_id\": {claim['claim_id']},\n",
    "                \"evidence\": [\n",
    "                    {{\n",
    "                        \"evidence_id\": 1,\n",
    "                        \"evidence_text\": \"specific experimental result/data point\",\n",
    "                        \"evidence_type\": \"primary/secondary\",\n",
    "                        \"strength\": \"strong/moderate/weak\",\n",
    "                        \"limitations\": \"stated limitations or assumptions\",\n",
    "                        \"location\": \"specific section & paragraph\",\n",
    "                        \"exact_quote\": \"verbatim text from paper\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "\n",
    "            response = self._get_claude_response(evidence_prompt)\n",
    "            self.execution_times[\"evidence_analysis\"] = time.time() - start_time\n",
    "\n",
    "            result = self._parse_json_response(response)\n",
    "            if result:\n",
    "                evidence_results.append(result)\n",
    "                \n",
    "        return evidence_results\n",
    "\n",
    "    def analyze_conclusions(self, filename: str, claims: Dict, evidence_results: List[Dict]) -> Dict:\n",
    "        \"\"\"Analyze conclusions considering claims and evidence\"\"\"\n",
    "        if not self.paper_text:\n",
    "            text = self.extract_text_from_pdf(filename)\n",
    "        else:\n",
    "            text = self.paper_text\n",
    " \n",
    "        def build_evidence_summary(claim_id):\n",
    "            claim_evidence = next((e['evidence'] for e in evidence_results if e.get('claim_id') == claim_id), [])\n",
    "            evidence_text = []\n",
    "            for idx, evidence in enumerate(claim_evidence, 1):\n",
    "                evidence_text.append(\n",
    "                    f\"  Evidence {idx}:\\n\"\n",
    "                    f\"    - Text: {evidence.get('evidence_text', 'No text provided')}\\n\"\n",
    "                    f\"    - Strength: {evidence.get('strength', 'Not specified')}\\n\"\n",
    "                    f\"    - Limitations: {evidence.get('limitations', 'None specified')}\\n\"\n",
    "                    f\"    - Location: {evidence.get('location', 'Location not specified')}\"\n",
    "                )\n",
    "            return \"\\n\".join(evidence_text)\n",
    "\n",
    "        analysis_sections = []\n",
    "        for claim in claims.get('claims', []):\n",
    "            claim_id = claim.get('claim_id')\n",
    "            claim_section = (\n",
    "                f\"\\nClaim {claim_id}:\\n\"\n",
    "                f\"Statement: {claim.get('claim_text', 'No text provided')}\\n\"\n",
    "                f\"Location: {claim.get('location', 'Location not specified')}\\n\"\n",
    "                f\"\\nEvidence Summary:\\n{build_evidence_summary(claim_id)}\"\n",
    "            )\n",
    "            analysis_sections.append(claim_section)\n",
    "\n",
    "        full_analysis = \"\\n\".join(analysis_sections)\n",
    "\n",
    "        conclusions_prompt = f\"\"\"\n",
    "        Paper text: {text}\n",
    "        \n",
    "        Analyze the following claims and their supporting evidence:\n",
    "        {full_analysis}\n",
    "\n",
    "        For each claim, provide a comprehensive conclusion analysis following these guidelines:\n",
    "\n",
    "        1. Evidence Assessment:\n",
    "        - Evaluate the strength and quality of ALL evidence presented\n",
    "        - Consider both supporting and contradicting evidence\n",
    "        - Assess the methodology and reliability of evidence\n",
    "\n",
    "        2. Conclusion Analysis:\n",
    "        - Determine what the authors concluded about each claim\n",
    "        - Evaluate if conclusions are justified by the evidence\n",
    "        - Consider the relationship between evidence quality and conclusion strength\n",
    "\n",
    "        3. Robustness Evaluation:\n",
    "        - Assess how well the evidence supports the conclusions\n",
    "        - Consider methodological strengths and weaknesses\n",
    "        - Evaluate the consistency of evidence across different sources\n",
    "\n",
    "        4. Limitations Analysis:\n",
    "        - Identify specific limitations in both evidence and conclusions\n",
    "        - Consider gaps in methodology or data\n",
    "        - Note any potential biases or confounding factors\n",
    "\n",
    "        Return ONLY the following JSON structure:\n",
    "        {{\n",
    "            \"conclusions\": [\n",
    "                {{\n",
    "                    \"claim_id\": number,\n",
    "                    \"author_conclusion\": \"detailed description of authors' conclusion based on evidence\",\n",
    "                    \"conclusion_justified\": true/false,\n",
    "                    \"justification_explanation\": \"detailed explanation of why conclusion is/isn't justified\",\n",
    "                    \"robustness_analysis\": \"comprehensive analysis of evidence strength and reliability\",\n",
    "                    \"limitations\": \"specific limitations and caveats\",\n",
    "                    \"location\": \"section/paragraph where conclusion appears\",\n",
    "                    \"evidence_alignment\": \"analysis of how well evidence aligns with conclusion\",\n",
    "                    \"confidence_level\": \"high/medium/low based on evidence quality\",\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        response = self._get_claude_response(conclusions_prompt)\n",
    "        result = self._parse_json_response(response)\n",
    "\n",
    "        if not result or not isinstance(result, dict) or 'conclusions' not in result:\n",
    "            return {\"conclusions\": []}\n",
    "\n",
    "        claims_ids = set(claim['claim_id'] for claim in claims.get('claims', []))\n",
    "        all_conclusions = result.get('conclusions', [])\n",
    "        start_time = time.time()\n",
    "\n",
    "        complete_conclusions = []\n",
    "        for claim_id in claims_ids:\n",
    "            existing_conclusion = next(\n",
    "                (c for c in all_conclusions if c.get('claim_id') == claim_id),\n",
    "                None\n",
    "            )\n",
    "            \n",
    "            if existing_conclusion:\n",
    "                complete_conclusions.append(existing_conclusion)\n",
    "            else:\n",
    "                complete_conclusions.append({\n",
    "                    \"claim_id\": claim_id,\n",
    "                    \"author_conclusion\": \"No conclusion available\",\n",
    "                    \"conclusion_justified\": False,\n",
    "                    \"justification_explanation\": \"Analysis not available\",\n",
    "                    \"robustness_analysis\": \"No robustness analysis available\",\n",
    "                    \"limitations\": \"No limitations analysis available\",\n",
    "                    \"location\": \"Location not specified\",\n",
    "                    \"evidence_alignment\": \"No alignment analysis available\",\n",
    "                    \"confidence_level\": \"low\"\n",
    "                })\n",
    "        self.execution_times[\"conclusions_analysis\"] = time.time() - start_time\n",
    "\n",
    "        return {\n",
    "            \"conclusions\": complete_conclusions,\n",
    "            \"analysis_metadata\": {\n",
    "                \"total_claims_analyzed\": len(claims_ids),\n",
    "                \"claims_with_conclusions\": len(all_conclusions),\n",
    "                \"analysis_timestamp\": str(datetime.datetime.now())\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    def _parse_json_response(self, response: str) -> Dict:\n",
    "        \"\"\"Parse JSON response and handle errors\"\"\"\n",
    "        try:\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in response\")\n",
    "                \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            return json.loads(json_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {e}\")\n",
    "            print(\"Raw response:\", response)\n",
    "            return None\n",
    "\n",
    "    def combine_results(self, claims: Dict, evidence_results: List[Dict], conclusions: Dict) -> Dict:\n",
    "        \"\"\"Combine all analysis results into a final structured format\"\"\"\n",
    "        final_results = {\n",
    "            \"paper_analysis\": []\n",
    "        }\n",
    "        \n",
    "        conclusions_dict = {\n",
    "            c['claim_id']: c \n",
    "            for c in conclusions.get('conclusions', [])\n",
    "        } if conclusions else {}\n",
    "        \n",
    "        evidence_dict = {\n",
    "            e['claim_id']: e.get('evidence', [])\n",
    "            for e in evidence_results if isinstance(e, dict)\n",
    "        }\n",
    "        \n",
    "        for claim in claims.get('claims', []):\n",
    "            claim_id = claim['claim_id']\n",
    "            conclusion = conclusions_dict.get(claim_id, {})\n",
    "            evidence = evidence_dict.get(claim_id, [])\n",
    "            \n",
    "            analysis = {\n",
    "                \"claim_id\": claim_id,\n",
    "                \"claim\": claim.get('claim_text', ''),\n",
    "                \"claim_location\": claim.get('location', 'Location not specified'),\n",
    "                \"evidence\": evidence,\n",
    "                \"evidence_locations\": [ev.get('location', 'Location not specified') for ev in evidence],\n",
    "                \"conclusion\": {\n",
    "                    \"author_conclusion\": conclusion.get('author_conclusion', 'No conclusion available'),\n",
    "                    \"conclusion_justified\": conclusion.get('conclusion_justified', False),\n",
    "                    \"robustness_analysis\": conclusion.get('robustness_analysis', 'No robustness analysis available'),\n",
    "                    \"limitations\": conclusion.get('limitations', 'No limitations analysis available'),\n",
    "                    \"conclusion_location\": conclusion.get('location', 'Location not specified')\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            final_results['paper_analysis'].append(analysis)\n",
    "\n",
    "            # Add timing information\n",
    "        final_results[\"execution_times\"] = {\n",
    "            \"claims_analysis_time\": f\"{self.execution_times['claims_analysis']:.2f} seconds\",\n",
    "            \"evidence_analysis_time\": f\"{self.execution_times['evidence_analysis']:.2f} seconds\",\n",
    "            \"conclusions_analysis_time\": f\"{self.execution_times['conclusions_analysis']:.2f} seconds\",\n",
    "            \"total_execution_time\": f\"{self.execution_times['total_time']:.2f} seconds\"\n",
    "        }\n",
    "        \n",
    "        return final_results\n",
    "\n",
    "    def print_analysis_results(self, final_results: Dict):\n",
    "        \"\"\"Print the analysis results in a readable format\"\"\"\n",
    "        print(\"\\n=== Complete Paper Analysis ===\\n\")\n",
    "        \n",
    "        for analysis in final_results['paper_analysis']:\n",
    "            print(f\"Claim {analysis['claim_id']}:\")\n",
    "            print(f\"Statement: {analysis['claim']}\")\n",
    "            print(\"\\nEvidence:\")\n",
    "            for evidence in analysis['evidence']:\n",
    "                print(f\"- {evidence['evidence_text']}\")\n",
    "                print(f\"  Strength: {evidence['strength']}\")\n",
    "                print(f\"  Limitations: {evidence['limitations']}\")\n",
    "            \n",
    "            print(\"\\nConclusion:\")\n",
    "            print(f\"Author's Conclusion: {analysis['conclusion']['author_conclusion']}\")\n",
    "            print(f\"Justified by Evidence: {'Yes' if analysis['conclusion']['conclusion_justified'] else 'No'}\")\n",
    "            print(f\"Robustness: {analysis['conclusion']['robustness_analysis']}\")\n",
    "            print(f\"Limitations: {analysis['conclusion']['limitations']}\")\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "def main():\n",
    "    # Initialize analyzer\n",
    "    api_key = \"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\"\n",
    "    analyzer = PaperAnalyzer(api_key)\n",
    "    \n",
    "    # Analyze paper\n",
    "    filename = \"ICLR_1.pdf\"\n",
    "    basefile_name = Path(filename).stem\n",
    "    try:\n",
    "        # Extract text once at the beginning\n",
    "\n",
    "        total_start_time = time.time()\n",
    "\n",
    "        print(\"Extracting text from PDF...\")\n",
    "        analyzer.extract_text_from_pdf(filename)\n",
    "        \n",
    "        # Step 1: Extract claims\n",
    "        print(\"Extracting claims...\")\n",
    "        claims = analyzer.get_claims(filename)\n",
    "\n",
    "        # Step 2: Analyze evidence\n",
    "        print(\"Analyzing evidence...\")\n",
    "        evidence_results = analyzer.analyze_evidence(filename, claims)\n",
    "        \n",
    "        # Step 3: Analyze conclusions\n",
    "        print(\"Analyzing conclusions...\")\n",
    "        conclusions = analyzer.analyze_conclusions(filename, claims, evidence_results)\n",
    "        \n",
    "\n",
    "\n",
    "        analyzer.execution_times[\"total_time\"] = time.time() - total_start_time\n",
    "\n",
    "        # Combine results\n",
    "        final_results = analyzer.combine_results(claims, evidence_results, conclusions)\n",
    "        \n",
    "        # Print results\n",
    "        analyzer.print_analysis_results(final_results)\n",
    "        os.makedirs('claude_one_by_one', exist_ok=True)\n",
    "\n",
    "        # Save results\n",
    "        with open(f'claude_one_by_one/{basefile_name}_analysis.json', 'w') as f:\n",
    "            json.dump(final_results, f, indent=4)\n",
    "        # print(\"Results saved to 'claude_detailed_analysis_results.json'\")\n",
    "        \n",
    "        # Save intermediate results\n",
    "        intermediate_results = {\n",
    "            \"claims\": claims,\n",
    "            \"evidence\": evidence_results,\n",
    "            \"conclusions\": conclusions,\n",
    "            \"execution_times\": final_results[\"execution_times\"]\n",
    "\n",
    "            \n",
    "        }\n",
    "        with open(f'claude_one_by_one/{basefile_name}_intermediate.json', 'w') as f:\n",
    "            json.dump(intermediate_results, f, indent=4)\n",
    "        # print(\"Intermediate results saved to 'claude_intermediate_results.json'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing paper: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Processing ICLR_1.pdf...\n",
      "[                                        ] (0/1===[====                                    ] ( 1/10===[========                                ] ( 2/10===[============                            ] ( 3/10===[================                        ] ( 4/10===[====================                    ] ( 5/10===[========================                ] ( 6/10===[============================            ] ( 7/10===[================================        ] ( 8/10===[====================================    ] ( 9/10===[========================================] (10/10]\n",
      "Analyzing paper...\n",
      "\n",
      "=== Complete Paper Analysis ===\n",
      "\n",
      "Claim 1:\n",
      "Statement: CQCC features outperform MFCC features for neurodegenerative disorder classification\n",
      "\n",
      "Evidence:\n",
      "- Binary classification (healthy vs pathological) results showing CQCC superiority\n",
      "  Strength: strong\n",
      "  Limitations: Limited to two classifiers (RF and SVM)\n",
      "- Multi-class classification results\n",
      "  Strength: strong\n",
      "  Limitations: Specific to the datasets used\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: Multiple experiments with different classifiers consistently show CQCC outperforming MFCC\n",
      "Justified by Evidence: Yes\n",
      "Robustness: high\n",
      "Limitations: Results specific to tested datasets and classifiers\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 2:\n",
      "Statement: CQCC provides better class separation compared to MFCC\n",
      "\n",
      "Evidence:\n",
      "- LDA visualization comparison\n",
      "  Strength: moderate\n",
      "  Limitations: Visual analysis is somewhat subjective\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: Visual evidence supported by quantitative classification results\n",
      "Justified by Evidence: Yes\n",
      "Robustness: medium\n",
      "Limitations: Relies partially on visual interpretation\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 3:\n",
      "Statement: Form-invariance property of CQT provides advantage over STFT\n",
      "\n",
      "Evidence:\n",
      "- Mathematical proof of form-invariance\n",
      "  Strength: strong\n",
      "  Limitations: Theoretical rather than empirical evidence\n",
      "\n",
      "Conclusion:\n",
      "Author's Conclusion: Mathematical derivation provides strong theoretical foundation\n",
      "Justified by Evidence: Yes\n",
      "Robustness: high\n",
      "Limitations: Lacks direct empirical validation\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Error analyzing paper: 'loca tion'\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pymupdf4llm\n",
    "import time\n",
    "import datetime\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class SinglePassPaperAnalyzer:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-3-5-sonnet-20241022\"\n",
    "        self.paper_text = None\n",
    "        self.execution_times = {\n",
    "        \"single_pass_analysis\": 0,\n",
    "        \"total_time\": 0\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "    def extract_text_from_pdf(self, filename: str) -> str:\n",
    "        \"\"\"Extract text from PDF file using PyMuPDF\"\"\"\n",
    "        try:\n",
    "            self.paper_text = pymupdf4llm.to_markdown(filename)\n",
    "            return self.paper_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from PDF: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def analyze_paper(self, filename):\n",
    "        \"\"\"Perform comprehensive single-pass analysis of the paper\"\"\"\n",
    "        if not self.paper_text:\n",
    "            text = self.extract_text_from_pdf(filename)\n",
    "        else:\n",
    "            text = self.paper_text\n",
    "            \n",
    "        if not text:\n",
    "            raise Exception(\"Failed to extract text from PDF\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        comprehensive_prompt = f\"\"\"\n",
    "        Analyze this research paper and provide a comprehensive evaluation.\n",
    "        Paper text: {text}\n",
    "\n",
    "        Follow these guidelines:\n",
    "\n",
    "        1. Identify ALL claims in the paper where each claim:\n",
    "           - Makes a specific, verifiable assertion\n",
    "           - Is supported by concrete evidence\n",
    "           - Represents findings, contributions, or methodological advantages\n",
    "           - Can be from any section except abstract\n",
    "\n",
    "        2. For each identified claim:\n",
    "           - Extract ALL supporting or contradicting evidence (experimental results, data, or methodology)\n",
    "           - Evaluate the evidence strength and limitations\n",
    "           - Assess how well conclusions align with evidence\n",
    "\n",
    "        Return ONLY the following JSON structure:\n",
    "        {{\n",
    "            \"analysis\": [\n",
    "                {{\n",
    "                    \"claim_id\": number,\n",
    "                    \"claim\": {{\n",
    "                        \"text\": \"statement of the claim\",\n",
    "                        \"type\": \"methodology/result/contribution/performance\",\n",
    "                        \"location\": \"section/paragraph\",\n",
    "                        \"exact_quote\": \"verbatim text from paper\"\n",
    "                    }},\n",
    "                    \"evidence\": [\n",
    "                        {{\n",
    "                            \"evidence_text\": \"specific experimental result/data\",\n",
    "                            \"strength\": \"strong/moderate/weak\",\n",
    "                            \"limitations\": \"specific limitations\",\n",
    "                            \"location\": \"section/paragraph\",\n",
    "                            \"exact_quote\": \"verbatim text from paper\"\n",
    "                        }}\n",
    "                    ],\n",
    "                    \"evaluation\": {{\n",
    "                        \"conclusion_justified\": true/false,\n",
    "                        \"robustness\": \"high/medium/low\",\n",
    "                        \"justification\": \"explanation of evidence-conclusion alignment\",\n",
    "                        \"key_limitations\": \"critical limitations affecting validity\",\n",
    "                        \"confidence_level\": \"high/medium/low\"\n",
    "                    }}\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "        Ensure:\n",
    "        - ALL substantive claims are captured\n",
    "        - Evaluations are objective and well-reasoned\n",
    "        - All locations and quotes are precise\n",
    "        - Multiple pieces of evidence per claim are included when present\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add rate limiting\n",
    "        # time.sleep(45)\n",
    "        \n",
    "        # Get response from Claude\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            system=\"You are a helpful assistant specialized in analyzing research papers.\",\n",
    "            max_tokens=8192,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": comprehensive_prompt}\n",
    "            ]\n",
    "        )\n",
    "        self.execution_times[\"single_pass_analysis\"] = time.time() - start_time\n",
    "\n",
    "        return self._parse_json_response(response.content[0].text)\n",
    "\n",
    "    def _parse_json_response(self, response: str) -> Dict:\n",
    "        \"\"\"Parse JSON response and handle errors\"\"\"\n",
    "        try:\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in response\")\n",
    "            json_str = response[start_idx:end_idx]\n",
    "            return json.loads(json_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {e}\")\n",
    "            print(\"Raw response:\", response)\n",
    "            return None\n",
    "\n",
    "    def combine_results(self, analysis_results: Dict) -> tuple:\n",
    "        \"\"\"Restructure the single-pass analysis results into the desired format\"\"\"\n",
    "        claims = {\n",
    "            \"claims\": [\n",
    "                {\n",
    "                    \"claim_id\": item[\"claim_id\"],\n",
    "                    \"claim_text\": item[\"claim\"][\"text\"],\n",
    "                    \"location\": item[\"claim\"][\"location\"],\n",
    "                    \"claim_type\": item[\"claim\"][\"type\"],\n",
    "                    \"exact_quote\": item[\"claim\"][\"exact_quote\"]\n",
    "                }\n",
    "                for item in analysis_results[\"analysis\"]\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        evidence_results = [\n",
    "            {\n",
    "                \"claim_id\": item[\"claim_id\"],\n",
    "                \"evidence\": [\n",
    "                    {\n",
    "                        \"evidence_id\": idx + 1,\n",
    "                        \"evidence_text\": ev[\"evidence_text\"],\n",
    "                        \"evidence_type\": \"primary\",\n",
    "                        \"strength\": ev[\"strength\"],\n",
    "                        \"limitations\": ev[\"limitations\"],\n",
    "                        \"location\": ev[\"location\"],\n",
    "                        \"exact_quote\": ev[\"exact_quote\"]\n",
    "                    }\n",
    "                    for idx, ev in enumerate(item[\"evidence\"])\n",
    "                ]\n",
    "            }\n",
    "            for item in analysis_results[\"analysis\"]\n",
    "        ]\n",
    "        \n",
    "        conclusions = {\n",
    "            \"conclusions\": [\n",
    "                {\n",
    "                    \"claim_id\": item[\"claim_id\"],\n",
    "                    \"author_conclusion\": item[\"evaluation\"][\"justification\"],\n",
    "                    \"conclusion_justified\": item[\"evaluation\"][\"conclusion_justified\"],\n",
    "                    \"robustness_analysis\": item[\"evaluation\"][\"robustness\"],\n",
    "                    \"limitations\": item[\"evaluation\"][\"key_limitations\"],\n",
    "                    \"evidence_alignment\": item[\"evaluation\"][\"justification\"],\n",
    "                    \"confidence_level\": item[\"evaluation\"][\"confidence_level\"]\n",
    "                }\n",
    "                for item in analysis_results[\"analysis\"]\n",
    "            ],\n",
    "            \"analysis_metadata\": {\n",
    "                \"total_claims_analyzed\": len(analysis_results[\"analysis\"]),\n",
    "                \"claims_with_conclusions\": len(analysis_results[\"analysis\"]),\n",
    "                \"analysis_timestamp\": str(datetime.datetime.now())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        final_results = {\n",
    "            \"paper_analysis\": []\n",
    "        }\n",
    "        \n",
    "        for item in analysis_results[\"analysis\"]:\n",
    "            claim_id = item[\"claim_id\"]\n",
    "            analysis = {\n",
    "                \"claim_id\": claim_id,\n",
    "                \"claim\": item[\"claim\"][\"text\"],\n",
    "                \"claim_location\": item[\"claim\"][\"location\"],\n",
    "                \"evidence\": item[\"evidence\"],\n",
    "                \"evidence_locations\": [ev[\"location\"] for ev in item[\"evidence\"]],\n",
    "                \"conclusion\": {\n",
    "                    \"author_conclusion\": item[\"evaluation\"][\"justification\"],\n",
    "                    \"conclusion_justified\": item[\"evaluation\"][\"conclusion_justified\"],\n",
    "                    \"robustness_analysis\": item[\"evaluation\"][\"robustness\"],\n",
    "                    \"limitations\": item[\"evaluation\"][\"key_limitations\"],\n",
    "                    \"conclusion_location\": item[\"claim\"][\"location\"]\n",
    "                }\n",
    "            }\n",
    "            final_results[\"paper_analysis\"].append(analysis)\n",
    "        final_results[\"execution_times\"] = {\n",
    "        \"single_pass_analysis_time\": f\"{self.execution_times['single_pass_analysis']:.2f} seconds\",\n",
    "        \"total_execution_time\": f\"{self.execution_times['total_time']:.2f} seconds\"\n",
    "        }\n",
    "\n",
    "        \n",
    "        return claims, evidence_results, conclusions, final_results\n",
    "\n",
    "    def print_analysis_results(self, final_results: Dict):\n",
    "        \"\"\"Print the analysis results in a readable format\"\"\"\n",
    "        print(\"\\n=== Complete Paper Analysis ===\\n\")\n",
    "        \n",
    "        for analysis in final_results['paper_analysis']:\n",
    "            print(f\"Claim {analysis['claim_id']}:\")\n",
    "            print(f\"Statement: {analysis['claim']}\")\n",
    "            print(\"\\nEvidence:\")\n",
    "            for evidence in analysis['evidence']:\n",
    "                print(f\"- {evidence['evidence_text']}\")\n",
    "                print(f\"  Strength: {evidence['strength']}\")\n",
    "                print(f\"  Limitations: {evidence['limitations']}\")\n",
    "            \n",
    "            print(\"\\nConclusion:\")\n",
    "            print(f\"Author's Conclusion: {analysis['conclusion']['author_conclusion']}\")\n",
    "            print(f\"Justified by Evidence: {'Yes' if analysis['conclusion']['conclusion_justified'] else 'No'}\")\n",
    "            print(f\"Robustness: {analysis['conclusion']['robustness_analysis']}\")\n",
    "            print(f\"Limitations: {analysis['conclusion']['limitations']}\")\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "    def save_results(self, results: Dict, base_filename: str):\n",
    "        \"\"\"Save analysis results to files\"\"\"\n",
    "        output_dir = Path('claude_all_at_once')\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "\n",
    "\n",
    "        results[\"execution_times\"] = {\n",
    "        \"single_pass_analysis_time\": f\"{self.execution_times['single_pass_analysis']:.2f} seconds\",\n",
    "        \"total_execution_time\": f\"{self.execution_times['total_time']:.2f} seconds\"\n",
    "        \n",
    "        }\n",
    "        # Save full JSON results\n",
    "        json_path = output_dir / f'{base_filename}_analysis.json'\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        \n",
    "        # Save readable text summary\n",
    "        text_path = output_dir / f'{base_filename}_summary.txt'\n",
    "        with open(text_path, 'w', encoding='utf-8') as f:\n",
    "            for analysis in results['analysis']:\n",
    "                f.write(f\"Claim {analysis['claim_id']}:\\n\")\n",
    "                f.write(f\"Type: {analysis['claim']['type']}\\n\")\n",
    "                f.write(f\"Statement: {analysis['claim']['text']}\\n\")\n",
    "                f.write(f\"Location: {analysis['claim']['location']}\\n\")\n",
    "                f.write(f\"Exact Quote: {analysis['claim']['exact_quote']}\\n\\n\")\n",
    "                \n",
    "                f.write(\"Evidence:\\n\")\n",
    "                for evidence in analysis['evidence']:\n",
    "                    f.write(f\"- Evidence Text: {evidence['evidence_text']}\\n\")\n",
    "                    f.write(f\"  Strength: {evidence['strength']}\\n\")\n",
    "                    f.write(f\"  Location: {evidence['loca tion']}\\n\")\n",
    "                    f.write(f\"  Limitations: {evidence['limitations']}\\n\")\n",
    "                    f.write(f\"  Exact Quote: {evidence['exact_quote']}\\n\\n\")\n",
    "                \n",
    "                eval_data = analysis['evaluation']\n",
    "                f.write(\"Evaluation:\\n\")\n",
    "                f.write(f\"Conclusion Justified: {'Yes' if eval_data['conclusion_justified'] else 'No'}\\n\")\n",
    "                f.write(f\"Robustness: {eval_data['robustness']}\\n\")\n",
    "                f.write(f\"Confidence Level: {eval_data['confidence_level']}\\n\")\n",
    "                f.write(f\"Justification: {eval_data['justification']}\\n\")\n",
    "                f.write(f\"Key Limitations: {eval_data['key_limitations']}\\n\")\n",
    "                \n",
    "                f.write(\"\\n\" + \"-\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        stats_path = output_dir / f'{base_filename}_statistics.txt'\n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            total_claims = len(results['analysis'])\n",
    "            justified_claims = sum(1 for a in results['analysis'] \n",
    "                                 if a['evaluation']['conclusion_justified'])\n",
    "            \n",
    "            f.write(\"Analysis Statistics:\\n\")\n",
    "            f.write(f\"Total Claims Analyzed: {total_claims}\\n\")\n",
    "            f.write(f\"Justified Claims: {justified_claims}\\n\")\n",
    "            \n",
    "            # Evidence strength distribution\n",
    "            strength_levels = {}\n",
    "            for analysis in results['analysis']:\n",
    "                for evidence in analysis['evidence']:\n",
    "                    strength = evidence['strength']\n",
    "                    strength_levels[strength] = strength_levels.get(strength, 0) + 1\n",
    "            \n",
    "            f.write(\"\\nEvidence Strength Distribution:\\n\")\n",
    "            total_evidence = sum(strength_levels.values())\n",
    "            for strength, count in strength_levels.items():\n",
    "                f.write(f\"{strength}: {count} pieces ({count/total_evidence*100:.1f}%)\\n\")\n",
    "\n",
    "def main():\n",
    "    # Initialize analyzer\n",
    "    api_key = \"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\"\n",
    "    analyzer = SinglePassPaperAnalyzer(api_key)\n",
    "    \n",
    "    # Analyze paper\n",
    "    filename = \"ICLR_1.pdf\"\n",
    "    try:\n",
    "\n",
    "        total_start_time = time.time()\n",
    "\n",
    "        # Extract text once at the beginning\n",
    "        print(\"Extracting text from PDF...\")\n",
    "        analyzer.extract_text_from_pdf(filename)\n",
    "        \n",
    "        # Perform single-pass analysis\n",
    "        print(\"Analyzing paper...\")\n",
    "        analysis_results = analyzer.analyze_paper(filename)\n",
    "\n",
    "        analyzer.execution_times[\"total_time\"] = time.time() - total_start_time\n",
    "\n",
    "        \n",
    "        # Restructure results into desired format\n",
    "        claims, evidence_results, conclusions, final_results = analyzer.combine_results(analysis_results)\n",
    "        \n",
    "        # Print results\n",
    "        analyzer.print_analysis_results(final_results)\n",
    "        \n",
    "        # Save detailed results\n",
    "        # with open('detailed_analysis_results.json', 'w') as f:\n",
    "        #     json.dump(final_results, f, indent=4)\n",
    "        # print(\"Results saved to 'detailed_analysis_results.json'\")\n",
    "        \n",
    "        # Save intermediate results\n",
    "        intermediate_results = {\n",
    "            \"claims\": claims,\n",
    "            \"evidence\": evidence_results,\n",
    "            \"conclusions\": conclusions,\n",
    "            \"execution_times\": final_results[\"execution_times\"]\n",
    "\n",
    "        }\n",
    "        # with open('intermediate_results.json', 'w') as f:\n",
    "        #     json.dump(intermediate_results, f, indent=4)\n",
    "        # print(\"Intermediate results saved to 'intermediate_results.json'\")\n",
    "        \n",
    "        # Save additional analysis outputs\n",
    "        base_filename = Path(filename).stem\n",
    "        analyzer.save_results(analysis_results, base_filename)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing paper: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of ICLR_1.pdf\n",
      "Extracting text from PDF...\n",
      "Processing ICLR_1.pdf...\n",
      "[                                        ] (0/1===[====                                    ] ( 1/10===[========                                ] ( 2/10===[============                            ] ( 3/10===[================                        ] ( 4/10===[====================                    ] ( 5/10===[========================                ] ( 6/10===[============================            ] ( 7/10===[================================        ] ( 8/10===[====================================    ] ( 9/10===[========================================] (10/10]\n",
      "Extracting claims...\n",
      "Processing file: ICLR_1.pdf\n",
      "Parsing response...\n",
      "Raw response: {\n",
      "    \"claims\": [\n",
      "        {\n",
      "            \"claim_id\": 1,\n",
      "            \"claim_text\": \"CQCC features significantly outperform MFCC in classifying neurodegenerative disorders when using Random Forest and SVM classifiers\",\n",
      "            \"location\": \"Abstract\",\n",
      "            \"claim_type\": \"Results/Performance\",\n",
      "            \"exact_quote\": \"CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 2,\n",
      "            \"claim_text\": \"CQCC achieved the highest classification accuracy of 99% using Random Forest classifier for binary classification\",\n",
      "            \"location\": \"Results/Section 5.2.1\",\n",
      "            \"claim_type\": \"Results/Performance\",\n",
      "            \"exact_quote\": \"Among the features analyzed, CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%, in contrast to the 63.4% accuracy achieved by the Support Vector Machine classifier\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 3,\n",
      "            \"claim_text\": \"This is the first study using sustained vowel sounds for multi neurodegenerative disorder classification and analysis\",\n",
      "            \"location\": \"Introduction\",\n",
      "            \"claim_type\": \"Novelty\",\n",
      "            \"exact_quote\": \"To the best of the authors' knowledge, this is the first study of it;s kind on sustained vowel sounds for multi neurodegenerative disorder classification and analysis\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 4,\n",
      "            \"claim_text\": \"CQCC features show improved class separation compared to MFCC in LDA visualization\",\n",
      "            \"location\": \"Results/Section 5.2.3\",\n",
      "            \"claim_type\": \"Results/Analysis\",\n",
      "            \"exact_quote\": \"the LDA plot of CQCC features exhibits a clearer separation, especially between the ALS and Parkinson's disease classes\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 5,\n",
      "            \"claim_text\": \"CQCC outperforms baseline features in multiple pathological classifications\",\n",
      "            \"location\": \"Results/Section 5.2.2\",\n",
      "            \"claim_type\": \"Results/Performance\",\n",
      "            \"exact_quote\": \"CQCC yields the highest accuracy with SVM (86.1%) and consistently performs well with RF (80.5%), indicating its superior capability in capturing the nuanced differences in the vocal characteristics associated with these diseases\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 6,\n",
      "            \"claim_text\": \"CQCC provides better spectrotemporal resolution due to geometrically spaced frequency bins\",\n",
      "            \"location\": \"Abstract\",\n",
      "            \"claim_type\": \"Methodology\",\n",
      "            \"exact_quote\": \"CQCC, which leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Successfully parsed JSON response\n",
      "Claims extraction completed\n",
      "Extracting evidence...\n",
      "Processing evidence for claims: Claim 1: CQCC features significantly outperform MFCC in classifying neurodegenerative disorders when using Random Forest and SVM classifiers\n",
      "Claim 2: CQCC achieved the highest classification accuracy of 99% using Random Forest classifier for binary classification\n",
      "Claim 3: This is the first study using sustained vowel sounds for multi neurodegenerative disorder classification and analysis\n",
      "Claim 4: CQCC features show improved class separation compared to MFCC in LDA visualization\n",
      "Claim 5: CQCC outperforms baseline features in multiple pathological classifications\n",
      "Claim 6: CQCC provides better spectrotemporal resolution due to geometrically spaced frequency bins\n",
      "Parsing response...\n",
      "Raw response: {\n",
      "    \"evidence_sets\": [\n",
      "        {\n",
      "            \"claim_id\": 1,\n",
      "            \"evidence\": [\n",
      "                {\n",
      "                    \"evidence_id\": 1,\n",
      "                    \"evidence_text\": \"CQCC outperforms MFCC with 5.6% and 7.7% improvements on RF and SVM respectively\",\n",
      "                    \"strength\": \"strong\",\n",
      "                    \"limitations\": \"Limited to specific datasets tested\",\n",
      "                    \"location\": \"Section 5.2.2\",\n",
      "                    \"exact_quote\": \"the proposed CQCC features outperform the baseline MFCC features with an absolute increment of 5.6% and 7.7% on RF and SVM classifiers, respectively\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 2,\n",
      "            \"evidence\": [\n",
      "                {\n",
      "                    \"evidence_id\": 2,\n",
      "                    \"evidence_text\": \"CQCC achieved 99% accuracy with RF classifier for binary classification\",\n",
      "                    \"strength\": \"strong\",\n",
      "                    \"limitations\": \"Only tested on one dataset (D2)\",\n",
      "                    \"location\": \"Section 5.2.1, Table 4\",\n",
      "                    \"exact_quote\": \"CQCC achieved the highest classification accuracy, with the Random Forest classifier attaining an exceptional 99%\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 4,\n",
      "            \"evidence\": [\n",
      "                {\n",
      "                    \"evidence_id\": 4,\n",
      "                    \"evidence_text\": \"LDA plots show clearer separation between classes for CQCC compared to MFCC\",\n",
      "                    \"strength\": \"moderate\",\n",
      "                    \"limitations\": \"Qualitative visual analysis\",\n",
      "                    \"location\": \"Section 5.2.3\",\n",
      "                    \"exact_quote\": \"the LDA plot of CQCC features exhibits a clearer separation, especially between the ALS and Parkinson's disease classes\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 5,\n",
      "            \"evidence\": [\n",
      "                {\n",
      "                    \"evidence_id\": 5,\n",
      "                    \"evidence_text\": \"CQCC shows higher accuracy in multiple pathological classifications\",\n",
      "                    \"strength\": \"strong\",\n",
      "                    \"limitations\": \"Limited to specific disorders tested\",\n",
      "                    \"location\": \"Section 5.2.2, Table 5\",\n",
      "                    \"exact_quote\": \"CQCC features outperform the baseline MFCC features with an absolute increment of 5.6% and 7.7% on RF and SVM classifiers, respectively\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 6,\n",
      "            \"evidence\": [\n",
      "                {\n",
      "                    \"evidence_id\": 6,\n",
      "                    \"evidence_text\": \"CQT uses geometrically spaced frequency bins with constant Q factor\",\n",
      "                    \"strength\": \"moderate\",\n",
      "                    \"limitations\": \"Technical description without direct performance comparison\",\n",
      "                    \"location\": \"Section 3.1\",\n",
      "                    \"exact_quote\": \"the quality factor P of the subband filters used in the filter bank remains constant, thus leading to geometrically spaced frequency bins\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Successfully parsed JSON response\n",
      "Evidence extraction completed\n",
      "Analyzing conclusions...\n",
      "Parsing response...\n",
      "Raw response: {\n",
      "    \"conclusions\": [\n",
      "        {\n",
      "            \"claim_id\": 1,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"medium\",\n",
      "            \"key_limitations\": \"Results from only two classifiers, specific datasets used, no statistical significance testing reported\",\n",
      "            \"confidence_level\": \"medium\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 2,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"medium\",\n",
      "            \"key_limitations\": \"Binary classification only, potential overfitting not addressed, dataset size and balance not fully detailed\",\n",
      "            \"confidence_level\": \"medium\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 3,\n",
      "            \"conclusion_justified\": false,\n",
      "            \"robustness\": \"low\",\n",
      "            \"key_limitations\": \"No evidence provided to support novelty claim, no comprehensive literature review shown\",\n",
      "            \"confidence_level\": \"low\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 4,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"medium\",\n",
      "            \"key_limitations\": \"Qualitative visual assessment only, no quantitative metrics for separation\",\n",
      "            \"confidence_level\": \"medium\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 5,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"medium\",\n",
      "            \"key_limitations\": \"Limited number of pathologies tested, specific test conditions not fully detailed\",\n",
      "            \"confidence_level\": \"medium\"\n",
      "        },\n",
      "        {\n",
      "            \"claim_id\": 6,\n",
      "            \"conclusion_justified\": true,\n",
      "            \"robustness\": \"high\",\n",
      "            \"key_limitations\": \"Theoretical advantage not directly linked to empirical performance improvements\",\n",
      "            \"confidence_level\": \"high\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Successfully parsed JSON response\n",
      "Conclusions analysis completed\n",
      "Results saved to analysis_outputs/:\n",
      "- Detailed analysis: claude_3_prompts/ICLR_1_analysis.json\n",
      "- Summary: claude_3_prompts/ICLR_1_summary.txt\n",
      "- Statistics: claude_3_prompts/ICLR_1_stats.txt\n",
      "Analysis completed successfully\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "import json\n",
    "import datetime\n",
    "import pymupdf4llm\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "import traceback\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class PaperAnalyzer:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = \"claude-3-5-sonnet-20241022\"\n",
    "        self.paper_text = None\n",
    "\n",
    "\n",
    "        self.execution_times = {\n",
    "        \"claims_analysis\": 0,\n",
    "        \"evidence_analysis\": 0,\n",
    "        \"conclusions_analysis\": 0,\n",
    "        \"total_time\": 0\n",
    "       }\n",
    "    def extract_text_from_pdf(self, filename: str) -> str:\n",
    "        \"\"\"Extract text from PDF file using PyMuPDF\"\"\"\n",
    "        try:\n",
    "            self.paper_text = pymupdf4llm.to_markdown(filename)\n",
    "            return self.paper_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from PDF: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def get_all_claims(self, filename: str) -> Dict:\n",
    "        \"\"\"Get all claims in one pass\"\"\"\n",
    "        try:\n",
    "            if not self.paper_text:\n",
    "                text = self.extract_text_from_pdf(filename)\n",
    "            else:\n",
    "                text = self.paper_text\n",
    "\n",
    "            print(f\"Processing file: {filename}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            claims_prompt = f\"\"\"\n",
    "            paper text: {text}\n",
    "            task is to identify all statements in the text that meet the following criteria for a claim:\n",
    "            1. Makes a specific, testable assertion about results, methods, or contributions\n",
    "            2. Represents a novel finding, improvement, or advancement\n",
    "            3. Presents a clear position or conclusion\n",
    "\n",
    "            Make sure to:\n",
    "            1. Include both major and minor claims\n",
    "            2. Don't miss any claims\n",
    "            3. Present each claim as a separate item\n",
    "            \n",
    "            Return ONLY the following JSON structure:\n",
    "            {{\n",
    "                \"claims\": [\n",
    "                    {{\n",
    "                        \"claim_id\": 1,\n",
    "                        \"claim_text\": \"statement of the claim\",\n",
    "                        \"location\": \"section/paragraph where this claim appears\",\n",
    "                        \"claim_type\": \"Nature of the claim\",\n",
    "                        \"exact_quote\": \"complete verbatim text containing the claim\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            \n",
    "            # time.sleep(45)  # Rate limiting\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                system=\"You are a helpful assistant specialized in analyzing research papers.\",\n",
    "                max_tokens=8192,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": claims_prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            result = self._parse_json_response(response.content[0].text)\n",
    "            self.execution_times[\"claims_analysis\"] = time.time() - start_time\n",
    "\n",
    "            print(\"Claims extraction completed\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_all_claims: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_all_evidence(self, filename: str, claims: Dict) -> Dict:\n",
    "        \"\"\"Get evidence for all claims in one pass\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "\n",
    "            if not self.paper_text:\n",
    "                text = self.extract_text_from_pdf(filename)\n",
    "            else:\n",
    "                text = self.paper_text\n",
    "            \n",
    "            claims_text = \"\\n\".join([f\"Claim {c['claim_id']}: {c['claim_text']}\" \n",
    "                                   for c in claims['claims']])\n",
    "            print(\"Processing evidence for claims:\", claims_text)\n",
    "            \n",
    "            evidence_prompt = f\"\"\"\n",
    "            Paper text: {text}\n",
    "\n",
    "            For these claims:\n",
    "            {claims_text}\n",
    "\n",
    "             Please identify relevant evidence that:\n",
    "            1. Directly supports or contradicts the claim's specific assertion\n",
    "            2. Is presented with experimental results, data, or concrete examples\n",
    "            3. Can be traced to specific methods, results, or discussion sections\n",
    "            4. Is not from the abstract or introduction\n",
    "\n",
    "            Return ONLY the following JSON:\n",
    "            {{\n",
    "                \"evidence_sets\": [\n",
    "                    {{\n",
    "                        \"claim_id\": number,\n",
    "                        \"evidence\": [\n",
    "                            {{\n",
    "                                \"evidence_id\": number,\n",
    "                                \"evidence_text\": \"specific evidence\",\n",
    "                                \"strength\": \"strong/moderate/weak\",\n",
    "                                \"limitations\": \"key limitations\",\n",
    "                                \"location\": \"section/paragraph\",\n",
    "                                \"exact_quote\": \"verbatim text\"\n",
    "                            }}\n",
    "                        ]\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "\n",
    "            \n",
    "            \n",
    "            # time.sleep(45)  # Rate limiting\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                system=\"You are a helpful assistant specialized in analyzing research papers.\",\n",
    "                max_tokens=8192,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": evidence_prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            result = self._parse_json_response(response.content[0].text)\n",
    "            self.execution_times[\"evidence_analysis\"] = time.time() - start_time\n",
    "\n",
    "            print(\"Evidence extraction completed\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_all_evidence: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def get_all_conclusions(self, filename: str, claims: Dict, evidence_sets: Dict) -> Dict:\n",
    "            \"\"\"Analyze conclusions for all claims and evidence in one pass\"\"\"\n",
    "            try:\n",
    "                if not self.paper_text:\n",
    "                    text = self.extract_text_from_pdf(filename)\n",
    "                else:\n",
    "                    text = self.paper_text\n",
    "                start_time = time.time()\n",
    "                # Create summary of claims and evidence for the prompt\n",
    "                analysis_summary = []\n",
    "                for claim in claims['claims']:\n",
    "                    claim_id = claim['claim_id']\n",
    "                    claim_evidence = next((e['evidence'] for e in evidence_sets['evidence_sets'] \n",
    "                                        if e['claim_id'] == claim_id), [])\n",
    "                    \n",
    "                    summary = f\"\\nClaim {claim_id}: {claim['claim_text']}\\n\"\n",
    "                    summary += \"Evidence:\\n\"\n",
    "                    for evidence in claim_evidence:\n",
    "                        summary += f\"- {evidence['evidence_text']}\\n\"\n",
    "                    analysis_summary.append(summary)\n",
    "                \n",
    "                analysis_text = \"\\n\".join(analysis_summary)\n",
    "                \n",
    "                conclusions_prompt = f\"\"\"\n",
    "                Paper text: {text}\n",
    "\n",
    "                Analyze these claims and their evidence:\n",
    "                {analysis_text}\n",
    "\n",
    "                For each claim-evidence pair, evaluate:\n",
    "                1. Whether the evidence justifies the claim\n",
    "                2. The overall strength of support\n",
    "                3. Any important limitations\n",
    "\n",
    "        \n",
    "                Return ONLY the following JSON:\n",
    "                {{\n",
    "                    \"conclusions\": [\n",
    "                        {{\n",
    "                            \"claim_id\": number,\n",
    "                            \"conclusion_justified\": true/false,\n",
    "                            \"robustness\": \"high/medium/low\",\n",
    "                            \"key_limitations\": \"specific limitations\",\n",
    "                            \"confidence_level\": \"high/medium/low\"\n",
    "                        }}\n",
    "                    ]\n",
    "                }}\n",
    "                \"\"\"\n",
    "                \n",
    "                # time.sleep(45)  # Rate limiting\n",
    "                response = self.client.messages.create(\n",
    "                    model=self.model,\n",
    "                    system=\"You are a helpful assistant specialized in analyzing research papers.\",\n",
    "                    max_tokens=8192,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": conclusions_prompt}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                result = self._parse_json_response(response.content[0].text)\n",
    "                self.execution_times[\"conclusions_analysis\"] = time.time() - start_time\n",
    "                print(\"Conclusions analysis completed\")\n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in get_all_conclusions: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "    def _parse_json_response(self, response: str) -> Dict:\n",
    "        \"\"\"Parse JSON response with better error handling\"\"\"\n",
    "        try:\n",
    "            print(\"Parsing response...\")\n",
    "            print(\"Raw response:\", response)\n",
    "            \n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            \n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON content found in response\")\n",
    "                \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            result = json.loads(json_str)\n",
    "            \n",
    "            print(\"Successfully parsed JSON response\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {str(e)}\")\n",
    "            print(\"Raw response:\", response)\n",
    "            raise\n",
    "\n",
    "    def analyze_paper(self, filename: str) -> Dict:\n",
    "        \"\"\"Complete paper analysis using three-prompt approach\"\"\"\n",
    "        try:\n",
    "            total_start_time = time.time()\n",
    "\n",
    "            # Extract text once at the beginning\n",
    "            print(\"Extracting text from PDF...\")\n",
    "            self.extract_text_from_pdf(filename)\n",
    "\n",
    "            # Get all claims\n",
    "            print(\"Extracting claims...\")\n",
    "            claims = self.get_all_claims(filename)\n",
    "            if not claims:\n",
    "                raise Exception(\"Failed to extract claims\")\n",
    "\n",
    "            # Get evidence for all claims\n",
    "            print(\"Extracting evidence...\")\n",
    "            evidence_sets = self.get_all_evidence(filename, claims)\n",
    "            if not evidence_sets:\n",
    "                raise Exception(\"Failed to extract evidence\")\n",
    "\n",
    "            # Get conclusions for all claim-evidence pairs\n",
    "            print(\"Analyzing conclusions...\")\n",
    "            conclusions = self.get_all_conclusions(filename, claims, evidence_sets)\n",
    "            if not conclusions:\n",
    "                raise Exception(\"Failed to generate conclusions\")\n",
    "\n",
    "\n",
    "            self.execution_times[\"total_time\"] = time.time() - total_start_time\n",
    "\n",
    "            # Structure final results\n",
    "            final_results = {\n",
    "                \"paper_analysis\": [] }\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "            for claim in claims['claims']:\n",
    "                claim_id = claim['claim_id']\n",
    "                \n",
    "                # Get evidence for this claim\n",
    "                evidence = next((e['evidence'] for e in evidence_sets['evidence_sets'] \n",
    "                            if e['claim_id'] == claim_id), [])\n",
    "                \n",
    "                # Get conclusion for this claim\n",
    "                conclusion = next((c for c in conclusions['conclusions'] \n",
    "                                if c['claim_id'] == claim_id), {})\n",
    "\n",
    "                analysis_item = {\n",
    "                    \"claim_id\": claim_id,\n",
    "                    \"claim\": {\n",
    "                        \"text\": claim['claim_text'],\n",
    "                        \"location\": claim['location'],\n",
    "                        \"type\": claim['claim_type'],\n",
    "                        \"exact_quote\": claim['exact_quote']\n",
    "                    },\n",
    "                    \"evidence\": evidence,\n",
    "                    \"conclusion\": {\n",
    "                        \"conclusion_justified\": conclusion.get('conclusion_justified', False),\n",
    "                        \"robustness\": conclusion.get('robustness', 'Not evaluated'),\n",
    "                        \"limitations\": conclusion.get('key_limitations', 'Not specified'),\n",
    "                        \"confidence_level\": conclusion.get('confidence_level', 'low')\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                final_results['paper_analysis'].append(analysis_item)\n",
    "            final_results[\"execution_times\"] = {\n",
    "            \"claims_analysis_time\": f\"{self.execution_times['claims_analysis']:.2f} seconds\",\n",
    "            \"evidence_analysis_time\": f\"{self.execution_times['evidence_analysis']:.2f} seconds\",\n",
    "            \"conclusions_analysis_time\": f\"{self.execution_times['conclusions_analysis']:.2f} seconds\",\n",
    "            \"total_execution_time\": f\"{self.execution_times['total_time']:.2f} seconds\"\n",
    "                }\n",
    "\n",
    "            return final_results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in paper analysis: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def save_results(self, results: Dict, filename: str):\n",
    "        \"\"\"Save analysis results in multiple formats\"\"\"\n",
    "        try:\n",
    "            base_filename = Path(filename).stem\n",
    "            \n",
    "            # Create output directory\n",
    "            os.makedirs('claude_3_prompts', exist_ok=True)\n",
    "            output_dir = \"claude_3_prompts\"\n",
    "            # Save detailed JSON results\n",
    "            json_filename = f'{output_dir}/{base_filename}_analysis.json'\n",
    "            with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            # Save human-readable summary\n",
    "            summary_filename = f'{output_dir}/{base_filename}_summary.txt'\n",
    "            with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"=== Paper Analysis Summary ===\\n\\n\")\n",
    "                \n",
    "                for analysis in results['paper_analysis']:\n",
    "                    f.write(f\"Claim {analysis['claim_id']}:\\n\")\n",
    "                    f.write(f\"Statement: {analysis['claim']['text']}\\n\")\n",
    "                    f.write(f\"Location: {analysis['claim']['location']}\\n\")\n",
    "                    f.write(f\"Type: {analysis['claim']['type']}\\n\")\n",
    "                    f.write(f\"Quote: {analysis['claim']['exact_quote']}\\n\\n\")\n",
    "                    \n",
    "                    f.write(\"Evidence:\\n\")\n",
    "                    for evidence in analysis['evidence']:\n",
    "                        f.write(f\"- {evidence['evidence_text']}\\n\")\n",
    "                        f.write(f\"  Strength: {evidence['strength']}\\n\")\n",
    "                        f.write(f\"  Location: {evidence['location']}\\n\")\n",
    "                        f.write(f\"  Limitations: {evidence['limitations']}\\n\")\n",
    "                        f.write(f\"  Quote: {evidence['exact_quote']}\\n\\n\")\n",
    "                    \n",
    "                    f.write(\"Conclusion:\\n\")\n",
    "                    f.write(f\"Justified: {analysis['conclusion']['conclusion_justified']}\\n\")\n",
    "                    f.write(f\"Robustness: {analysis['conclusion']['robustness']}\\n\")\n",
    "                    f.write(f\"Limitations: {analysis['conclusion']['limitations']}\\n\")\n",
    "                    f.write(f\"Confidence: {analysis['conclusion']['confidence_level']}\\n\")\n",
    "                    f.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "            # Save statistics\n",
    "            stats_filename = f'{output_dir}/{base_filename}_stats.txt'\n",
    "            with open(stats_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"Analysis Statistics:\\n\\n\")\n",
    "                f.write(f\"Total Claims Analyzed: {len(results['paper_analysis'])}\\n\")\n",
    "                \n",
    "                # Evidence statistics\n",
    "                total_evidence = sum(len(analysis['evidence']) for analysis in results['paper_analysis'])\n",
    "                f.write(f\"Total Evidence Pieces: {total_evidence}\\n\")\n",
    "                \n",
    "                # Confidence distribution\n",
    "                confidence_levels = {}\n",
    "                for analysis in results['paper_analysis']:\n",
    "                    level = analysis['conclusion']['confidence_level']\n",
    "                    confidence_levels[level] = confidence_levels.get(level, 0) + 1\n",
    "                \n",
    "                f.write(\"\\nConfidence Level Distribution:\\n\")\n",
    "                for level, count in confidence_levels.items():\n",
    "                    f.write(f\"{level}: {count} claims\\n\")\n",
    "\n",
    "                f.write(\"\\nExecution Times:\\n\")\n",
    "                f.write(f\"Claims Analysis: {self.execution_times['claims_analysis']:.2f} seconds\\n\")\n",
    "                f.write(f\"Evidence Analysis: {self.execution_times['evidence_analysis']:.2f} seconds\\n\")\n",
    "                f.write(f\"Conclusions Analysis: {self.execution_times['conclusions_analysis']:.2f} seconds\\n\")\n",
    "                f.write(f\"Total Execution Time: {self.execution_times['total_time']:.2f} seconds\\n\")\n",
    "\n",
    "\n",
    "            print(f\"Results saved to analysis_outputs/:\")\n",
    "            print(f\"- Detailed analysis: {json_filename}\")\n",
    "            print(f\"- Summary: {summary_filename}\")\n",
    "            print(f\"- Statistics: {stats_filename}\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        api_key = \"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\"\n",
    "        analyzer = PaperAnalyzer(api_key)\n",
    "        \n",
    "        filename = \"ICLR_1.pdf\"\n",
    "        print(f\"Starting analysis of {filename}\")\n",
    "        \n",
    "        # Analyze paper\n",
    "        results = analyzer.analyze_paper(filename)\n",
    "        \n",
    "        if results:\n",
    "            # Save results in structured format\n",
    "            analyzer.save_results(results, filename)\n",
    "            print(\"Analysis completed successfully\")\n",
    "        else:\n",
    "            print(\"Analysis failed to produce results\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
