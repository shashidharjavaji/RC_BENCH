Claim 1:
Type: result
Statement: Even among the top 0.6% of neurons considered well-explained by GPT-4, the explanations have poor faithfulness with low precision and recall scores
Location: Introduction section
Exact Quote: In the observational mode, we find that even among the top 0.6% of neurons which are considered well-explained by GPT-4's own assessment, the explanation is far from faithful; construed as predictions about neuron activations, GPT-4 generated explanations achieve a precision of 0.64 and a recall of 0.50.

Evidence:
- Evidence Text: F1 scores of 0.56 for single neurons without probing
  Strength: strong
  Location: Results section 3.3
  Limitations: Limited to GPT-2 XL model only
  Exact Quote: For single neuron without probing, the GPT-4 explanations have a mean F1 score of 0.56 (with a precision of 0.64 and a recall of 0.50), whereas the random baseline has a F1 score of zero.

- Evidence Text: Demonstration that high GPT-4 scores don't guarantee faithful explanations
  Strength: moderate
  Location: Discussion section 3.4
  Limitations: Based on theoretical example
  Exact Quote: Consider an unfaithful explanation E = year 2000 and 2001 of a neuron a that only activates on "2000". When sampling the 10 examples from a corpus that has n% examples containing "2001", the probability of having at least one example containing "2001" (a Type I error) is 1-(1-n%)[5] ≈ 5n%.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by both empirical results showing low F1 scores and theoretical demonstration of how high GPT-4 scores can coexist with unfaithful explanations
Key Limitations: Study limited to GPT-2 XL model, may not generalize to other architectures

--------------------------------------------------

Claim 2:
Type: result
Statement: There is no evidence that neurons are causal mediators of the concepts denoted by GPT-4's explanations
Location: Introduction section
Exact Quote: In the intervention mode, the picture is more worrisome: we are unable to find evidence that neurons are causal mediators of the concepts denoted by the explanations.

Evidence:
- Evidence Text: GPT-4 explanations perform similar to random baseline in intervention tests
  Strength: strong
  Location: Results section 4.3
  Limitations: Limited set of test tasks
  Exact Quote: GPT-4 generated explanations have similar causal effects as the random baseline on most tasks.

- Evidence Text: Token-activation correlation baseline outperforms GPT-4 explanations
  Strength: strong
  Location: Results section 4.3
  Limitations: May not cover all possible intervention scenarios
  Exact Quote: In terms of the IIA ranking, we have: token-activation correlation baseline ≫ GPT-4 explanation ≈ random baseline

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: Multiple evaluation tasks consistently show GPT-4 explanations performing no better than random in identifying causal relationships
Key Limitations: Limited set of intervention tasks, may not cover all possible causal relationships

--------------------------------------------------

