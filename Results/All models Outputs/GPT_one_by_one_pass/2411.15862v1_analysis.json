{
    "paper_analysis": [
        {
            "claim_id": 1,
            "claim": "Chain-of-Thought can enhance LLMs' performance on complex tasks but introduces slower inference speeds and higher computational costs.",
            "claim_location": "Abstract",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "The study conducted experiments using the model Qwen2.5-72b-instruct under different problem presentations using implicit or explicit reasoning on 3-step and 5-step problems. The experiments specifically examined the inference speeds and computational demands of Chain-of-Thought (CoT) reasoning by comparing its performance in both implicit and explicit forms across various problem modifications.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The study's generalization to all forms of complex tasks beyond arithmetic reasoning and the applicability of results to models with different architectures or scales were not discussed.",
                    "location": "Section 2.3 Result of Slightly Perturbing the Prompt & Section 3 Conclusion",
                    "exact_quote": "From the results in Table 1, we can clearly see that, compare to the original problems, the modified problems significantly degrade the performance when using implicit reasoning."
                }
            ],
            "evidence_locations": [
                "Section 2.3 Result of Slightly Perturbing the Prompt & Section 3 Conclusion"
            ],
            "conclusion": {
                "author_conclusion": "LLMs, despite often giving the correct answer to a multi-step problem, do not engage in step-by-step reasoning unless through explicit Chain-of-Thought (CoT) prompting. Implicit reasoning appears to be more about recalling the answer from memory than about computational reasoning, indicating a fundamental difference from explicit CoT processes.",
                "conclusion_justified": true,
                "robustness_analysis": "The experimental setup, particularly the probing method for intermediate steps and the testing with modified problems, demonstrates methodological strength. The findings are consistent across different problem modifications and show a clear distinction in performance between implicit and explicit reasoning, highlighting a significant reliability in the evidence presented.",
                "limitations": "The study is limited by the scope of tasks (arithmetic problems) and the specific model architecture studied (Qwen2.5-72B-Instruct). These factors could influence the generalizability of the results across different types of complex tasks and other LLM architectures. Additionally, the research suggests, but does not conclusively prove, that the observed phenomena of implicit reasoning are universal across all forms of complex reasoning tasks.",
                "conclusion_location": "Conclusion section of 2411.15862v1.pdf"
            }
        },
        {
            "claim_id": 2,
            "claim": "LLMs do not actually engage in step-by-step reasoning with implicit CoT.",
            "claim_location": "Abstract",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "The experimental results indicate that LLMs hardly think about intermediate steps in implicit CoT, suggesting they may just rely on experience rather than strict step-by-step reasoning.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The study's insights are mainly limited to arithmetic reasoning problems.",
                    "location": "Abstract & Section 2.2 Results of Probing Intermediate Steps",
                    "exact_quote": "The results surprisingly indicate that LLMs hardly think about intermediate steps, suggesting they may just rely on experience rather than strict step-by-step reasoning."
                },
                {
                    "evidence_id": 2,
                    "evidence_text": "Even when LLMs correctly give an answer to a multi-step problem, the process does not involve calculating intermediate steps, underscoring the absence of step-by-step reasoning in implicit CoT.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "Focuses on arithmetic problems which may not fully represent all types of problems LLMs encounter.",
                    "location": "Section 2.2 Results of Probing Intermediate Steps",
                    "exact_quote": "It actually skips the intermediate steps and come up with the final result directly... its mechanism is not equivalent to the explicit CoT process at all."
                },
                {
                    "evidence_id": 3,
                    "evidence_text": "Modifying the arithmetic problem presentation significantly degrades LLM performance in implicit reasoning, suggesting a reliance on experience or intuition rather than logical step-by-step processing.",
                    "evidence_type": "primary",
                    "strength": "moderate",
                    "limitations": "The results might not generalize to other forms of reasoning or to tasks beyond arithmetic.",
                    "location": "Section 2.3 Result of Slightly Perturbing the Prompt",
                    "exact_quote": "The modified problems significantly degrade the performance when using implicit reasoning... This cause the way of implicit reasoning less robust and less reliable."
                }
            ],
            "evidence_locations": [
                "Abstract & Section 2.2 Results of Probing Intermediate Steps",
                "Section 2.2 Results of Probing Intermediate Steps",
                "Section 2.3 Result of Slightly Perturbing the Prompt"
            ],
            "conclusion": {
                "author_conclusion": "LLMs, when dealing with arithmetic problems, do not engage in step-by-step reasoning in the context of implicit Chain of Thought (CoT), but rather, derive answers directly from experience and pattern recognition, demonstrating a fundamental difference from explicit CoT reasoning.",
                "conclusion_justified": true,
                "robustness_analysis": "The evidence strength and reliability are heightened by the methodical approach of probing hidden states and observing model performance under varied conditions (e.g., reversed problem statements). The use of a large-scale model and a substantial dataset for training and testing the classifiers ensures that findings are not sporadic or model-specific but underline a consistent limitation in the implicit reasoning capabilities of LLMs.",
                "limitations": "The investigation primarily focuses on arithmetic problems, which may limit the generalizability of the findings to other types of reasoning or problem-solving tasks. The reliance on linear classifiers for probing might oversimplify the nuanced information processing within LLMs. Additionally, the performance drop in modified problem scenarios could also reflect on the models' lack of flexibility rather than an absence of reasoning.",
                "conclusion_location": "Abstract, Conclusion"
            }
        },
        {
            "claim_id": 3,
            "claim": "LLMs' implicit reasoning capabilities are susceptible and unstable.",
            "claim_location": "Abstract",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "The accuracy of LLMs under different problem presentations using implicit or explicit reasoning on 3-step and 5-step problems.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The study focuses on arithmetic problems, which might not fully represent all implicit reasoning tasks LLMs are capable of.",
                    "location": "Result of Slightly Perturbing the Prompt, Table 1",
                    "exact_quote": "From the results in Table 1, we can clearly see that, compare to the original problems, the modified problems significantly degrade the performance when using implicit reasoning. While the performance of explicit reasoning is always perfect. This contrast further demonstrates our inference that, in implicit reasoning, the model is actually answering directly by experience and intuition, but not by reasoning step-by-step. This cause the way of implicit reasoning less robust and less reliable."
                }
            ],
            "evidence_locations": [
                "Result of Slightly Perturbing the Prompt, Table 1"
            ],
            "conclusion": {
                "author_conclusion": "Implicit reasoning in LLMs does not equal explicit reasoning, as LLMs fail to process intermediate steps and rely on intuition and experience instead.",
                "conclusion_justified": true,
                "robustness_analysis": "The evidence is robust, drawn from controlled experiments with detailed analysis of the LLM's processing through probing of hidden states and specific modifications of problem structure to test reasoning stability.",
                "limitations": "The research mainly focuses on arithmetic reasoning tasks and may not fully account for other types of reasoning or content domains. The study assumes a direct correlation between the probing method's effectiveness and the LLM\u2019s reasoning process, which might not capture all aspects of implicit reasoning.",
                "conclusion_location": "Abstract and Conclusion sections"
            }
        },
        {
            "claim_id": 4,
            "claim": "Explicit CoT methodologies are necessary for enhancing LLMs' abilities on complex tasks.",
            "claim_location": "Introduction",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "In a study exploring the effects of explicit CoT methodology on LLMs handling complex arithmetic tasks, it was found that while LLMs can often produce correct answers directly, they do not engage in step-by-step reasoning without explicit CoT. This indicates that implicit reasoning might be an illusion created by LLMs' memory and experience, emphasizing the necessity for explicit CoT methodologies to enhance their ability in complex tasks.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The study's experiments were specifically focused on arithmetic problems, which might limit the generalizability of the findings across all types of complex tasks.",
                    "location": "Results and Conclusion sections.",
                    "exact_quote": "in conclusion, we think LLMs, despite they can often directly give the correct answer of a multi-step problem, especially when with a larger size, they are not really doing step-by-step reasoning (at least in arithmetic problems), unless adopting explicit CoT."
                },
                {
                    "evidence_id": 2,
                    "evidence_text": "An experimental design involving LLMs solving multi-step arithmetic problems without explicit CoT prompts revealed LLMs tend to output the correct answer by drawing from their 'powerful memory and rich experience', rather than actual reasoning. Supporting the claim, it underscores the importance of explicit CoT methods to facilitate genuine reasoning processes in LLMs.",
                    "evidence_type": "primary",
                    "strength": "moderate",
                    "limitations": "While the experiment provides important insights, it hinges on arithmetic problems, possibly overlooking how explicit CoT might benefit LLMs in broader, more abstract problem-solving contexts.",
                    "location": "Experiment Design and Results sections.",
                    "exact_quote": "Our study provides critical insights into the mechanics of implicit reasoning and emphasizes the ongoing necessity for explicit CoT methodologies in enhancing LLMs ability on complex tasks."
                },
                {
                    "evidence_id": 3,
                    "evidence_text": "Further experimentation, altering problem presentation styles to probe LLMs' reasoning, illustrates diminished performance in tasks employing implicit reasoning modifications, compared to flawless performance via explicit reasoning. This demonstrates the limitations of implicit reasoning and reinforces the argument for explicit CoT's superiority in fostering LLMs' problem-solving capabilities on complex tasks.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The evidence is derived from alterations in prompt presentation for arithmetic problems; this experimental scope may not capture LLM performance on a wider variety of complex tasks.",
                    "location": "Result of Slightly Perturbing the Prompt section.",
                    "exact_quote": "This contrast further demonstrate our inference that, in implicit reasoning, the model is actually answering directly by experience and intuition, but not by reasoning step-by-step. This cause the way of implicit reasoning less robust and less reliable."
                }
            ],
            "evidence_locations": [
                "Results and Conclusion sections.",
                "Experiment Design and Results sections.",
                "Result of Slightly Perturbing the Prompt section."
            ],
            "conclusion": {
                "author_conclusion": "Explicit CoT methodologies are critical for enhancing LLMs' performance on complex tasks, as implicit reasoning methods do not adequately capture the intermediate steps necessary for robust and reliable reasoning.",
                "conclusion_justified": true,
                "robustness_analysis": "The study's methodology, which includes probing the hidden states of LLMs and analyzing performance under variations of problem presentation, offers strong evidence supporting the claim. The differentiated performance between explicit and implicit reasoning approaches underlines explicit CoT's effectiveness.",
                "limitations": "The research mainly focuses on arithmetic reasoning tasks, which may limit the generalizability of the findings to other forms of complex reasoning. Additionally, the analysis of implicit reasoning's efficacy could benefit from further exploration into models of varying sizes and configurations.",
                "conclusion_location": "Conclusion"
            }
        },
        {
            "claim_id": 5,
            "claim": "Implicit reasoning does not equate to explicit reasoning in LLMs.",
            "claim_location": "Conclusion",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "LLMs perform differently under implicit versus explicit reasoning conditions, demonstrating that implicit reasoning does not equate to explicit reasoning.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The study focuses on arithmetic problems and may not directly extend to other types of reasoning or tasks.",
                    "location": "Results section & Conclusion section",
                    "exact_quote": "From the results in Table 1, we can clearly see that, compared to the original problems, the modified problems significantly degrade the performance when using implicit reasoning. While the performance of explicit reasoning is always perfect. This contrast further demonstrates our inference that, in implicit reasoning, the model is actually answering directly by experience and intuition, but not by reasoning step-by-step. This causes the way of implicit reasoning less robust and less reliable."
                }
            ],
            "evidence_locations": [
                "Results section & Conclusion section"
            ],
            "conclusion": {
                "author_conclusion": "Implicit reasoning in LLMs cannot equate to explicit reasoning because it lacks a step-by-step process and relies on intuition, making it less reliable.",
                "conclusion_justified": true,
                "robustness_analysis": "The evidence is robust, showing consistent performance differences across problem types and clear distinctions in the LLM's reasoning approach for implicit versus explicit tasks. Methodological strengths include the diversity of problems tested and the empirical probing of LLM hidden states.",
                "limitations": "The study only focuses on arithmetic problems, limiting its generalizability. There's also an assumption that the model\u2019s internal process can be accurately interpreted through external probing, disregarding potential complexities in how LLMs process information.",
                "conclusion_location": "Conclusion"
            }
        },
        {
            "claim_id": 6,
            "claim": "Implicit reasoning relies on LLMs' powerful memory and rich experience, differing fundamentally from conventional reasoning.",
            "claim_location": "Conclusion",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "Despite LLMs often providing the correct answer to a multi-step problem, an experiment uncovers they do not calculate intermediate results in an implicit reasoning process, indicating a reliance on powerful memory and rich experience. This method is faster but less reliable than step-by-step explicit reasoning.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The result indicates that this form of reasoning is more susceptible and less stable without a conventional step-by-step process.",
                    "location": "Approach & Experiment Design sections",
                    "exact_quote": "The experiment results are surprising and counter-intuitive: we find the model hardly calculates the intermediate results in implicit reasoning, despite it can often give the correct answer of the multi-step problem. Moreover, through slightly modifying the problem without even increase its difficulty, we find implicit reasoning is more unstable and susceptible. This finding suggests in implicit reasoning, the model may not strictly follow a step-by-step reasoning process, but relies solely on an intuitive and direct way of thinking to complete the task, belonging to System 1 thinking (Kahneman, 2011), which is faster but less reliable."
                }
            ],
            "evidence_locations": [
                "Approach & Experiment Design sections"
            ],
            "conclusion": {
                "author_conclusion": "Implicit reasoning in LLMs, while capable of producing correct answers for multi-step problems, does not involve step-by-step reasoning analogous to explicit CoT. Instead, it likely relies on the models' extensive memory and experience, which fundamentally differs from conventional reasoning strategies.",
                "conclusion_justified": true,
                "robustness_analysis": "The research demonstrates methodological strengths through specific experiment design, such as probing hidden states to infer intermediate reasoning steps and modifying problem presentations to test LLMs' reasoning capabilities under varied conditions. This thorough approach lends credence to the finding that implicit reasoning is significantly distinct from explicit reasoning methods.",
                "limitations": "Potential limitations include focusing only on arithmetic problems, which might not fully represent the broad spectrum of tasks LLMs can perform. Also, the results may depend on the specific architecture and size of the language model used, making it uncertain whether these findings generalize across different models or settings.",
                "conclusion_location": "Conclusion"
            }
        },
        {
            "claim_id": 7,
            "claim": "LLMs' performance degrades significantly under modified problems when using implicit reasoning.",
            "claim_location": "Result of Slightly Perturbing the Prompt",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "Compared to the original problems, the modified problems significantly degrade LLMs' performance when using implicit reasoning, while explicit reasoning maintains perfect performance.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The study focuses on arithmetic problems, which may not generalize across all types of tasks requiring implicit reasoning.",
                    "location": "Results of Probing Intermediate Steps & Result of Slightly Perturbing the Prompt section",
                    "exact_quote": "From the results in Table 1, we can clearly see that, compared to the original problems, the modified problems significantly degrade the performance when using implicit reasoning. While the performance of explicit reasoning is always perfect."
                },
                {
                    "evidence_id": 2,
                    "evidence_text": "LLMs' implicit reasoning largely relies on experience and intuition without step-by-step processing, making it less reliable and robust compared to explicit reasoning.",
                    "evidence_type": "primary",
                    "strength": "moderate",
                    "limitations": "Assessment is based on the performance on arithmetic problems and may not apply to other problem types.",
                    "location": "Conclusion section",
                    "exact_quote": "This contrast further demonstrate our inference that, in implicit reasoning, the model is actually answering directly by experience and intuition, but not by reasoning step-by-step. This causes the way of implicit reasoning less robust and less reliable."
                }
            ],
            "evidence_locations": [
                "Results of Probing Intermediate Steps & Result of Slightly Perturbing the Prompt section",
                "Conclusion section"
            ],
            "conclusion": {
                "author_conclusion": "LLMs, when solving arithmetic problems using implicit reasoning, do not engage in a step-by-step process; rather, they rely on intuition and previously acquired knowledge. This approach, while occasionally effective, is fundamentally less reliable and robust than explicit reasoning strategies, such as Chain-of-Thought (CoT), which explicitly maps out reasoning steps.",
                "conclusion_justified": true,
                "robustness_analysis": "The experiment's design, leveraging a substantial dataset of arithmetic problems and analyzing the model's performance under different conditions, strengthens the reliability of the findings. The comparison between implicit and explicit reasoning frameworks provides a clear demonstration of the limitations inherent in the implicit approach.",
                "limitations": "The study focuses on arithmetic problems, which may not fully generalize to all types of reasoning tasks LLMs might encounter. Additionally, the analysis of hidden states provides insights into the processing steps of LLMs, but the correlation between these states and cognitive reasoning processes remains speculative.",
                "conclusion_location": "Section 2.3 Result of Slightly Perturbing the Prompt and Conclusion in 2411.15862v1.pdf"
            }
        },
        {
            "claim_id": 8,
            "claim": "LLMs may have the ability to perform a 2-hop reasoning in implicit reasoning, but not more.",
            "claim_location": "Results of Probing Intermediate Steps",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "The results of probing the intermediate result of each step when the problem is 3-step or 5-step suggest that LLMs can perform a 2-hop reasoning in implicit reasoning",
                    "evidence_type": "primary",
                    "strength": "moderate",
                    "limitations": "The ability to probe the result of the second step to some extent in both 3-step or 5-step problems suggests capabilities for 2-hop reasoning; however, results for steps beyond two are limited.",
                    "location": "Results of Probing Intermediate Steps section",
                    "exact_quote": "However, since the result of the second step can be detected to some extent, both in 3-step or 5-step problems, this suggests that LLMs may have the ability to perform a 2-hop reasoning in implicit reasoning, but not at all when there are more steps involved."
                }
            ],
            "evidence_locations": [
                "Results of Probing Intermediate Steps section"
            ],
            "conclusion": {
                "author_conclusion": "Large Language Models (LLMs), while capable of providing correct answers for multi-step problems, especially with larger models, do not engage in step-by-step reasoning in the context of arithmetic problems without explicitly adopting a Chain-of-Thought (CoT) approach. The ability to perform 2-hop reasoning in implicit reasoning contexts suggests an overlap with explicit reasoning capabilities; however, this does not extend beyond more complex problems. Implicit reasoning appears as an illusion created by the model's powerful memory and abstraction abilities, fundamentally differing from conventional reasoning.",
                "conclusion_justified": true,
                "robustness_analysis": "The evidence is robust in illustrating the limitations of LLMs in performing more than 2-hop reasoning implicitly for arithmetic problems. By employing large models and a detailed experimental setup involving probing of hidden states and performance comparison under varying conditions, the study systematically demonstrates the models' reliance on memory and abstraction rather than computational reasoning.",
                "limitations": "The main limitations include a focus on arithmetic reasoning, which may not generalize to other types of reasoning or knowledge areas. The methodology, involving probing hidden states and accuracy measurement across different problem structures, presumes a direct correlation between these measurable factors and the models' reasoning capabilities, which might not capture the entirety of the models' cognitive processes.",
                "conclusion_location": "Results of Probing Intermediate Steps; Conclusion"
            }
        },
        {
            "claim_id": 9,
            "claim": "Explicit reasoning performance remains perfect under various problem presentations.",
            "claim_location": "Result of Slightly Perturbing the Prompt",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "The study evaluates the model's performance under different problem presentations, noting perfect performance in explicit reasoning across varied presentations.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The evidence is focused on explicit reasoning performance under controlled experimental conditions, potentially not reflecting real-world complexity.",
                    "location": "Results section, Paragraph 1",
                    "exact_quote": "From the results in Table 1, we can clearly see that, compare to the original problems, the modified problems significantly degrade the performance when using implicit reasoning. While the performance of explicit reasoning is always perfect."
                }
            ],
            "evidence_locations": [
                "Results section, Paragraph 1"
            ],
            "conclusion": {
                "author_conclusion": "Explicit reasoning outperforms implicit reasoning in robustness and reliability under different problem presentations, maintaining perfect accuracy while implicit reasoning suffers.",
                "conclusion_justified": true,
                "robustness_analysis": "The evidence demonstrates a stark contrast in performance stability between explicit and implicit reasoning, with the former's perfect outcomes underlining its robustness and consistency.",
                "limitations": "The study's limitation lies in its focus on arithmetic problems, which may not encapsulate the complexity of real-world reasoning tasks. Moreover, the implicit reasoning's real mechanism and potential for complex reasoning beyond arithmetic remains unexplored.",
                "conclusion_location": "Result of Slightly Perturbing the Prompt"
            }
        },
        {
            "claim_id": 10,
            "claim": "LLMs skip intermediate steps and directly conclude in implicit reasoning.",
            "claim_location": "Results of Probing Intermediate Steps",
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "In generic cases, there is not a specific state where the model calculates the results of the intermediate steps, even when it correctly gives an answer to the multi-step problem. It actually skips the intermediate steps and comes up with the final result directly.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "This conclusion is based on probing intermediate steps in implicit reasoning, suggesting LLMs may rely on large memory and abstraction abilities to map multi-step problems to their answers intuitively.",
                    "location": "Results of Probing Intermediate Steps",
                    "exact_quote": "This finding indicates that, in generic cases, there is actually not a specific state where the model calculates the results of the intermediate steps, even when it correctly give a answer of the multi-step problem. It actually skips the intermediate steps and come up with the final result directly."
                },
                {
                    "evidence_id": 2,
                    "evidence_text": "Modifying the problem slightly degrades the performance significantly when using implicit reasoning, suggesting that in implicit reasoning, the model is answering directly by experience and intuition, not by reasoning step-by-step.",
                    "evidence_type": "primary",
                    "strength": "strong",
                    "limitations": "The evidence is drawn from experimental results showing that LLMs' implicit reasoning capabilities are not as robust or reliable as explicit reasoning.",
                    "location": "Result of Slightly Perturbing the Prompt",
                    "exact_quote": "From the results in Table 1, we can clearly see that, compare to the original problems, the modified problems significantly degrade the performance when using implicit reasoning."
                }
            ],
            "evidence_locations": [
                "Results of Probing Intermediate Steps",
                "Result of Slightly Perturbing the Prompt"
            ],
            "conclusion": {
                "author_conclusion": "LLMs do not truly engage in implicit reasoning by calculating intermediate steps in a step-by-step manner for multi-step arithmetic problems, but rather, they seemingly 'skip' these steps, directly arriving at the final answer through abstract patterns learned during training. This approach makes implicit reasoning appear less robust and reliable compared to explicit CoT, highlighting a fundamental difference in mechanism.",
                "conclusion_justified": true,
                "robustness_analysis": "The comprehensive approach, including the design of arithmetic problem solving without explicit intermediate steps, analysis of model hidden states, and controlled modifications to problem statements, provides a methodologically sound basis for the conclusions. The evidence is consistent and convincing, showing how LLMs operationalize implicit reasoning.",
                "limitations": "The study focuses predominantly on arithmetic problem solving, which may not fully encompass or represent other reasoning domains or types. The generalizability of the findings to broader reasoning tasks or to models trained under different paradigms remains in question. The experimental setup's emphasis on linear probing and reliance on a single large model also poses potential limitations in scope and applicability.",
                "conclusion_location": "Results of Probing Intermediate Steps and Conclusion sections"
            }
        }
    ],
    "execution_times": {
        "claims_analysis_time": "33.08 seconds",
        "evidence_analysis_time": "204.38 seconds",
        "conclusions_analysis_time": "205.58 seconds",
        "total_execution_time": "0.00 seconds"
    }
}