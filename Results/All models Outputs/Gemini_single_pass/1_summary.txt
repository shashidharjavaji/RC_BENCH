Claim 1:
Type: performance
Statement: All four models achieved high scores on the MNLI test set.
Location: Experimental Setup
Exact Quote: All models achieved high scores on the MNLI test\nset (Figure 1a), replicating the accuracies found\nin past work (DA: Gururangan et al. 2018; ESIM:\nWilliams et al. 2018b; SPINN: Williams et al.\n2018a; BERT: Devlin et al. 2019).

Evidence:
- Evidence Text: Figure 1a shows all models performed well on the MNLI test set.
  Strength: strong
  Location: Results
  Limitations: None
  Exact Quote: None

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence from Figure 1a strongly supports the claim that all four models achieved high scores on the MNLI test set.
Key Limitations: None

--------------------------------------------------

Claim 2:
Type: performance
Statement: All four models performed poorly on the HANS dataset.
Location: Results
Exact Quote: On the HANS\ndataset, all models almost always assigned the correct label in the cases where the label is entailment, i.e., where the correct answer is in line with\nthe hypothesized heuristics. However, they all performed poorly—with accuracies less than 10% in\nmost cases, when chance is 50%—on the cases\nwhere the heuristics make incorrect predictions

Evidence:
- Evidence Text: Figure 1b shows all models performed poorly on the HANS dataset.
  Strength: strong
  Location: Results
  Limitations: None
  Exact Quote: None

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence from Figure 1b strongly supports the claim that all four models performed poorly on the HANS dataset.
Key Limitations: None

--------------------------------------------------

Claim 3:
Type: performance
Statement: SPINN had the best performance on the subsequence cases.
Location: Results
Exact Quote: SPINN had the best performance on the subsequence cases.

Evidence:
- Evidence Text: Figure 1b shows SPINN performed better than other models on the subsequence cases.
  Strength: strong
  Location: Results
  Limitations: None
  Exact Quote: None

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence from Figure 1b strongly supports the claim that SPINN had the best performance on the subsequence cases.
Key Limitations: None

--------------------------------------------------

Claim 4:
Type: performance
Statement: SPINN outperformed DA and ESIM on the constituent cases.
Location: Results
Exact Quote: SPINN also outperformed DA and ESIM\non the constituent cases, suggesting that SPINN’s\ntree-based representations moderately helped it\nlearn how specific constituents contribute to the\noverall sentence.

Evidence:
- Evidence Text: Figure 1b shows SPINN performed better than DA and ESIM on the constituent cases.
  Strength: strong
  Location: Results
  Limitations: None
  Exact Quote: None

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence from Figure 1b strongly supports the claim that SPINN outperformed DA and ESIM on the constituent cases.
Key Limitations: None

--------------------------------------------------

Claim 5:
Type: performance
Statement: BERT did slightly worse than SPINN on the subsequence cases, but performed noticeably less\npoorly than all other models at both the constituent\nand lexical overlap cases.
Location: Results
Exact Quote: BERT did slightly worse than SPINN on the\nsubsequence cases, but performed noticeably less\npoorly than all other models at both the constituent\nand lexical overlap cases (though it was still far\nbelow chance).

Evidence:
- Evidence Text: Figure 1b shows BERT performed better than other models on the constituent and lexical overlap cases.
  Strength: strong
  Location: Results
  Limitations: None
  Exact Quote: None

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence from Figure 1b strongly supports the claim that BERT did slightly worse than SPINN on the subsequence cases, but performed noticeably less\npoorly than all other models at both the constituent\nand lexical overlap cases.
Key Limitations: None

--------------------------------------------------

Claim 6:
Type: performance
Statement: BERT achieved 39% accuracy on conjunction but 0% accuracy on subject/object swap.
Location: Results
Exact Quote: For example, within the\nlexical overlap cases, BERT achieved 39% accuracy on conjunction (e.g., The actor and the doctor\nsaw the artist ↛ The actor saw the doctor) but 0%\naccuracy on subject/object swap (The judge called\nthe lawyer ↛ The lawyer called the judge).

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by the provided information, however, the source of the information is not specified, which makes it difficult to assess the robustness of the claim.
Key Limitations: The source of the information is not specified.

--------------------------------------------------

Claim 7:
Type: performance
Statement: BERT achieved 49% accuracy at determining that a clause embedded under if and other conditional words is not entailed, but 0% accuracy at identifying that the clause outside of the conditional\nclause is also not entailed.
Location: Results
Exact Quote: Within\nthe constituent heuristic cases, BERT achieved\n49% accuracy at determining that a clause embedded under if and other conditional words is not entailed (If the doctor resigned, the lawyer danced\n↛ The doctor resigned), but 0% accuracy at identifying that the clause outside of the conditional\nclause is also not entailed (If the doctor resigned,\nthe lawyer danced ↛ The lawyer danced).

Evidence:
Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by the provided information, however, the source of the information is not specified, which makes it difficult to assess the robustness of the claim.
Key Limitations: The source of the information is not specified.

--------------------------------------------------

Claim 8:
Type: result
Statement: The results further suggest that the models’ poor compositional behavior arises more because of the training set than because of model architecture.
Location: section 3
Exact Quote: These results further suggest that the models’ poor compositional behavior arises more because of the training set than because of model architecture.

Evidence:
- Evidence Text: Supporting this conclusion, McCoy et al. (2019) found little evidence of compositional structure in the InferSent model, which was trained on SNLI, even though the same model type (an RNN) did learn clear compositional structure when trained on tasks that underscored the need for such structure.
  Strength: strong
  Location: section 3
  Limitations: The study by McCoy et al. (2019) used a different dataset and model than the current study, so the results may not be directly comparable.
  Exact Quote: Supporting this conclusion, McCoy et al. (2019) found little evidence of compositional structure in the InferSent model, which was trained on SNLI, even though the same model type (an RNN) did learn clear compositional structure when trained on tasks that underscored the need for such structure.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence provided by McCoy et al. (2019) suggests that the poor compositional behavior of NLI models may be due to the training set rather than the model architecture. However, this evidence is not conclusive, as it is based on a single study using a different dataset and model.
Key Limitations: The study by McCoy et al. (2019) used a different dataset and model than the current study, so the results may not be directly comparable.

--------------------------------------------------

Claim 9:
Type: result
Statement: Overall, the models trained on the augmented MNLI performed very well on HANS.
Location: section 7
Exact Quote: Overall, the models trained on the augmented MNLI performed very well on HANS.

Evidence:
- Evidence Text: Figure 2 shows the HANS accuracies for models trained on MNLI plus examples of all 30 categories in HANS.
  Strength: strong
  Location: section 7
  Limitations: The results in Figure 2 are based on a single experiment, so they may not be generalizable to other datasets or models.
  Exact Quote: Figure 2 shows the HANS accuracies for models trained on MNLI plus examples of all 30 categories in HANS.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The results in Figure 2 show that the models trained on the augmented MNLI performed very well on HANS. However, these results are based on a single experiment, so they may not be generalizable to other datasets or models.
Key Limitations: The results in Figure 2 are based on a single experiment, so they may not be generalizable to other datasets or models.

--------------------------------------------------

Claim 10:
Type: result
Statement: Training with HANS-like examples has benefits that extend beyond HANS.
Location: section 8
Exact Quote: BERT fine-tuned on MNLI augmented with HANS-like examples has benefits that extend beyond HANS.

Evidence:
- Evidence Text: The augmentation improved performance modestly for the long examples and dramatically for the short examples.
  Strength: strong
  Location: section 8
  Limitations: The results are based on a single experiment, so they may not be generalizable to other datasets or models.
  Exact Quote: The augmentation improved performance modestly for the long examples and dramatically for the short examples.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The results show that BERT fine-tuned on MNLI augmented with HANS-like examples improved performance on the lexical overlap dataset from Dasgupta et al. (2018). However, these results are based on a single experiment, so they may not be generalizable to other datasets or models.
Key Limitations: The results are based on a single experiment, so they may not be generalizable to other datasets or models.

--------------------------------------------------

Claim 11:
Type: result
Statement: The HANS heuristics can be contradicted by examples from the MNLI training set.
Location: A MNLI Examples
Exact Quote: The sentences in (7) show examples from\nthe MNLI training set that contradict the lexical overlap, subsequence, and constituent\nheuristics.

Evidence:
- Evidence Text: The HANS heuristics may be contradicted by examples from the MNLI training set, as shown in the examples provided in (7).
  Strength: strong
  Location: A MNLI Examples
  Limitations: The examples provided are not exhaustive, and it is possible that other examples could be found that contradict the HANS heuristics.
  Exact Quote: None

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence provided shows clear examples of how the HANS heuristics can be contradicted by examples from the MNLI training set.
Key Limitations: The examples provided are not exhaustive, and it is possible that other examples could be found that contradict the HANS heuristics.

--------------------------------------------------

