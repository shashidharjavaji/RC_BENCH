Claim 1:
Type: methodology
Statement: ScopeCoE manages to search for the minimal set that completely covers all CoE features, ultimately outputting a set of knowledge snippets that covers the maximum number of CoE features, which serves as context input for the LLM.
Location: part 4
Exact Quote: _ScopeCoE manages to search for the minimal set_ that completely covers all CoE features, ultimately outputting a set of knowledge snippets that covers the maximum number of CoE features, which serves as context input for the LLM.

Evidence:
Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is not supported by any concrete evidence or experimental results.
Key Limitations: Lack of empirical evidence

--------------------------------------------------

Claim 2:
Type: result
Statement: The results show that RAG+ScopeCoE achieves average ACC of 77.8% and 81.6% on HotpotQA and 2WikiMultihopQA respectively, outperforming RAG by 10.4% and 28.7%.
Location: part 4
Exact Quote: The results show that RAG+ScopeCoE achieves average ACC of 77.8% and 81.6% on HotpotQA and 2WikiMultihopQA respectively, outperforming RAG by 10.4% and 28.7%.

Evidence:
- Evidence Text: Table 5 demonstrates the impact of naive RAG and RAG+ScopeCoE on LLMs’ accuracy. 
  Strength: strong
  Location: part 4
  Limitations: The table only shows the average ACC of RAG and RAG+ScopeCoE on two datasets.
  Exact Quote: Table 5 demonstrates the impact of naive RAG and RAG+ScopeCoE on LLMs’ accuracy.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: medium
Justification: The claim is supported by the results shown in Table 5.
Key Limitations: The results are limited to two datasets.

--------------------------------------------------

Claim 3:
Type: result
Statement: ScopeCoE can help LLMs generate more accurate outputs with fewer knowledge pieces (4.6 for HotpotQA and 4.8 for 2WikiMultihopQA) compared to the naive framework (5 pieces).
Location: part 4
Exact Quote: Moreover, we also observe that ScopeCoE can help LLMs generate more accurate outputs with fewer knowledge pieces (4.6 for HotpotQA and 4.8 for 2WikiMultihopQA) compared to the naive framework (5 pieces).

Evidence:
- Evidence Text: Table 5 demonstrates the impact of naive RAG and RAG+ScopeCoE on LLMs’ accuracy.
  Strength: weak
  Location: part 4
  Limitations: The table only shows the accuracy of RAG and RAG+ScopeCoE, and does not provide information about the number of knowledge pieces used by each model.
  Exact Quote: Table 5 demonstrates the impact of naive RAG and RAG+ScopeCoE on LLMs’ accuracy.

Evaluation:
Conclusion Justified: No
Robustness: low
Confidence Level: low
Justification: The claim is not strongly supported by the evidence provided, as the table only shows the accuracy of RAG and RAG+ScopeCoE, and does not provide information about the number of knowledge pieces used by each model.
Key Limitations: Lack of information about the number of knowledge pieces used by each model

--------------------------------------------------

