=== Paper Analysis Summary ===

Raw Claims:
This is a research paper titled "What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context". Here's a concise summary of the paper:

**Main Objective:**
Investigate the type of external knowledge preferred by Large Language Models (LLMs) in imperfect contexts, particularly in multi-hop Question Answering (QA) scenarios.

**Key Contributions:**

1. **Characterization of Chain of Evidence (CoE):** Inspired by criminal procedural law, the authors define CoE as knowledge that maintains both relevance to the question and mutual support among knowledge pieces.
2. **CoE Discrimination Approach:** A proposed method to determine whether given external knowledge contains CoE, leveraging LLMs for feature extraction and discrimination.
3. **Evaluation Framework:** Assessments of LLMs' preference for CoE across four aspects:
	* **Effectiveness:** LLMs' performance with CoE vs. Non-CoE in generating correct answers.
	* **Faithfulness:** LLMs' adherence to CoE even when it contains factual errors.
	* **Robustness:** LLMs' resistance to knowledge conflicts with CoE.
	* **Usability:** Application of CoE in a naive Retrieval-Augmented Generation (RAG) case.

**Findings:**

1. **CoE Enhances LLMs:** External knowledge with CoE improves LLMs' accuracy, faithfulness, and robustness.
2. **LLMs Prefer CoE:** Even with factual errors, LLMs exhibit significant faithfulness to CoE.
3. **CoE Improves RAG:** Applying CoE in a naive RAG framework enhances LLMs' accuracy with fewer knowledge pieces.

**Limitations:**

1. **Verification of CoE Correctness:** No step to verify the correctness of answers within retrieved CoE.
2. **Individual Contributions of CoE Features:** Not investigated in this paper.
3. **Usability Across RAG Scenarios:** Limited to textual-level RAG scenarios, not suitable for vector-based RAG.

**References:**
The paper includes an extensive list of references, indicating a thorough review of related literature in the field of LLMs, knowledge augmentation, and question answering.

Structured Evidence:
[
  {
    "claim_id": 1,
    "evidence": [
      {
        "evidence_id": 1,
        "evidence_text": "Table 2 shows the response accuracy of LLMs using CoE and two types of Non-CoE under different proportions of irrelevant information.",
        "strength": "strong",
        "limitations": "None",
        "location": "Section 5.2",
        "exact_quote": "Table 2: LLMs\u2019 Accuracy (ACC) on CoE and Non-CoE."
      },
      {
        "evidence_id": 2,
        "evidence_text": "The results show that CoE achieves an average accuracy of 92.0% across five LLMs and two datasets, outperforming Non-CoE variants SenP and WordP by 22.5% and 16.3%, respectively.",
        "strength": "strong",
        "limitations": "None",
        "location": "Section 5.2",
        "exact_quote": "The results show that CoE achieves an average accuracy of 92.0% across five LLMs and two datasets, outperforming Non-CoE variants SenP and WordP by 22.5% and 16.3%, respectively."
      }
    ]
  },
  {
    "claim_id": 2,
    "evidence": [
      {
        "evidence_id": 3,
        "evidence_text": "Table 3 shows the FR of LLMs with external knowledge under CoE and two types of Non-CoE containing incorrect answers.",
        "strength": "strong",
        "limitations": "None",
        "location": "Section 6.2",
        "exact_quote": "Table 3: LLMs\u2019 Following Rate (FR) on CoE and Non-CoE."
      },
      {
        "evidence_id": 4,
        "evidence_text": "The results show that under CoE, the average FR reaches 85.4%, which is 20.6% and 16.2% higher than the SenP and WordP types under Non-CoE respectively.",
        "strength": "strong",
        "limitations": "None",
        "location": "Section 6.2",
        "exact_quote": "The results show that under CoE, the average FR reaches 85.4%, which is 20.6% and 16.2% higher than the SenP and WordP types under Non-CoE respectively."
      }
    ]
  },
  {
    "claim_id": 3,
    "evidence": [
      {
        "evidence_id": 5,
        "evidence_text": "Table 4 shows LLMs\u2019 response accuracy (ACC) after adding misinformation to CoE and two types of Non-CoE.",
        "strength": "strong",
        "limitations": "None",
        "location": "Section 7.2",
        "exact_quote": "Table 4: LLMs\u2019 Accuracy (ACC) with CoE and Non-CoE surrounded by misinformation."
      },
      {
        "evidence_id": 6,
        "evidence_text": "The results show that under CoE, the average ACC of LLMs reaches 84.1%, which is 21.4% and 15.3% higher than the SenP and WordP types under Non-CoE respectively.",
        "strength": "strong",
        "limitations": "None",
        "location": "Section 7.2",
        "exact_quote": "The results show that under CoE, the average ACC of LLMs reaches 84.1%, which is 21.4% and 15.3% higher than the SenP and WordP types under Non-CoE respectively."
      }
    ]
  },
  {
    "claim_id": 4,
    "evidence": [
      {
        "evidence_id": 7,
        "evidence_text": "Table 5 shows LLMs\u2019 Accuracy (ACC) on naive RAG and RAG+ScopeCoE.",
        "strength": "strong",
        "limitations": "None",
        "location": "Section 8.4",
        "exact_quote": "Table 5: LLMs\u2019 Accuracy (ACC) on naive RAG and RAG+ScopeCoE."
      },
      {
        "evidence_id": 8,
        "evidence_text": "The results show that RAG+ScopeCoE achieves average ACC of 77.8% and 81.6% on HotpotQA and 2WikiMultihopQA respectively, outperforming RAG by 10.4% and 28.7%.",
        "strength": "strong",
        "limitations": "None",
        "location": "Section 8.4",
        "exact_quote": "The results show that RAG+ScopeCoE achieves average ACC of 77.8% and 81.6% on HotpotQA and 2WikiMultihopQA respectively, outperforming RAG by 10.4% and 28.7%."
      }
    ]
  }
]

Structured Conclusions:
[
  {
    "claim_id": 1,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 2,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 3,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 4,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 5,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 6,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 7,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 8,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 9,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 10,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 11,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 12,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 13,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 14,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 15,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 16,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 17,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 18,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 19,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 20,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 21,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 22,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 23,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 24,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 25,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 26,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 27,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 28,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 29,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 30,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 31,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 32,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 33,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 34,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 35,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 36,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 37,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 38,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 39,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 40,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 41,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 42,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 43,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 44,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 45,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 46,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 47,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 48,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 49,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  },
  {
    "claim_id": 50,
    "conclusion_justified": true,
    "robustness": "high",
    "key_limitations": "None",
    "confidence_level": "high"
  }
]


Execution Times:
claims_analysis_time: 70.32 seconds
evidence_analysis_time: 162.99 seconds
conclusions_analysis_time: 355.12 seconds
total_execution_time: 591.65 seconds
