Claim 1:
Type: performance
Statement: The proposed Multi-modal Grouping Network (MGN) achieves superior results on weakly-supervised audio-visual video parsing.
Location: Section 4.2
Exact Quote: As can be seen, the proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.

Evidence:
- Evidence Text: Table 1: Quantitative results of weakly-supervised audio-visual video parsing.
  Strength: strong
  Location: Table 1
  Limitations: Comparison is limited to the LLP dataset and specific evaluation metrics.
  Exact Quote: The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence strongly supports the claim, as the proposed MGN outperforms previous baselines in most metrics.
Key Limitations: Dataset and evaluation metrics limitations.

--------------------------------------------------

Claim 2:
Type: methodology
Statement: The proposed MGN is more efficient, using only 47.2% parameters of the baselines.
Location: Section 3.2
Exact Quote: When the depth of CUG and MCG is 3 and 6, the proposed MGN with only 47.2% parameters of the vanilla baseline performs the best on Type@AV and Event@AV, especially on Audio.

Evidence:
- Evidence Text: Comparison of model parameters and performance in Table 2.
  Strength: moderate
  Location: Table 2
  Limitations: Limited to the specific depths of CUG and MCG.
  Exact Quote: When the depth of CUG and MCG is 3 and 6, the proposed MGN with only 47.2% parameters of the vanilla baseline performs the best on Type@AV and Event@AV, especially on Audio.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence supports the claim, but is limited to specific depths of CUG and MCG.
Key Limitations: Limited generalizability to other depths.

--------------------------------------------------

Claim 3:
Type: contribution
Statement: The proposed MGN significantly eliminates false predictions caused by the modality and temporal uncertainties existing in the baseline.
Location: Section 4.3
Exact Quote: Our MGN with the class-aware unimodal grouping modules decreases the false positives of audio and visual events by large margins, 381 and 494.

Evidence:
- Evidence Text: Comparison of false positives between HAN and the proposed MGN in Figure 3.
  Strength: strong
  Location: Figure 3
  Limitations: Limited to the specific evaluation metric (false positives).
  Exact Quote: Our MGN with the class-aware unimodal grouping modules decreases the false positives of audio and visual events by large margins, 381 and 494.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence strongly supports the claim, showing a significant reduction in false positives.
Key Limitations: Limited to the specific evaluation metric.

--------------------------------------------------

