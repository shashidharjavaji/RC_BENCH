{
    "raw_claims": "```json\n{\n    \"claims\": [\n        {\n            \"claim_id\": 1,\n            \"claim_text\": \"We propose a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We propose a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 2,\n            \"claim_text\": \"FAME-ViL can save 61.5% of parameters over alternatives, while significantly outperforming the conventional independently trained single-task models.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Performance\",\n            \"exact_quote\": \"FAME-ViL can save 61.5% of parameters over alternatives, while significantly outperforming the conventional independently trained single-task models.\"\n        },\n        {\n            \"claim_id\": 3,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 4,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 5,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 6,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 7,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 8,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 9,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 10,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 11,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 12,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 13,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 14,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 15,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 16,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 17,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 18,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 19,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 20,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 21,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 22,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 23,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 24,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 25,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 26,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 27,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 28,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 29,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 30,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 31,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 32,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 33,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 34,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 35,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 36,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 37,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 38,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 39,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 40,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 41,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 42,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 43,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 44,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 45,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 46,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 47,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 48,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 49,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 50,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 51,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 52,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 53,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 54,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 55,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 56,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 57,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 58,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 59,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 60,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 61,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 62,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 63,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 64,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 65,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 66,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 67,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 68,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 69,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 70,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 71,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 72,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 73,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 74,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 75,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 76,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 77,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 78,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 79,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 80,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 81,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n            \"location\": \"3.1. Model architecture\",\n            \"claim_type\": \"Method\",\n            \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n        },\n        {\n            \"claim_id\": 82,\n            \"claim_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n            \"location\": \"1. Introduction\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n        },\n        {\n            \"claim_id\": 83,\n            \"claim_text\": \"Our FAME-ViL can switch among three operational modes to flexibly",
    "raw_evidence": "```json\n{\n    \"evidence_sets\": [\n        {\n            \"claim_id\": 1,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 1,\n                    \"evidence_text\": \"We propose a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"Abstract\",\n                    \"exact_quote\": \"We propose a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 2,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 2,\n                    \"evidence_text\": \"FAME-ViL can save 61.5% of parameters over alternatives, while significantly outperforming the conventional independently trained single-task models.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"Abstract\",\n                    \"exact_quote\": \"FAME-ViL can save 61.5% of parameters over alternatives, while significantly outperforming the conventional independently trained single-task models.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 3,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 3,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 4,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 4,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 5,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 5,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 6,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 6,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 7,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 7,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 8,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 8,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 9,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 9,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 10,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 10,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 11,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 11,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 12,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 12,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 13,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 13,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 14,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 14,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 15,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 15,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 16,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 16,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 17,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 17,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 18,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 18,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 19,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 19,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 20,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 20,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 21,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 21,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 22,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 22,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 23,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 23,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 24,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 24,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 25,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 25,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 26,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 26,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 27,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 27,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 28,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 28,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 29,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 29,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 30,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 30,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 31,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 31,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 32,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 32,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 33,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 33,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 34,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 34,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 35,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 35,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 36,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 36,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"1. Introduction\",\n                    \"exact_quote\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 37,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 37,\n                    \"evidence_text\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\",\n                    \"strength\": \"strong\",\n                    \"limitations\": \"None\",\n                    \"location\": \"3.1. Model architecture\",\n                    \"exact_quote\": \"Our FAME-ViL can switch among three operational modes to flexibly support various fashion tasks.\"\n                }\n            ]\n        },\n        {\n            \"claim_id\": 38,\n            \"evidence\": [\n                {\n                    \"evidence_id\": 38,\n                    \"evidence_text\": \"We introduce a novel FAshion-focused Multi-task Efficient learning method for Vision-and-Language tasks (FAME-ViL) in this work.\",\n                    \"strength\": \"strong\",\n                    \"limitations",
    "raw_conclusions": "```json\n{\n    \"conclusions\": [\n        {\n            \"claim_id\": 1,\n            \"conclusion_justified\": true,\n            \"robustness\": \"high\",\n            \"key_limitations\":",
    "execution_times": {
        "claims_analysis_time": "328.92 seconds",
        "evidence_analysis_time": "232.28 seconds",
        "conclusions_analysis_time": "5.12 seconds",
        "total_execution_time": "570.57 seconds"
    }
}