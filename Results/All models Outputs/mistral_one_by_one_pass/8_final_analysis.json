{
    "paper_analysis": [],
    "raw_claims": " For example:\n```json\n{\n    \"claims\": [\n        {\n            \"claim_id\": 1,\n            \"claim_text\": \"REPLUG is a retrieval-augmented language modeling framework that treats the language model as a black box and augments it with a tuneable retrieval model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG, a retrieval-augmented language modeling framework that treats the language model (LM) as a black box and augments it with a tuneable retrieval model.\"\n        },\n        {\n            \"claim_id\": 2,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments demonstrate that REPLUG with the tuned retriever significantly improves the performance of GPT-3 (175B) on language modeling by 6.3%, as well as the performance of Codex on five-shot MMLU by 5.1%.\"\n        },\n        {\n            \"claim_id\": 3,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 4,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 5,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 6,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 7,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 8,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 9,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 10,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 11,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 12,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 13,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 14,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 15,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 16,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 17,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 18,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 19,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 20,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 21,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 22,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 23,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 24,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 25,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 26,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 27,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 28,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 29,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 30,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 31,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 32,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 33,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 34,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 35,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 36,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 37,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 38,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 39,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 40,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 41,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 42,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 43,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 44,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 45,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 46,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 47,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 48,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 49,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 50,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 51,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 52,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 53,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 54,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 55,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 56,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 57,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 58,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 59,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 60,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 61,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 62,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 63,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 64,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 65,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 66,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 67,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 68,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 69,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 70,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 71,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n        },\n        {\n            \"claim_id\": 72,\n            \"claim_text\": \"REPLUG LSR can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"We introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model.\"\n        },\n        {\n            \"claim_id\": 73,\n            \"claim_text\": \"REPLUG LSR outperforms various off-the-shelf retrievers and leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance.\"\n        },\n        {\n            \"claim_id\": 74,\n            \"claim_text\": \"REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU and open-domain QA.\",\n            \"location\": \"Abstract\",\n            \"claim_type\": \"Contribution\",\n            \"exact_quote\": \"Our experiments show that REPLUG can improve the performance of var\"\n       ",
    "raw_evidence": "",
    "raw_conclusions": "",
    "execution_times": {
        "claims_analysis_time": "322.11 seconds",
        "evidence_analysis_time": "1.71 seconds",
        "conclusions_analysis_time": "1.71 seconds",
        "total_execution_time": "328.60 seconds"
    }
}