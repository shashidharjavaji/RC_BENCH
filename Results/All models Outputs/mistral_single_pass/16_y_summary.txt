Claim 1:
Type: result
Statement: LLMs have limited financial domain knowledge and insufficient mathematical capabilities when analyzing XBRL reports.
Location: Section 3.3
Exact Quote: Our analysis reveals two inherent limitations of LLMs for XBRL report analysis, which are difficult to address through internal mechanisms such as prompt engineering alone.

Evidence:
- Evidence Text: The models demonstrate insufficient mastery of specialized financial knowledge and terminology, hindering their ability to provide accurate and granular interpretations of XBRL reports.
  Strength: strong
  Location: Section 3.3
  Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.
  Exact Quote: The models demonstrate insufficient mastery of specialized financial knowledge and terminology, hindering their ability to provide accurate and granular interpretations of XBRL reports.

- Evidence Text: The LLMs exhibit a notable weakness in processing and interpreting numeric information, encountering difficulties in performing complex financial calculations and deriving meaningful insights from numerical data in XBRL reports.
  Strength: strong
  Location: Section 3.3
  Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.
  Exact Quote: The LLMs exhibit a notable weakness in processing and interpreting numeric information, encountering difficulties in performing complex financial calculations and deriving meaningful insights from numerical data in XBRL reports.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence is supported by experimental results and specific examples from the motivating experiment.
Key Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.

--------------------------------------------------

Claim 2:
Type: methodology
Statement: The XBRL-Agent, a LLM agent integrated with specialized tools for XBRL analysis, aims to mitigate the limitations of LLMs with external tools to generate more accurate text.
Location: Section 4
Exact Quote: Inspired by prior LLM agent frameworks, we establish XBRL Agent, a LLM agent integrated with specialized tools for XBRL analysis.

Evidence:
- Evidence Text: The XBRL-Agent uses a retriever and a calculator to enhance the LLM’s ability to handle domain-specific financial tasks and perform complex financial calculations.
  Strength: strong
  Location: Section 4
  Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.
  Exact Quote: The XBRL-Agent uses a retriever and a calculator to enhance the LLM’s ability to handle domain-specific financial tasks and perform complex financial calculations.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence is supported by the description of the XBRL-Agent and its components.
Key Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.

--------------------------------------------------

Claim 3:
Type: contribution
Statement: The retriever tool enhances the LLM’s ability to handle domain-specific financial tasks by retrieving relevant background information from a knowledge base.
Location: Section 4.1
Exact Quote: To address the limited financial domain knowledge of LLMs in domain query task, we propose implementing a retriever tool through the RAG process.

Evidence:
- Evidence Text: The retriever tool improves the performance of all three tested LLMs in the XBRL Domain Query Task.
  Strength: strong
  Location: Section 5.2
  Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.
  Exact Quote: Implementing a retriever for domain-related queries improves the performance of all three tested LLMs, as shown in the left two columns of Figure 6.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence is supported by experimental results showing improvements in the XBRL Domain Query Task.
Key Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.

--------------------------------------------------

Claim 4:
Type: contribution
Statement: The calculator tool enhances the LLM’s ability to perform complex financial calculations by invoking a financial calculator.
Location: Section 4.1
Exact Quote: To mitigate the deficient mathematical capabilities of LLMs in numeric type query, we introduce a calculator tool.

Evidence:
- Evidence Text: The calculator tool improves the performance of all three tested LLMs in the Financial Math Task.
  Strength: strong
  Location: Section 5.2
  Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.
  Exact Quote: Integrating a calculator into LLMs improves their performance on numeric type queries (Fig. 6, right columns).

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence is supported by experimental results showing improvements in the Financial Math Task.
Key Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.

--------------------------------------------------

Claim 5:
Type: result
Statement: Combining the retriever and calculator for numeric type query tasks yields significant improvements in both financial math and numeric queries.
Location: Section 5.2
Exact Quote: Combining the retriever and calculator for numeric type query task yields significant improvements (Figure 7).

Evidence:
- Evidence Text: For Financial Math, Llama3-8B led by 67% accuracy, followed by Qwen2-7B (61%) and Gemma2-9B (59%).
  Strength: strong
  Location: Section 5.2
  Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.
  Exact Quote: For Financial Math, Llama3-8B led by 67% accuracy, followed by Qwen2-7B (61%) and Gemma2-9B (59%).

- Evidence Text: For Numeric Query to XBRL Reports task, Llama3-8B (53%), Gemma2-9B (49%), and Qwen2-7B (46%), representing increases of 25 to 30 percentage points compared to the single tool approach.
  Strength: strong
  Location: Section 5.2
  Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.
  Exact Quote: For Numeric Query to XBRL Reports task, Llama3-8B (53%), Gemma2-9B (49%), and Qwen2-7B (46%), representing increases of 25 to 30 percentage points compared to the single tool approach.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence is supported by experimental results showing improvements in both financial math and numeric queries.
Key Limitations: The study is limited to specific LLMs and datasets, and the findings may not generalize to other models or data.

--------------------------------------------------

