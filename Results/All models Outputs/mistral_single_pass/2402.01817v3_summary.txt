Claim 1:
Type: contribution
Statement: Large Language Models (LLMs) cannot, by themselves, do planning or self-verification.
Location: Abstract
Exact Quote: We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification (which is after all a form of reasoning), and shed some light on the reasons for misunderstandings in the literature.

Evidence:
- Evidence Text: Results in the autonomous mode are pretty bleak. On average, only about 12% of the plans that the best LLM (GPT-4) generates are actually executable without errors and goal-reaching.
  Strength: strong
  Location: Section 2.1
  Limitations: The study only focuses on a specific set of LLMs and planning domains.
  Exact Quote: We show that results in the autonomous mode are pretty bleak. On average, only about 12% of the plans that the best LLM (GPT-4) generates are actually executable without errors and goal-reaching.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results showing that LLMs struggle to generate executable plans.
Key Limitations: The study only focuses on a specific set of LLMs and planning domains.

--------------------------------------------------

Claim 2:
Type: contribution
Statement: LLMs can be a whole lot more than machine translators.
Location: Introduction
Exact Quote: They are a kind of approximate knowledge source (albeit sans guarantees) trained on our collective consciousness. While it is unlikely that they will have System 2 competencies by themselves, they can nevertheless be valuable resources in solving System 2 tasks.

Evidence:
- Evidence Text: The problem with Alchemy of yore was not that Chemistry is useless, but that people wanted to delude themselves that Chemistry–a pretty amazing discipline on its own merits–can be Nuclear Physics if you prompt it just so.
  Strength: moderate
  Location: Introduction
  Limitations: The analogy is used to illustrate a point rather than provide empirical evidence.
  Exact Quote: The problem with Alchemy of yore was not that Chemistry is useless, but that people wanted to delude themselves that Chemistry–a pretty amazing discipline on its own merits–can be Nuclear Physics if you prompt it just so.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The analogy is used to illustrate a point rather than provide empirical evidence.
Key Limitations: The analogy is used to illustrate a point rather than provide empirical evidence.

--------------------------------------------------

Claim 3:
Type: methodology
Statement: LLMs can play a variety of constructive roles in solving planning tasks–especially as approximate knowledge sources and candidate plan generators in so-called LLM-Modulo Frameworks, where they are used in conjunction with external sound model-based verifiers.
Location: Introduction
Exact Quote: The central position of the paper is that LLMs cannot plan themselves but can play a variety of constructive roles in solving planning tasks–especially as approximate knowledge sources and candidate plan generators in so-called LLM-Modulo Frameworks, where they are used in conjunction with external sound model-based verifiers.

Evidence:
- Evidence Text: The LLM-Modulo architecture is a 'Generate-Test' one that involves LLMs interacting with the external critics/verifiers rather than a LLMs being just frontends to external solvers.
  Strength: strong
  Location: Section 3.1
  Limitations: The architecture is described but not empirically tested.
  Exact Quote: The LLM-Modulo architecture is a 'Generate-Test' one that involves LLMs interacting with the external critics/verifiers rather than a LLMs being just frontends to external solvers.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The architecture is described and supported by the methodology.
Key Limitations: The architecture is described but not empirically tested.

--------------------------------------------------

Claim 4:
Type: contribution
Statement: LLMs can help in generating plans, translating plans into syntactic forms, and helping end users flesh out incomplete specifications.
Location: Section 3.4
Exact Quote: The LLM plays a role in converting the guessed plan candidate into specialized representations used by the various critics (e.g., the time-line view, the causal link view etc.).

Evidence:
- Evidence Text: The LLM plays a role in converting the guessed plan candidate into specialized representations used by the various critics (e.g., the time-line view, the causal link view etc.).
  Strength: strong
  Location: Section 3.4
  Limitations: The role is described but not empirically tested.
  Exact Quote: The LLM plays a role in converting the guessed plan candidate into specialized representations used by the various critics (e.g., the time-line view, the causal link view etc.).

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The role is described and supported by the methodology.
Key Limitations: The role is described but not empirically tested.

--------------------------------------------------

