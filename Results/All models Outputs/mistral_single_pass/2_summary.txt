Claim 1:
Type: result
Statement: Language models can produce well-calibrated probabilities when they are asked to choose the correct answer from among several explicit options.
Location: Section 2
Exact Quote: We find that when multiple choice problems are formatted in this way (as used by e.g. [Rae et al., 2021]), our largest models tend to produce a well-calibrated probability distribution among the available options.

Evidence:
- Evidence Text: Figure 4 shows calibration curves for various model sizes on all of the multiple choice tasks in BIG Bench, in the format described in section 2.
  Strength: strong
  Location: Section 2
  Limitations: None
  Exact Quote: Figure 4 shows calibration curves for various model sizes on all of the multiple choice tasks in BIG Bench, in the format described in section 2.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the experimental results showing well-calibrated probabilities for multiple choice tasks.
Key Limitations: None

--------------------------------------------------

Claim 2:
Type: methodology
Statement: Language models can evaluate their own outputs by generating potential answers to questions and then having the model evaluate whether any of them are correct.
Location: Section 3
Exact Quote: That is, we can simply ask models to generate potential answers to questions, and then have the model evaluate whether any of them are correct.

Evidence:
- Evidence Text: Figure 1 shows the overall ability of a 52B language model to evaluate its own proposed answers to questions from TriviaQA, Lambada, Arithmetic, GSM8k, and Codex HumanEval.
  Strength: strong
  Location: Section 3
  Limitations: None
  Exact Quote: Figure 1 shows the overall ability of a 52B language model to evaluate its own proposed answers to questions from TriviaQA, Lambada, Arithmetic, GSM8k, and Codex HumanEval.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the experimental results showing the ability of language models to evaluate their own outputs.
Key Limitations: None

--------------------------------------------------

Claim 3:
Type: contribution
Statement: Language models can be trained to predict whether they know the answer to any given free-form question.
Location: Section 5
Exact Quote: We train models to predict whether they know the answer to any given free-form question, denoting the probability they assign as ‘P(IK)’ (for Probability that I Know the answer).

Evidence:
- Evidence Text: Figure 12 shows that the model is able to separate the questions it got correct and incorrect quite well.
  Strength: strong
  Location: Section 5
  Limitations: None
  Exact Quote: Figure 12 shows that the model is able to separate the questions it got correct and incorrect quite well.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the experimental results showing the ability of language models to predict whether they know the answer to any given free-form question.
Key Limitations: None

--------------------------------------------------

Claim 4:
Type: result
Statement: P(IK) generalizes to account for source materials.
Location: Section 5.3
Exact Quote: We see that including the article increases P(IK). Furthermore, shorter articles increase P(IK) more.

Evidence:
- Evidence Text: Figure 18 shows the effects of including Wikipedia articles on P(IK).
  Strength: strong
  Location: Section 5.3
  Limitations: None
  Exact Quote: Figure 18 shows the effects of including Wikipedia articles on P(IK).

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the experimental results showing that P(IK) generalizes to account for source materials.
Key Limitations: None

--------------------------------------------------

Claim 5:
Type: result
Statement: P(IK) generalizes to account for hints towards GSM8k solutions.
Location: Section 5.4
Exact Quote: We see that showing more of the hint generally leads to higher P(IK).

Evidence:
- Evidence Text: Figure 19 shows the effect of hints on P(IK) applied to GSM8k.
  Strength: strong
  Location: Section 5.4
  Limitations: None
  Exact Quote: Figure 19 shows the effect of hints on P(IK) applied to GSM8k.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the experimental results showing that P(IK) generalizes to account for hints towards GSM8k solutions.
Key Limitations: None

--------------------------------------------------

Claim 6:
Type: contribution
Statement: P(IK) can be used to distinguish between models trained with distinct pretraining distributions.
Location: Section 5.5
Exact Quote: We studied two 12B models (with identical architecture) that were pretrained on distinct data distributions.

Evidence:
- Evidence Text: The models get many of the same questions correct and incorrect.
  Strength: moderate
  Location: Section 5.5
  Limitations: None
  Exact Quote: The models get many of the same questions correct and incorrect.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The claim is supported by the experimental results showing that P(IK) can be used to distinguish between models trained with distinct pretraining distributions.
Key Limitations: None

--------------------------------------------------

