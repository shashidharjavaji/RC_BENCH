Claim 1:
Type: contribution
Statement: MME is the first comprehensive MLLM evaluation benchmark.
Location: Introduction
Exact Quote: In this paper, we fill in this blank, presenting the first comprehensive MLLM Evaluation benchmark MME.

Evidence:
- Evidence Text: The paper presents MME as a new benchmark.
  Strength: strong
  Location: Introduction
  Limitations: None stated in the abstract.
  Exact Quote: In this paper, we fill in this blank, presenting the first comprehensive MLLM Evaluation benchmark MME.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper introduces MME as a new benchmark, which is supported by the detailed description of the benchmark in the subsequent sections.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 2:
Type: methodology
Statement: MME measures both perception and cognition abilities on a total of 14 subtasks.
Location: Introduction
Exact Quote: It measures both perception and cognition abilities on a total of 14 subtasks.

Evidence:
- Evidence Text: The paper describes 14 subtasks covering perception and cognition.
  Strength: strong
  Location: Introduction
  Limitations: None stated in the abstract.
  Exact Quote: It measures both perception and cognition abilities on a total of 14 subtasks.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a detailed description of the 14 subtasks, which cover both perception and cognition.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 3:
Type: methodology
Statement: The annotations of instruction-answer pairs are all manually designed to avoid data leakage.
Location: Introduction
Exact Quote: However, on the one hand, it may be hard to reflect the emergent abilities of MLLMs on these datasets. On the other hand, since the training sets of large models are no longer unified, it is difficult to guarantee that all MLLMs have not used the testing set for training.... The annotations of instruction-answer pairs are all manually designed.

Evidence:
- Evidence Text: The paper states that manual design of instruction-answer pairs is used to avoid data leakage.
  Strength: strong
  Location: Introduction
  Limitations: None stated in the abstract.
  Exact Quote: However, on the one hand, it may be hard to reflect the emergent abilities of MLLMs on these datasets. On the other hand, since the training sets of large models are no longer unified, it is difficult to guarantee that all MLLMs have not used the testing set for training.... All instruction-answer pairs are manually designed.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a clear rationale for the manual design of instruction-answer pairs to avoid data leakage.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 4:
Type: methodology
Statement: MME's instruction design allows for easy quantitative statistics.
Location: Introduction
Exact Quote: The responses of MLLMs to the instructions should be intuitive and convenient for quantitative analysis.

Evidence:
- Evidence Text: The paper states that the instruction design allows for easy quantitative statistics.
  Strength: strong
  Location: Introduction
  Limitations: None stated in the abstract.
  Exact Quote: The responses of MLLMs to the instructions should be intuitive and convenient for quantitative analysis.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a clear rationale for the instruction design allowing for easy quantitative statistics.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 5:
Type: result
Statement: A total of 30 advanced MLLMs are comprehensively evaluated on MME.
Location: Introduction
Exact Quote: A total of 30 advanced MLLMs are comprehensively evaluated on our MME.

Evidence:
- Evidence Text: The paper presents a leaderboard with 30 MLLMs.
  Strength: strong
  Location: Introduction
  Limitations: None stated in the abstract.
  Exact Quote: A total of 30 advanced MLLMs are comprehensively evaluated on our MME.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper presents a leaderboard with 30 MLLMs, which supports the claim.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 6:
Type: result
Statement: Existing MLLMs still have a large room for improvement.
Location: Results
Exact Quote: The evaluated MLLMs show clear discrepancies in our MME evaluation benchmark.

Evidence:
- Evidence Text: The paper presents a leaderboard showing discrepancies among MLLMs.
  Strength: strong
  Location: Results
  Limitations: None stated in the abstract.
  Exact Quote: The evaluated MLLMs show clear discrepancies in our MME evaluation benchmark.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The leaderboard shows discrepancies among MLLMs, which supports the claim.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 7:
Type: result
Statement: MME reveals the potential directions for subsequent model optimization.
Location: Results
Exact Quote: It is expected that these findings are instructive for the subsequent model optimization.

Evidence:
- Evidence Text: The paper presents a leaderboard showing discrepancies among MLLMs.
  Strength: strong
  Location: Results
  Limitations: None stated in the abstract.
  Exact Quote: The evaluated MLLMs show clear discrepancies in our MME evaluation benchmark.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The leaderboard shows discrepancies among MLLMs, which supports the claim.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 8:
Type: methodology
Statement: MME covers the examination of perception and cognition.
Location: 2. MME Evaluation Suite
Exact Quote: MME covers the examination of perception and cognition abilities.

Evidence:
- Evidence Text: The paper describes 14 subtasks covering perception and cognition.
  Strength: strong
  Location: 2. MME Evaluation Suite
  Limitations: None stated in the abstract.
  Exact Quote: MME covers the examination of perception and cognition abilities.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a detailed description of the 14 subtasks, which supports the claim.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 9:
Type: methodology
Statement: MME's instruction design is concise and in line with human cognition.
Location: 2. MME Evaluation Suite
Exact Quote: The instructions of MME are designed concisely to avoid the impact of prompt engineering on the model output.

Evidence:
- Evidence Text: The paper states that the instructions are designed concisely to avoid the impact of prompt engineering.
  Strength: strong
  Location: 2. MME Evaluation Suite
  Limitations: None stated in the abstract.
  Exact Quote: The instructions of MME are designed concisely to avoid the impact of prompt engineering on the model output.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a clear rationale for the instruction design being concise and in line with human cognition.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 10:
Type: methodology
Statement: MME's evaluation metric is based on accuracy and accuracy+.
Location: 2. MME Evaluation Suite
Exact Quote: We calculate the metrics of accuracy and accuracy+.

Evidence:
- Evidence Text: The paper describes the use of accuracy and accuracy+ as evaluation metrics.
  Strength: strong
  Location: 2. MME Evaluation Suite
  Limitations: None stated in the abstract.
  Exact Quote: We calculate the metrics of accuracy and accuracy+.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a clear rationale for the use of accuracy and accuracy+ as evaluation metrics.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 11:
Type: methodology
Statement: MME's data collection avoids using publicly available datasets.
Location: 2. MME Evaluation Suite
Exact Quote: All instruction-answer pairs are manually constructed. For the few public datasets involved in our study, we only use images without directly relying on their original annotations.

Evidence:
- Evidence Text: The paper states that all instruction-answer pairs are manually constructed and that public datasets are used without relying on original annotations.
  Strength: strong
  Location: 2. MME Evaluation Suite
  Limitations: None stated in the abstract.
  Exact Quote: All instruction-answer pairs are manually constructed. For the few public datasets involved in our study, we only use images without directly relying on their original annotations.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a clear rationale for the data collection method.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 12:
Type: methodology
Statement: MME's perception tasks include coarse-grained and fine-grained recognition, and OCR.
Location: 2. MME Evaluation Suite
Exact Quote: The perception tasks include coarse-grained and fine-grained recognition, and OCR.

Evidence:
- Evidence Text: The paper describes the perception tasks as including coarse-grained and fine-grained recognition, and OCR.
  Strength: strong
  Location: 2. MME Evaluation Suite
  Limitations: None stated in the abstract.
  Exact Quote: The perception tasks include coarse-grained and fine-grained recognition, and OCR.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a clear rationale for the perception tasks.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 13:
Type: methodology
Statement: MME's cognition tasks include commonsense reasoning, numerical calculation, text translation, and code reasoning.
Location: 2. MME Evaluation Suite
Exact Quote: The cognition tasks include commonsense reasoning, numerical calculation, text translation, and code reasoning.

Evidence:
- Evidence Text: The paper describes the cognition tasks as including commonsense reasoning, numerical calculation, text translation, and code reasoning.
  Strength: strong
  Location: 2. MME Evaluation Suite
  Limitations: None stated in the abstract.
  Exact Quote: The cognition tasks include commonsense reasoning, numerical calculation, text translation, and code reasoning.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a clear rationale for the cognition tasks.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 14:
Type: methodology
Statement: MME's evaluation metric is based on accuracy and accuracy+.
Location: 2. MME Evaluation Suite
Exact Quote: We calculate the metrics of accuracy and accuracy+.

Evidence:
- Evidence Text: The paper describes the use of accuracy and accuracy+ as evaluation metrics.
  Strength: strong
  Location: 2. MME Evaluation Suite
  Limitations: None stated in the abstract.
  Exact Quote: We calculate the metrics of accuracy and accuracy+.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a clear rationale for the use of accuracy and accuracy+ as evaluation metrics.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 15:
Type: methodology
Statement: MME's data collection involves manually photographed or generated images.
Location: 2. MME Evaluation Suite
Exact Quote: The images are sampled from COCO, but the instruction-answer pairs are all manually constructed, rather than directly using publicly available annotations.

Evidence:
- Evidence Text: The paper states that the images are sampled from COCO, but the instruction-answer pairs are all manually constructed.
  Strength: strong
  Location: 2. MME Evaluation Suite
  Limitations: None stated in the abstract.
  Exact Quote: The images are sampled from COCO, but the instruction-answer pairs are all manually constructed, rather than directly using publicly available annotations.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The paper provides a clear rationale for the data collection method.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 16:
Type: result
Statement: MME's evaluation results show that there is still a large room for improvement in MLLMs.
Location: Results
Exact Quote: The evaluated MLLMs show clear discrepancies in our MME evaluation benchmark.

Evidence:
- Evidence Text: The paper presents a leaderboard showing discrepancies among MLLMs.
  Strength: strong
  Location: Results
  Limitations: None stated in the abstract.
  Exact Quote: The evaluated MLLMs show clear discrepancies in our MME evaluation benchmark.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The leaderboard shows discrepancies among MLLMs, which supports the claim.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 17:
Type: result
Statement: MME's evaluation results reveal four common problems in MLLMs.
Location: Results
Exact Quote: We also summarize the common problem raised in experimental results, providing valuable guidance for the development of MLLM.

Evidence:
- Evidence Text: The paper presents a leaderboard showing discrepancies among MLLMs and summarizes four common problems.
  Strength: strong
  Location: Results
  Limitations: None stated in the abstract.
  Exact Quote: We also summarize the common problem raised in experimental results, providing valuable guidance for the development of MLLM.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The leaderboard shows discrepancies among MLLMs and summarizes four common problems, which supports the claim.
Key Limitations: None stated in the abstract.

--------------------------------------------------

Claim 18:
Type: result
Statement: MME's evaluation results provide valuable guidance for the development of MLLMs.
Location: Results
Exact Quote: We also summarize the common problem raised in experimental results, providing valuable guidance for the development of MLLM.

Evidence:
- Evidence Text: The paper presents a leaderboard showing discrepancies among MLLMs and summarizes four common problems.
  Strength: strong
  Location: Results
  Limitations: None stated in the abstract.
  Exact Quote: We also summarize the common problem raised in experimental results, providing valuable guidance for the development of MLLM.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The leaderboard shows discrepancies among MLLMs and summarizes four common problems, which supports the claim.
Key Limitations: None stated in the abstract.

--------------------------------------------------

