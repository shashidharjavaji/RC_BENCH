Claim 1:
Type: result
Statement: Most LLMs struggle to faithfully translate natural language instructions into grounded states in the environment.
Location: Section 4.1, Goal Interpretation
Exact Quote: Most LLMs still struggle to faithfully translate natural language instructions into grounded states (objects, object states, and relations) in the environment.

Evidence:
- Evidence Text: GPT-4o makes no parsing errors in both simulators, while Llama 3 8B makes parsing errors in 0.6% of cases in VirtualHome and 2.0% in BEHAVIOR.
  Strength: moderate
  Location: Section 4.1, Goal Interpretation
  Limitations: limited to parsing errors, does not cover all types of errors
  Exact Quote: GPT-4o makes no parsing errors in both simulators, while Llama 3 8B makes parsing errors in 0.6% of cases in VirtualHome and 2.0% in BEHAVIOR.

- Evidence Text: Gemini 1.5 Pro achieves the highest overall goal interpretation performance (F1-score) in both VirtualHome and BEHAVIOR simulators.
  Strength: strong
  Location: Section 4.1, Goal Interpretation
  Limitations: performance on specific tasks, not generalizable to all LLMs
  Exact Quote: Gemini 1.5 Pro achieves the highest overall goal interpretation performance (F1-score) in both VirtualHome and BEHAVIOR simulators.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence provided shows that most LLMs have difficulty with goal interpretation, and Gemini 1.5 Pro outperforms other models.
Key Limitations: The evidence is limited to parsing errors and does not cover all types of errors.

--------------------------------------------------

Claim 2:
Type: result
Statement: Reasoning ability is a crucial aspect that LLMs should improve.
Location: Section 4.1, Action Sequencing
Exact Quote: Reasoning ability is a crucial aspect that LLMs should improve.

Evidence:
- Evidence Text: Trajectory runtime errors are common (41.2%), with a large portion of missing step (15.5%) and additional step (16.2%) errors.
  Strength: strong
  Location: Section 4.1, Action Sequencing
  Limitations: limited to runtime errors, does not cover all types of errors
  Exact Quote: Trajectory runtime errors are common (41.2%), with a large portion of missing step (15.5%) and additional step (16.2%) errors.

- Evidence Text: The success rate drops from around 60% for tasks with fewer than 5 goals to below 40% for tasks with more than 10 goals.
  Strength: moderate
  Location: Section 4.1, Action Sequencing
  Limitations: limited to task complexity, does not cover other factors
  Exact Quote: The success rate drops from around 60% for tasks with fewer than 5 goals to below 40% for tasks with more than 10 goals.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence provided shows that reasoning ability is a crucial aspect that LLMs should improve.
Key Limitations: The evidence is limited to task complexity, does not cover other factors.

--------------------------------------------------

Claim 3:
Type: result
Statement: Subgoal decomposition is not strictly easier than action sequencing in abstract action spaces.
Location: Section 4.1, Subgoal Decomposition
Exact Quote: Subgoal decomposition is not strictly easier than action sequencing in abstract action spaces.

Evidence:
- Evidence Text: o1-preview demonstrates superior performance in both VirtualHome and BEHAVIOR simulators compared to other state-of-the-art (SOTA) LLMs, with success rates of 89.4% and 57.0%, respectively.
  Strength: strong
  Location: Section 4.1, Subgoal Decomposition
  Limitations: performance on specific tasks, not generalizable to all LLMs
  Exact Quote: o1-preview demonstrates superior performance in both VirtualHome and BEHAVIOR simulators compared to other state-of-the-art (SOTA) LLMs, with success rates of 89.4% and 57.0%, respectively.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence provided shows that subgoal decomposition is not strictly easier than action sequencing in abstract action spaces.
Key Limitations: The evidence is limited to performance on specific tasks, not generalizable to all LLMs.

--------------------------------------------------

