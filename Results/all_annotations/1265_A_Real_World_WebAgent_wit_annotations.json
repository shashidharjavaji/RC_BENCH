[
    {
        "Claim_id": 1,
        "Claim_text": "We propose WebAgent, integration of two modular LLMs under self-supervision for real-world web automation. The domain-expert language model handles planning and HTML summarization, and a generalist language model generates executable Python programs.",
        "Evidence_text": "WebAgent is a new architecture that combines two LLMs to achieve efficient real-world web automation. HTML-T5, a domain-expert LLM, is responsible for predicting the next sub-instruction (planning) and generating related HTML snippets (summarization). Flan-U-PaLM (540B) (Chowdhery et al., 2022; Chung et al., 2022), is prompted to generate executable Python programs based on the planning and summarization provided by HTML-T5 (Figure 3). This modular two-stage approach enables WebAgent to effectively navigate and process HTML documents.",
        "Justification_Conclusion": "True. The authors state the related technical details in the methodology section of the paper."
    },
    {
        "Claim_id": 2,
        "Claim_text": "We newly introduce HTML-T5 – a language model with local-global attention mechanism that is pre-trained with a mixture of long-span denoising objective on a large-scale HTML corpus, curated from CommonCrawl, to capture the syntax and semantics of HTML better.",
        "Evidence_text": "utilize the HTML-specific information that could otherwise lead to better understanding of HTML content. To address this limitation, we introduce HTML-T5, a pre-trained encoder-decoder language model specifically designed for HTML-based web automation tasks. HTML-T5 carefully merges the generalist and specialist characteristics of language models… HTML-T5 is pre-trained on a large-scale HTML corpus curated from CommonCrawl using a mixture of long-span denoising objectives (Tay et al., 2022), and then finetuned it for each downstream task.",
        "Justification_Conclusion": "True. The authors state the related technical details in the methodology section of the paper."
    },
    {
        "Claim_id": 3,
        "Claim_text": "WebAgent notably improves the success rate by over 50% in real websites. When fine-tuned on downstream demonstrations, HTML-T5 itself outperforms prior language model agent by 18.7% in MiniWoB++, and achieves SoTA performance in Mind2Web, even surpassing GPT-4.",
        "Evidence_text": "Table 3 shows that HTML-T5-XL significantly outperforms WebN-T5, the prior best model, by 18.7%.",
        "Justification_Conclusion": "True. The authors share the related experimental result in the paper to support this claim."
    }
]