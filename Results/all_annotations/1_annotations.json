[
    
    {
        "claim_id": 1,
        "claim_text": "A machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. Lexical overlap: Assume that a premise entails all hypotheses constructed from words in the premise; Subsequence: Assume that a premise entails all of its contiguous subsequences.; Assume that a premise entails all complete subtrees in its parse tree.",
        "evidence_text": "All models achieved high scores on the MNLI test set (Figure 1a), replicating the accuracies found in past work (DA: Gururangan et al. 2018; ESIM: Williams et al. 2018b; SPINN: Williams et al. 2018a; BERT: Devlin et al. 2019). On the HANS dataset, all models almost always assigned the correct label in the cases where the label is entailment, i.e., where the correct answer is in line with the hypothesized heuristics. However, they all performed poorly—with accuracies less than 10% in most cases, when chance is 50%—on the cases where the heuristics make incorrect predictions. Thus, despite their high scores on the MNLI test set, all four models behaved in a way consistent with the use of the heuristics targeted in HANS, and not with the correct rules of inference.",
        "justification_conclusion": "The models perform well on the cases that are consistent with the hypothesized heuristics, but poorly on the cases where the heuristics make incorrect predictions. This suggests that the models may be relying on these heuristics to perform well on the MNLI test set."
    },
    {
        "claim_id": 2,
        "claim_text": "The behavior of a trained model depends on both the training set and the model’s architecture. The models’ poor results on HANS could therefore arise from architectural limitations, from insufficient signal in the MNLI training set, or from both.",
        "evidence_text": "The fact that SPINN did markedly better at the constituent and subsequence cases than ESIM and DA, even though the three models were trained on the same dataset, suggests that MNLI does contain some signal that can counteract the appeal of the syntactic heuristics tested by HANS. SPINN’s structural inductive biases allow it to leverage this signal, but the other models’ biases do not. Other sources of evidence suggest that the models’ failure is due in large part to insufficient signal from the MNLI training set, rather than the models’ representational capacities alone. The BERT model we used (bert-base-uncased) was found by Goldberg (2019) to achieve strong results in syntactic tasks such as subject-verb agreement prediction, a task that minimally requires a distinction between the subject and direct object of a sentence (Linzen et al., 2016; Gulordava et al., 2018; Marvin and Linzen, 2018). Despite this evidence that BERT has access to relevant syntactic information, its accuracy was 0% on the subject-object swap cases (e.g., The doctor saw the lawyer 9 The lawyer saw the doctor). We believe it is unlikely that our fine-tuning step on MNLI, a much smaller corpus than the corpus BERT was trained on, substantially changed the model’s representational capabilities. Even though the model most likely had access to information about subjects and objects, then, MNLI did not make it clear how that information applies to inference. Supporting this conclusion, McCoy et al. (2019) found little evidence of compositional structure in the InferSent model, which was trained on SNLI, even though the same model type (an RNN) did learn clear compositional structure when trained on tasks that underscored the need for such structure. These results further suggest that the models’ poor compositional behavior arises more because of the training set than because of model architecture. Finally, our BERT-based model differed from the other models in that it was pretrained on a massive amount of data on a masking task and a next-sentence classification task, followed by finetuning on MNLI, while the other models were only trained on MNLI; we therefore cannot rule out the possibility that BERT’s comparative success at HANS was due to the greater amount of data it has encountered rather than any architectural features.",
        "justification_conclusion": "The SPINN model's special structural biases allow it to leverage the some signal in the MNLI that others cannot use to allow it perform well on the HANS dataset. The BERT model pretrained on massive amount of data to make it perform better on the HANS dataset. Thus, both dataset and structure can contribute to form the heuristics."
    },
    {
        "claim_id": 3,
        "claim_text": "However, since most models we tested are in theory capable of handling HANS’s examples but failed to do so when trained on MNLI, it is likely that performance could also be improved by training the same architectures on a dataset in which these heuristics are less successful.",
        "evidence_text": "In general, the models trained on the augmented MNLI performed very well on HANS (Figure 2); the one exception was that the DA model performed poorly on subcases for which a bag-of-words representation was inadequate.",
        "justification_conclusion": "Pretraining on the heuristics based dataset can help to improve the performance of the models."
    }
]