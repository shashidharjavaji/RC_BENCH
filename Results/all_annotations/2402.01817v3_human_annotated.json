{
    "annotations": [
        {
            "claim": "We present a vision of LLM-Modulo Frameworks that combines the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime.",
            "evidences": [
                "Figure 3 gives a schematic of the LLM-Modulo Frame- work, as we envision it. As can be seen readily, the un- derlying architecture is a Generate-Test-Critique loop, with the LLM generating candidate plans and a bank of critics critiquing the candidate. The loop starts with the LLM get- ting the problem specification and generating its first plan candidate.8 Note that the plans an LLM helps generate in this architecture have soundness guarantees because of the external sound critics. This means that plans coming out of such an compound system will constitute a better corpus of synthetic data for any fine tuning phase carried out to improve/customize the LLM’s generation capability. The completeness of the system depends on the LLM’s ability to generate all potentially relevant candidates.",
                "Design Choices: Before going into the details about the framework and its various modules, it is worth noting some design decisions underlying the proposed architecture. We start by noting that the LLM-Modulo architecture is a “Generate-Test” one that involves LLMs interacting with the external critics/verifiers rather than a LLMs being just front- ends to external solvers. This is a deliberate decision–as this allows the LLM to guess/generate candidates to satisfy the critics, as against dealing with the expressiveness and search complexity issues of the solvers. The critics/verifiers also are also more naturally composable than solvers/planners. As we shall see, we do allow for constructive critics which can be based on solvers, and provide suggestions on specific ways of extending/modifying the candidate plans."
            ]
        },
        {
            "claim": "We will show how the modelsi driving the external verifiers themselves can be ac- quired with the help of LLMs. ",
            "evidences": [
                "Design Choices: Before going into the details about the framework and its various modules, it is worth noting some design decisions underlying the proposed architecture. We start by noting that the LLM-Modulo architecture is a “Generate-Test” one that involves LLMs interacting with the external critics/verifiers rather than a LLMs being just front- ends to external solvers. This is a deliberate decision–as this allows the LLM to guess/generate candidates to satisfy the critics, as against dealing with the expressiveness and search complexity issues of the solvers. The critics/verifiers also are also more naturally composable than solvers/planners. As we shall see, we do allow for constructive critics which can be based on solvers, and provide suggestions on specific ways of extending/modifying the candidate plans.",
                "Secondly, the framework explicitly recognizes that the LLMs can generate approximate ideas not just about plan candidates, but domain models, problem reduction strate- gies, and refinements to the problem specification. The framework also recognizes that LLMs are good at for- mat/syntax changes. Accordingly, the framework lever- ages all these abilities of LLMs, letting them play multiple roles in planning. Finally, the architecture carefully circum- scribes the human’s role–domain experts interact with the LLM to tease out the models used by (some of) the critics, while end users take part in refining any incomplete prob-",
                "3.4. Summary of LLM Roles in LLM-Modulo It is worth summarizing the multiple roles the LLM plays in the LLM-Modulo architecture. The most prominent, of course, is its role in “guessing” the candidate plans (step 2 in Figure 3) in response to problem specification and iterative back prompting from the bank of critics (Step 5). Second, the LLM plays a role in converting the guessed plan can- didate into specialized representations used by the various critics (e.g., the time-line view, the causal link view etc.). This role leverages the fact that LLMs are very good at for- mat conversion (c.f. (Olmo et al., 2021)). Third, the LLM plays a role in helping the end user flesh out the incomplete problem specification to begin with (Step 1 in Figure 3). Finally, the LLM plays a role in helping the domain expert tease out and refine the domain models used by the various model-based critics (Guan et al., 2023; Kwon et al., 2022), or help “implement” procedural critics (such as those check- ing syntactic constraints). As a broad approximate source of knowledge, the LLM can also help enumerate the list of potential critics needed to validate the candidate plans (once again with a human in the loop)."
            ]
        },
        {
            "claim": "We will also argue that rather than simply pipelining LLMs and sym- bolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and sym- bolic components, extending the scope of model- based planning/reasoning regimes towards more flexible knowledge, problem and preference spec- ifications.",
            "evidences": [
                "4. Two Case Studies of LLM-Modulo We have applied the LLM-Modulo framework to classical planning domains (as reported in (Valmeekam et al., 2023c)) and to a recent travel planning benchmark (as reported in (Gundawar et al., 2024)). In the former case, the results (presented in Section 5.2 and Table 4 of (Valmeekam et al., 2023c)) show that with back prompting from VAL (Howey et al., 2004) acting as the external verifier and critic, LLM performance in Blocks World improves to 82% within 15 back prompting rounds, while in Logistics, it improves to 70%. LLM-Modulo doesn’t help as much in an obfuscated version of blocks world called Mystery BW, reaching about 10% accuracy. This should be expected because the LLMs have difficulty generating plausible candidate plans for this domain (note that even here, if a plan is returned, it must have passed muster with VAL, and is thus guaranteed correct by its model).",
                "For the travel planning case study, we used a benchmark proposed in (Xie et al., 2024), which involves a rich mix of travel constraints presented in flexible natural language form. Our preliminary results on adapting LLM-Modulo framework to this benchmark are reported in (Gundawar et al., 2024). The benchmark’s authors test LLMs across a variety of prompt engineering techniques including Chain of Thought and ReAct, reporting that–on GPT-3.5-Turbo–the current best strategies only manage a startlingly low 0.7% performance rate! We adapted the LLM-Modulo framework to this benchmark by operationalizing their hard constraints (such as the budget constraint set by the user) or common- sense constraints (such as suggesting diverse attractions to visit) as critics as shown in Figure 4. Our preliminary re- sults show (see Figure 5; additional results in (Gundawar et al., 2024)) that LLM-Modulo based agentification with automated critics in the loop significantly improves the per- formance (6x of baselines) even with a limit of 10 back prompting cycles, and weaker models such as GPT-3.5-i turbo. Furthermore, we also find that LLMs can success- fully implement functions corresponding to hard critics and several common-sense critics. Finally, LLMs reliably play the role of reformatter as well, converting free form travel plans into structured plans parseable by the critics for back- prompts or plan evaluation. One interesting observation about this domain is that we were able to use the LLM itself to enumerate the type of critics needed to validate the plan (with light human supervision)."
            ]
        }
    ]
}