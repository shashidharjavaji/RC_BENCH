[
    {
        "claim_id": 1,
        "claim_text": "We have developed a new dataset, SelfAware, that comprises a diverse range of commonly posed unanswerable questions.",
        "evidence_text": "To conduct a more comprehensive evaluation of the model’s self-knowledge, we constructed a dataset that includes a larger number and more diverse types of unanswerable questions than KnowUnknowns dataset (Srivastava et al., 2022). To facilitate this, we collected a corpus of 2,858 unanswerable questions, sourced from online platforms like Quora and HowStuffWorks. These questions were meticulously evaluated by three seasoned annotation analysts, each operating independently. The analysts were permitted to leverage external resources, such as search engines. To ensure the validity of our dataset, we retained only the questions that all three analysts concurred were unanswerable. This rigorous process yielded a finalized collection of 1,032 unanswerable questions.",
        "justification_conclusion": "The authors give the details about how the dataset is constructed and the details."
    },
    {
        "claim_id": 2,
        "claim_text": "We propose an innovative evaluation technique based on text similarity to quantify the degree of uncertainty inherent in model outputs.",
        "evidence_text": "In order to achieve this, we define a similarity function, fsim, to compute the similarity, S, between a given sentence, t, and a collection of reference sentences, U = {u1, u2, . . . , un}, endowed with uncertain meanings.  Si = fsim(t, ui). (1)  Whenever any Si surpasses a pre-determined threshold T , we perceive the text t as encompassing uncertain meanings, thereby eliminating the need for manual evaluation of the response. Given the substantial disparity in the volume of answerable and unanswerable questions in SelfAware, we adopt the F1 score as a measure of LLMs’ self-knowledge. Our focus rests on identifying unanswerable questions, hence we designate them as positive cases and categorize answerable questions as negative cases.",
        "justification_conclusion": "The authors give a similarity based method to automatically evaluate whether the model's response convey uncertain semantic."
    },
    {
        "claim_id": 3,
        "claim_text": "Through our detailed analysis of 20 LLMs, benchmarked against human self-knowledge, we identified a significant disparity between the most advanced LLMs and humans.",
        "evidence_text": "Model Size. Figure 2 illustrates the correlation between model size and self-knowledge across various LLMs. It is noteworthy that across all three input forms, an augmentation in model parameter size is associated with an elevation in the F1 Score, with the most conspicuous enhancement manifesting in the ICL input form. Therefore, our analysis indicates that an LLM’s self-knowledge tends to enhance with increasing model size, a trend consistent with the scaling law. Compared with Human. Figure 3 reveals that, without supplementary samples, GPT-4 currently performs best among the tested models, achieving an impressive F1 score of 75.47%. However, a noticeable gap becomes evident when comparing this performance to the human benchmark of 84.93%. This underscores the considerable potential that remains for enhancing the self-knowledge level of LLMs.",
        "justification_conclusion": "The authors show that the model's self-knowledge improves with model size, but there is still a gap between the model and human performance."
    }
]