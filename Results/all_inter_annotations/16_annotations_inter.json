[
    {
        "claim_id": 1,
        "claim_text": "Achieves human-level performance on reward design across a diverse suite of 29 open-sourced RLenvironments that include 10 distinct robot morphologies, including quadruped, quadcopter, biped, manipulator, as well as several dexterous hands",
        "evidence_text": [
            "Notably, EUREKA exceeds or performs on par to human level on all Isaac tasks and 15 out of 20 tasks on Dexterity (see App. F for a per-task breakdown)."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 2,
        "claim_text": "Solves dexterous manipulation tasks that were previously not feasible by manual reward engineering. We consider pen spinning, in which a five-finger hand needs to rapidly rotate a pen in pre-defined spinning configurations for as many cycles as possible. Combining EUREKA with curriculum learning, we demonstrate for the first time rapid pen spinning maneuvers on a simulated anthropomorphic Shadow Hand.",
        "evidence_text": [
            "Eureka fine-tuning quickly adapts the policy to successfully spin the pen for many cycles in a row; see project website for videos. In contrast, neither pre-trained or learning-from-scratch policies can complete even a single cycle of pen spinning."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 3,
        "claim_text": "Enables a new gradient-free in-context learning approach to reinforcement learning from human feedback (RLHF) that cangenerate more performant and human-aligned reward functions based on various forms of human inputs without model updating. We demonstrate that EUREKA can readily benefit from and improve upon existing human reward functions.",
        "evidence_text": [
            "As shown, regardless of the quality of the human rewards, EUREKA improves and benefits from human rewards as EUREKA (Human Init.) is uniformly better than both EUREKA and Hu- man on all tasks [shown in Figure 8]."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 4,
        "claim_text": "EUREKA rewards consistently improve over iterations via evolutionary search.",
        "evidence_text": [
            "As seen [in Fig. 5], on both benchmarks, EUREKA rewards steadily improve and eventually surpass human rewards in performance despite sub-par initial performances."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 5,
        "claim_text": "EUREKA generates novel reward functions that differ significantly from human-engineered ones.",
        "evidence_text": [
             "As shown [in Figure 6], EUREKA mostly generates weakly correlated reward func- tions that outperform the human ones."
        ],
        "justification_conclusion": "True"
    }

]