[
    {
        "claim_id": 1,
        "claim_text": "To investigate the existence of localized knowledge regions, we construct two multi-choice QA datasets encompassing various domains and languages.",
        "evidence_text": [
            "Dataset Construction We construct two datasets to locate knowledge neurons that cover two different categories: sub- ject domains and languages. Domain Dataset is derived from MMLU (Hendrycks et al. 2020)... Language Dataset is adapted from Multilingual LAMA (Kassner, Dufter, and Sch√ºtze 2021)..."
        ],
        "justification_conclusion": "True"
    },

    {
        "claim_id": 2,
        "claim_text": "we observed that common neurons are concentrated in the top layer, predominantly expressing frequently used tokens.",
        "evidence_text": [
            "We also visualize their locations within Llama-2-7B and we observe that they tend to appear at the top layer (as shown in Figure A2 in the SM)."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 3,
        "claim_text": "The QRNCA method significantly outperforms baseline methods (Random Neuron, Activation, Knowledge Neuron) in identifying impactful neurons.",
        "evidence_text": [
            "Our QRNCA method consistently outperforms other baselines, evidenced by its higher PCR. For instance, our method achieves a boosting ratio of 41.2 on the language dataset, the highest among the baselines."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 4,
        "claim_text": "QR neurons for specific domains are predominantly located in the middle layers of Llama-2-7B, while common neurons are concentrated in the top layer.",
        "evidence_text": [
            "Regarding layer distribution, the QR neurons are predom- inantly located in the middle layers (15-18) and the top lay- ers (around 30), as depicted in Figure 2b... [Common neurons] tend to appear at the top layer (as shown in Figure A2 in the SM)."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 5,
        "claim_text": "Identifying QR neurons shows potential for knowledge editing, as modifying these neurons can successfully flip model predictions.",
        "evidence_text": [
            "Our observations indicate that QRNCA achieves higher success rates [in flipping predictions from incorrect to correct or vice versa] than other baselines."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 6,
        "claim_text": "Neuron activation patterns can potentially predict model answer correctness for domain-specific questions.",
        "evidence_text": [
            "We observe that the accuracy of the neuron-based predictions is very close to the accuracy of the prompt-based method of using the entire model..."
        ],
        "justification_conclusion": "True"
    }
]