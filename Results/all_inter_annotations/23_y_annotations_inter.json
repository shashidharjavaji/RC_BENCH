[
    {
        "claim_id": 1,
        "claim_text": "presenting the first comprehensive MLLM Evaluation benchmark MME1. It measures both perception and cognition abilities on a total of 14 subtasks.",
        "evidence_text": [
            "MME covers the examination of perception and cognition abilities. Apart from OCR, the perception includes the recognition of coarse-grained and fine-grained ob- jects... The cog- nition includes commonsense reasoning, numerical cal- culation, text translation, and code reasoning. The total number of subtasks is up to 14, as shown in Fig. 1."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 2,
        "claim_text": "Benefitting from our instruction design “please answer yes or no”, we can easily perform quantitative statistics based on the “yes” or “no” output of MLLMs, which is accurate and objective.",
        "evidence_text": [
            "Since the output of the model is limited to two types (\"yes\" or \"no\"), it is convenient to measure the metrics of accuracy and accuracy+."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 3,
        "claim_text": "MME evaluates 30 advanced MLLMs, revealing significant discrepancies in performance and highlighting areas for optimization.",
        "evidence_text": [
             "As dis- played in Fig. 2 that consists of 2 overall leaderboards (perception and cognition) and 14 individual leaderboards, these MLLMs show clear discrepancies in our MME eval- uation benchmark."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 4,
        "claim_text": "Many current MLLMs exhibit poor instruction following, even with simple 'yes/no' formats.",
        "evidence_text": [
            "The first problem is not follow- ing instructions. Although we have adopted a very con- cise instruction design, there are MLLMs that answer freely rather than following instructions."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 5,
        "claim_text": "MLLMs often exhibit object hallucination, particularly when prompted with descriptions of non-existent objects.",
        "evidence_text": [
            "The fourth problem is object hallucination follow- ing instructions, which is exemplified in the fourth row of Fig. 4. When the instruction contains descriptions of an object that does not appear in the image, the MLLM will imagine that the object exists and ultimately gives a \"yes\" answer."
        ],
        "justification_conclusion": "True"
    }
]