[
    {
        "claim_id": 1,
        "claim_text": "We have developed a new dataset, SelfAware, that comprises a diverse range of commonly posed unanswerable questions.",
        "evidence_text": [
            "This dataset com- prises 1,032 unanswerable questions, which are dis- tributed across five distinct categories, along with an additional 2,337 questions that are classified as answerable."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 2,
        "claim_text": "We propose an innovative evaluation technique based on text similarity to quantify the degree of uncertainty inherent in model outputs.",
        "evidence_text": [
             "In order to achieve this, we define a similarity func- tion, $f_{sim}$ to compute the similarity, S, between a given sentence, t, and a collection of reference sentences, $U=\\{u_{1},u_{2},...,u_{n}\\}$, endowed with uncertain meanings... Whenever any $\\mathcal{S}_{i}$ surpasses a pre-determined threshold T, we perceive the text t as encompass- ing uncertain meanings, thereby eliminating the need for manual evaluation of the response."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 3,
        "claim_text": "Through our detailed analysis of 20 LLMs, benchmarked against human self-knowledge, we identified a significant disparity between the most advanced LLMs and humans.",
        "evidence_text": [
            "Figure 3 reveals that, without supplementary samples, GPT-4 currently performs best among the tested models, achieving an impressive F1 score of 75.47%. However, a no- ticeable gap becomes evident when comparing this performance to the human benchmark of 84.93%."
        ],
        "justification_conclusion": "True"
    },
    {
        "claim_id": 4,
        "claim_text": "Larger models generally exhibit better self-knowledge (higher F1 score on SelfAware).",
        "evidence_text": [
            "It is noteworthy that across all three input forms, an augmentation in model parameter size is associated with an elevation in the F1 Score, with the most conspicuous enhancement manifest- ing in the ICL input form."
        ],
        "justification_conclusion": "True"
    },

    {
        "claim_id": 5,
        "claim_text": "In-context learning (ICL) also improves LLM self-knowledge, especially for base models.",
        "evidence_text": [
             "Specifically, ICL input form, providing richer contextual information, contributes to a sig- nificant enhancement in models' self-knowledge. This impact is particularly noticeable in the davinci model, where ICL facilitates a 27.96% improve- ment over the direct [input form]."
        ],
        "justification_conclusion": "True"
    }
]