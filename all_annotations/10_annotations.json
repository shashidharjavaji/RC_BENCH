[
    {
        "claim_id": 1,
        "claim_text": "In this paper, we demonstrate that, with some extensions to improve coverage of the verbalizer tokens, the performance gains of retrieval-augmented LMs generalize well to a wide range of downstream tasks.",
        "evidence_text": "Results for zero-shot prediction are in Table 2. kNN-Prompt outperforms all baselines in all tasks, improving over the base LM by 13.4% on average. The gains are particularly pronounced for MR and RT (sentiment analysis on movie reviews), Yahoo (topic classification).",
        "justification_conclusion": "Applying the method demonstrates a good performance improvement in all tasks."
    },
    {
        "claim_id": 2,
        "claim_text": "We find that applying the technique na√Øvely produces only marginal improvements",
        "evidence_text": "Interestingly, the kNN-LM alone yields a fairly small improvement over the base LM (about 0.4% on average). This suggests that the fuzzy verbalizer and PMI calibration methods may help kNNPrompt better leverage the information in the knearest neighbors distribution.",
        "justification_conclusion": "Applying the naive method only produces marginal improvements."
    },
    {
        "claim_id": 3,
        "claim_text": "We also show that kNN-Prompt can be used to adapt LMs to new domains and tasks with no further training.",
        "evidence_text": "As shown in Table 4, kNN-Prompt performs comparably with DAPT. Specifically, kNN-Prompt slightly outperforms DAPT on CR and MR. These results indicate that kNN-Prompt is an effective method for domain adaptation. Critically, unlike DAPT, kNN-Prompt does not require further training, which is more practical and efficient for adapting very large LMs.",
        "justification_conclusion": "The method can be applied to new domains and tasks without further training."
    }
]