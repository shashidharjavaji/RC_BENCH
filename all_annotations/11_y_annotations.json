[
    {
        "claim_id": 1,
        "claim_text": "We propose a new audio-visual video parsing baseline: Multi-modal Grouping Network (MGN) that enables explicit grouping in a multi-modal network to learn compact and discriminative audio and visual embeddings.",
        "evidence_text": "Our key motivation is to learn compact and discriminative audio and visual representations by explicit multi-modal grouping for mitigating the modality and temporal uncertainties in the weakly-supervised audio-visual video parsing problem.",
        "justification_conclusion": "True. This claim introduces MGN and its explicit grouping design, supported by qualitative and quantitative results showing improvements in audio-visual video parsing."
    },
    {
        "claim_id": 2,
        "claim_text": "The proposed class-aware unimodal grouping achieves significant gains in segment-level predictions for visual events.",
        "evidence_text": "Adding CUG to the vanilla baseline achieves significant gains of 2.4 Visual, indicating the effectiveness of grouping class-aware semantics in predicting snippet-wise categories for visual events.",
        "justification_conclusion": "True. The result shows that class-aware unimodal grouping (CUG) contributes significantly to the model's accuracy in segment-level predictions."
    },
    {
        "claim_id": 3,
        "claim_text": "Our MGN achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
        "evidence_text": "The proposed MGN achieves the overall best results against previous network baselines in terms of most metrics, including significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
        "justification_conclusion": "True. This result validates the superiority of MGN across various evaluation metrics in segment-level parsing."
    }
]
