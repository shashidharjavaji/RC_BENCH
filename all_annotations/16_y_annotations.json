[
    {
        "claim_id": 1,
        "claim_text": "Our research empirically evaluates the performance of LLMs in analyzing XBRL reports and identifies crucial limitations in their current capabilities.",
        "evidence_text": "LLMs demonstrate moderate proficiency in financial terminology but encounter difficulties with specific XBRL report interpretations. Performance in this category is relatively better, yet the accuracy rates still necessitate improvement. Even the best-performing model, Qwen2-7B, only achieves an 81% score in XBRL Term and a mere 51% in Domain Query to XBRL Reports. The performances in this category are particularly concerning. Even the best-performing model, Llama3-8B, only achieves 38% accuracy in Financial Formula Calculation and 24% in Numeric Query to XBRL Reports task. This demonstrates a severe limitation in LLMs’ ability to handle mathematical data and perform financial calculations.",
        "justification_conclusion": "True. The evidence supports the claim that LLMs have moderate proficiency in financial terminology but encounter difficulties with specific XBRL report interpretations. The evidence also supports the claim that LLMs have limitations in their ability to handle mathematical data and perform financial calculations."
    },
    {
        "claim_id": 2,
        "claim_text": "Implementation of enhancing methods: To mitigate the identified shortcomings, we propose and implement specific enhancements. These include integrating RAG technology to bolster LLMs with specialized financial knowledge and incorporating a dedicated financial calculator to improve accuracy in complex numeric computations",
        "evidence_text": "For Financial Math, Llama3-8B achieves an accuracy of 63%, followed by Qwen2-7B (58%) and Gemma2-9B (52%), showing 25-35 percentage point improvements. This demonstrates the calculator’s effectiveness in enhancing complex financial calculations. The Numeric Query to XBRL Reports task exhibits more modest: Llama3-8B (28%), Qwen2-7B (21%), and Gemma2-9B (19%), representing improvement of 2 to 4 percentage points.",
        "justification_conclusion": "True. The evidence supports the claim that the implementation of a dedicated financial calculator improves accuracy in complex numeric computations. The evidence also supports the claim that the calculator enhances complex financial calculations."
    },
    {
        "claim_id": 3,
        "claim_text": "Improvement in analysis reliability: Through extensive experiments, we demonstrate substantial improvements. Our enhancements lead to FactScore increases of up to 17% in the XBRL domain query task and up to 42% in the numeric type query task, respectively, effectively boosting the trustworthiness and accuracy of our XBRL-agent.",
        "evidence_text": "mplementing a retriever for domain-related queries improves the performance of all three tested LLMs, as shown in the left two columns of Figure 6. For XBRL Term, Qwen2-7B achieves 89% accuracy, followed by Llama3-8B (84%) and Gemma2-9B (83%). These results represent the retriever’s effectiveness in enhancing comprehension of XBRL terminology. The more complex Domain Query to XBRL Report task exhibits substantial improvements: Qwen2-7B (65%), Llama3-8B (64%), and Gemma2-9B (59%), representing increases of 14 to 17 percentage points. This highlights the retriever’s specific efficacy in handling complex XBRL report queries.",
        "justification_conclusion": "True. The evidence supports the claim that implementing a retriever for domain-related queries improves the performance of LLMs in the XBRL domain query task. The evidence also supports the claim that the enhancements lead to FactScore increases in the XBRL domain query task and the numeric type query task, effectively boosting the trustworthiness and accuracy of the XBRL-agent."
    }
]

