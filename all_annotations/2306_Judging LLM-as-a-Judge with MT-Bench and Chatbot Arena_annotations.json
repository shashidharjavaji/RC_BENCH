[
    {
        "Claim_id": 1,
        "Claim_text": "We first create the FEEDBACK COLLECTION, a new dataset that is crafted to encapsulate diverse and fine-grained user assessment score rubric that represent realistic user demands.",
        "Evidence_text": "We thus introduce the FEEDBACK COLLECTION, a new dataset for the sole purpose of fine-tuning an open-sourced evaluator LLM. Our 4 main considerations during dataset construction are: (1) including as many reference materials (i.e. reference answer, and scoring rubric) as possible, (2) maintaining auniform length among the reference answers for each score (1 to 5) to prevent undesired length bias, (3) maintaining a uniform score distribution to prevent undesired decision bias, and (4) limiting the scope of our instructions and responses to realistic situations where a user is interacting with a LLM.",
        "Justification_Conclusion": "True. The authors provide a detailed introduction about the dataset."
    },
    {
        "Claim_id": 2,
        "Claim_text": "Also, to best of our knowledge, we are first to explore the importance of including various reference materials– particularly the ‘Reference Answers’ – to effectively induce fine-grained evaluation capability.",
        "Evidence_text": "(4) the augmentation of the remaining components in the training instances (i.e. responses including the reference answers, feedback, and scores).",
        "Justification_Conclusion": "False. The authors do not share to much details in the main body of the paper."
    },
    {
        "Claim_id": 3,
        "Claim_text": "Also, when measuring the Pearson correlation with GPT-4 evaluation across 1222 customized score rubrics across 4 test sets (MT Bench, Vicuna Bench, Feedback Bench, Flask Eval), PROMETHEUS showed higher correlation compared to GPT-3.5-Turbo and Llama-2-Chat 70B. Lastly, when testing on 2 unseen human preference datasets (MT Bench Human Judgments, HHH Alignment), PROMETHEUS outperforms two state-of-the-art reward models and GPT-3.5-Turbo, highlighting its potential as an universal reward model.",
        "Evidence_text": "When comparing Pearson correlation with GPT-4, PROMETHEUS shows the highest correlation even outperforming GPT-3.5-Turbo. Lastly, we show that PROMETHEUS shows superior performance on human preference datasets, indicating its possibility as an universal reward model.",
        "Justification_Conclusion": "True. The authors provide related experimental results and analysis to support this claim. "
    }
]
