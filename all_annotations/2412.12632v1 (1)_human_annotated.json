{
    "annotations": [
        {
            "claim": "Ac- cordingly, we propose an automated CoE dis- crimination approach and explore LLMs’ pref- erences from their effectiveness, faithfulness and robustness, as well as CoE’s usability in a naive Retrieval-Augmented Generation (RAG)i case.",
            "evidences": [
                "3.1 CoE Characterization Drawing from the law of criminal procedure, ju- dicial decisions in cases require the formation of a Chain of Evidence (CoE) through evidence col- lection (Edmond and Roach, 2011; Murphy, 2013). Such evidence must demonstrate two properties: relevance (pertaining to the case) and interconnec- tivity (evidence mutually supporting each other). We analogize judicial decisions to the scenario in which LLMs identify correct answers from external knowledge in response to input questions.",
                "5 Effectiveness Assessment Starting from the constructed CoE and Non-CoE samples, we inject additional irrelevant pieces into their contexts and investigate whether CoE can better help LLMs generate correct answers under external information rich with irrelevant noise.",
                "g pp g Finding-1: External knowledge equipped with CoE can help LLMs generate correct answers more effectively than Non-CoE. Generally, ex- perimental results show that CoE achieves an av- erage accuracy of 92.0% across five LLMs and two datasets, outperforming Non-CoE variants SenP and WordP by 22.5% and 16.3%, respec- tively. Moreover, compared to CoE, we conducted Mann-Whitney tests (Mann and Whitney, 1947) on all experiment groups of Non-CoE. The results of the hypothesis test show that the improvement in",
                "Finding-2: LLMs exhibit greater resistance if CoE exists in external knowledge as the propor- tion of irrelevant information increases. As the proportion of irrelevant increases from 0% to 75%, the ACC of LLMs with CoE only decreases by 1.8%, while the ACC decreases by 12.9% and 9.0% under the Non-CoE variants SenP and WordP, respec- tively. In the Non-CoE, WordP demonstrates bet- ter performance over SenP, exhibiting both higher ACC and greater resistance against increasing irrel- evant information. The enhanced performance of WordP, which contains richer information content than SenP, indicates that the information density of external knowledge positively correlates with LLMs’ QA capabilities. Furthermore, while CoE and WordP possess comparable information con- tent, LLMs achieve better performance with CoE, highlighting the importance of forming CoE.i",
                "6 Faithfulness Assessment Based on the effectiveness assessment, we investi- gate a more challenging scenario, where the CoE contains factual errors, to determine whether LLMs can still exhibit a certain degree of faithfulness",
                "7 Robustness Assessment We make the knowledge conflicts by injecting the misinformation in the context of CoE and Non-CoE. Robustness explores whether CoE can help LLMs more effectively resist the conflict and produce the correct answers."
            ]
        },
        {
            "claim": "The evaluation on five LLMs reveals that CoE enhances LLMs through more accurate generation, stronger answer faithfulness, bet- ter robustness against knowledge conflict, and improved performance in a popular RAG case.",
            "evidences": [
                "g Finding-5: LLMs augmented with CoE ex- hibit higher robustness against knowledge con- flict than Non-CoE. The results show that under CoE, the average ACC of LLMs reaches 84.1%, which is 21.4% and 15.3% higher than the SenP and WordP types under Non-CoE respectively. Besides, as the proportion of misinformation increases from 0% to 75%, LLMs’ ACC under CoE shows 6.2% and 6.3% smaller decreases compared to the reduc- tions observed in SenP and WordP under Non-CoE.",
                "Finding-3: LLMs exhibit significant faithful- ness to the answer supported by CoE although it contains factual errors. The results show that under CoE, the average FR reaches 85.4%, which is 20.6% and 16.2% higher than the SenP and WordP types under Non-CoE respectively. More- over, Mann-Whitney tests confirmed statistically significant improvements of CoE over all Non-CoE groups (p < 0.05).",
                "Finding-7: For the subject case, CoE-guided re- trieval could improve the LLMs’ accuracy in the naive framework. Table 5 demonstrates the im- pact of naive RAG and RAG+ScopeCoE on LLMs’ accuracy. The results show that RAG+ScopeCoE achieves average ACC of 77.8% and 81.6% on Hot- potQA and 2WikiMultihopQA respectively, outper- forming RAG by 10.4% and 28.7%. Moreover, we also observe that ScopeCoE can help LLMs generate more accurate outputs with fewer knowledge pieces (4.6 for HotpotQA and 4.8 for 2WikiMultihopQA) compared to the naive framework (5 pieces). It implies that ScopeCoE can make LLMs more efficient in knowledge utiliza- tion, leading to improved performance and reduced dependency on large amounts of external data."
            ]
        },
        {
            "claim": "p Effectiveness where we investigate whether LLMs perform better when external knowl- edge contains CoE compared to the situation where it contains relevant information but does not constitute a CoE.",
            "evidences": [
                "to Non-CoE. As irrelevant information in external knowledge increases from 0% to 75%, the FR of LLMs with CoE decreases by 3.6%, while the FR drops by 9.7% and 7.9% under Non-CoE variants SenP and WordP, respectively. Beyond the main findings, we also discovered that LLMs demonstrate a 6.6% reduction in FR when processing CoE with factual errors, compared to those with correct answers (as indicated by ACC in Table 2). This discrepancy could be attributed to the LLM’s inherent parametric knowledge containing accurate information, facilitating self-correction of certain factual errors.",
                "Table 3: LLMs’ Following Rate (FR) on CoE and Non- CoE. HotpotQA 2WikiMultihopQA Irrelevent Model Proportion CoE Non-CoE CoE Non-CoE SenP WordP SenP WordP 0 86.1% 75.6%∗83.1%∗ 85.0% 58.5%∗57.4%∗ 0.25 85.8% 76.0%∗79.1%∗ 86.5% 53.8%∗52.4%∗ GPT-3.5 0.5 84.7% 72.2%∗77.8%∗ 84.2% 50.0%∗48.8%∗ 0.75 78.4% 72.0%∗73.7%∗ 83.3% 45.2%∗44.9%∗ 0 86.5% 52.2%∗59.0%∗ 85.4% 68.8%∗76.2%∗ 0.25 85.5% 50.5%∗58.9%∗ 87.2% 67.0%∗73.2%∗ GPT-4 0.5 84.0% 46.8%∗52.7%∗ 90.6% 65.2%∗76.8%∗ 0.75 78.2% 43.2%∗50.5%∗ 92.7% 62.3%∗75.1%∗ 0 78.2% 76.9%∗72.9%∗ 91.5% 89.8%∗88.6%∗ 0.25 77.1% 74.1%∗67.3%∗ 89.8% 87.5%∗86.3%∗ Llama2-13B 0.5 71.6% 70.0%∗67.5%∗ 89.1% 86.8%∗85.1%∗ 0.75 69.1% 64.5%∗64.8%∗ 84.1% 81.6%∗82.1%∗ 0 82.8% 76.9%∗72.8%∗ 89.7% 77.1%∗72.1%∗ 0.25 81.6% 75.1%∗71.9%∗ 89.5% 72.1%∗70.4%∗ Llama3-70B 0.5 78.0% 71.7%∗68.0%∗ 88.9% 69.4%∗66.5%∗ 0.75 78.2% 62.9%∗64.1%∗ 89.8% 51.4%∗53.7%∗ 0 90.6% 68.9%∗79.1%∗ 93.7% 43.5%∗65.8%∗ 0.25 87.7% 67.3%∗80.0%∗ 93.6% 47.2%∗67.3%∗ Qwen2.5-32B 0.5 86.3% 64.1%∗76.5%∗ 93.1% 47.0%∗68.6%∗ 0.75 85.8% 62.9%∗74.2%∗ 94.0% 46.5%∗65.6%∗ * indicates statistical significance compared to CoE (p < 0.05)"
            ]
        },
        {
            "claim": "Robustness where we explore whether CoE can help improve the resistance of LLM to ex- ternal knowledge occupied by misinformation which results in the knowledge conflicting.",
            "evidences": [
                "We also discovered that as misinformation in- creases, LLMs with weaker reasoning capabilities tend to favor frequently appearing knowledge in external knowledge, while LLMs with stronger rea- soning abilities adhere more to knowledge from CoE. With the proportion of misinformation in- creasing from 0% to 75%, less capable LLMs like GPT-3.5 and LLama2-13B are more likely to be misled by increasing misinformation, leading them to select answers from misinformation and resulting in significant ACC drops (with average ACC de- creasing by 34.5%), whereas more powerful LLMs such as GPT-4, Llama3-70B, and Qwen2.5-32B consistently adhere to answers within CoE, result- ing in slight ACC decreases (with average ACC decreasing by 7.1%).",
                "Table 4: LLMs’ Accuracy (ACC) with CoE and Non- CoE surrounded by misinformation. HotpotQA 2WikiMultihopQA Model Misinformation Proportion CoE Non-CoE CoE Non-CoE SenP WordP SenP WordP 0 91.9% 77.9%∗79.1%∗ 97.4% 74.1%∗83.5%∗ 0.25 81.8% 62.5%∗64.0%∗ 85.3% 40.6%∗63.8%∗ GPT-3.5 0.5 82.0% 63.0%∗65.7%∗ 65.5% 43.4%∗52.3%∗ 0.75 75.7% 58.9%∗60.8%∗ 55.5% 29.8%∗30.4%∗ 0 93.5% 83.4%∗86.4%∗ 93.7% 67.7%∗79.4%∗ 0.25 95.3% 89.7%∗89.9%∗ 96.5% 86.0%∗91.9%∗ GPT-4 0.5 90.7% 84.6%∗87.4%∗ 90.7% 78.3%∗84.2%∗ 0.75 86.6% 75.2%∗78.1%∗ 85.0% 60.7%∗69.4%∗ 0 89.9% 87.1%∗88.8%∗ 96.5% 95.3%∗93.3%∗ 0.25 74.8% 70.6%∗67.6%∗ 78.5% 73.9%∗67.7%∗ Llama2-13B 0.5 63.5% 59.2%∗56.5%∗ 57.9% 52.0%∗52.7%∗ 0.75 57.0% 42.1%∗44.9%∗ 49.7% 34.9%∗41.8%∗ 0 92.5% 76.8%∗74.5%∗ 95.7% 79.5%∗73.3%∗ 0.25 87.4% 71.3%∗67.3%∗ 93.1% 72.6%∗61.2%∗ Llama3-70B 0.5 82.1% 64.8%∗62.5%∗ 88.3% 64.1%∗55.8%∗ 0.75 84.0% 59.7%∗57.6%∗ 85.6% 56.5%∗52.4%∗ 0 87.8% 71.3%∗75.7%∗ 90.7% 53.1%∗67.0%∗ 0.25 95.1% 79.5%∗83.4%∗ 97.4% 63.5%∗75.4%∗ Qwen2.5-32B 0.5 88.5% 72.3%∗71.7%∗ 92.1% 40.6%∗64.5%∗ 0.75 83.0% 66.0%∗67.3%∗ 86.9% 39.6%∗55.0%∗ * indicates statistical significance compared to CoE (p < 0.05)"
            ]
        }
    ]
}