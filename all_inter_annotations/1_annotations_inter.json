[
    {
      "claim_id": 1,
      "claim_text": "We evaluate four popular NLI models, including BERT, a state-of-the-art model (Devlin et al., 2019), on the HANS dataset. All models performed substantially below chance on this dataset, barely exceeding 0% accuracy in most cases.",
      "evidence_text": [
        "On the HANS dataset, all models almost always assigned the correct label in the cases where the label is entailment, i.e., where the correct answer is in line with the hypothesized heuristics. However, they all performed poorly—with accuracies less than 10% in most cases, when chance is 50%—on the cases where the heuristics make incorrect predictions (Figure 1b)."
      ],
      "justification_conclusion": "True"
    },
    {
      "claim_id": 2,
      "claim_text": "we introduce the HANS dataset, an NLI evaluation set that tests specific hypotheses about invalid heuristics that NLI models are likely to learn",
      "evidence_text": [
        "We introduce a new evaluation set called HANS (Heuristic Analysis for NLI Systems), designed to diagnose the use of such fallible structural heuristics."
      ],
      "justification_conclusion": "True"
    },
    {
      "claim_id": 3,
      "claim_text": "we show that these shortcomings can be made less severe by augmenting a model’s training set with the types of examples present in HANS.",
      "evidence_text": [
        "In general, the models trained on the augmented MNLI performed very well on HANS (Figure 2)... these results do suggest that, to prevent a model from learning a heuristic, one viable approach is to use a training set that does not support this heuristic.",
        "The augmentation improved performance modestly for the long examples and dramatically for the short examples, suggesting that training with HANS-like examples has benefits that extend beyond HANS."
      ],
      "justification_conclusion": "True"
    }
  ]
  