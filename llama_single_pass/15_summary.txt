Claim 1:
Type: contribution
Statement: LLMs can reason effectively without prompting by altering the decoding process.
Location: Introduction
Exact Quote: Our study takes a novel approach by asking: Can LLMs reason effectively without prompting?

Evidence:
- Evidence Text: Alternative top-k tokens inspection unveiled inherent CoT paths.
  Strength: strong
  Location: Introduction
  Limitations: Limited to specific tasks and models
  Exact Quote: given a reasoning question, the LLM generates a wrong answer via the standard greedy decoding path, yet alternative top-k token inspection unveiled inherent CoT paths

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence supports the claim by demonstrating the existence of CoT paths in alternative decoding processes.
Key Limitations: Task and model specificity

--------------------------------------------------

Claim 2:
Type: methodology
Statement: CoT-decoding can reliably extract CoT-paths based on answer confidence.
Location: Section 2.2
Exact Quote: We propose CoT-decoding to select more reliable decoding paths, demonstrating significant improvements over greedy decoding across various reasoning benchmarks.

Evidence:
- Evidence Text: The model's confidence in its final answers increases when a CoT is present in its decoding path.
  Strength: strong
  Location: Section 2.2
  Limitations: Dependent on accurate answer span identification
  Exact Quote: the presence of a CoT path typically leads to a more confident decoding of the final answer, characterized by a significant probability disparity between the top and secondary tokens

- Evidence Text: Quantitative analysis on GSM8K (top-100) and Year Parity tasks
  Strength: moderate
  Location: Table 2
  Limitations: Limited to specific tasks and datasets
  Exact Quote: CoT-decoding (decode 10 paths, rank by model's answer confidence) **72.0%** **95.0%**

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence supports the claim by demonstrating the correlation between CoT presence and increased model confidence, as well as the effectiveness of CoT-decoding in improving reasoning performance.
Key Limitations: Answer span identification and task specificity

--------------------------------------------------

Claim 3:
Type: contribution
Statement: CoT-decoding effectively elicits reasoning across multiple language model families and scales.
Location: Section 3.1
Exact Quote: Across three language model families, PaLM-2, Mistral and Gemma, CoT-decoding effectively elicits model's reasoning, yielding consistent accuracy gains over both math and commonsense reasoning tasks.

Evidence:
- Evidence Text: Experimental results on GSM8K, Year Parity, and MultiArith tasks across PaLM-2, Mistral-7B, and Gemma-7B models
  Strength: strong
  Location: Figure 3 and Table 4
  Limitations: Limited to specific tasks and models
  Exact Quote: CoT-decoding effectively elicits reasoning across multiple language model families, with significant accuracy gains over three reasoning tasks

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence supports the claim by demonstrating the effectiveness of CoT-decoding across various language models and tasks.
Key Limitations: Task and model specificity

--------------------------------------------------

Claim 4:
Type: contribution
Statement: CoT-decoding partially closes the reasoning gap between pre-trained and instruction-tuned models without using any supervised data.
Location: Section 3.1
Exact Quote: Intriguingly, we observe that CoT-decoding enables a pre-trained model to achieve a similar performance of an instruction-tuned model

Evidence:
- Evidence Text: Comparison of CoT-decoding performance between pre-trained and instruction-tuned PaLM-2 Large models
  Strength: moderate
  Location: Figure 4
  Limitations: Limited to specific models and tasks
  Exact Quote: CoT-decoding achieves 63.2% accuracy on the pre-trained PaLM-2 Large model, close to the performance of the instruction-tuned model of the same scale at 67.8%

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence supports the claim by demonstrating the reduced performance gap between pre-trained and instruction-tuned models through CoT-decoding.
Key Limitations: Model and task specificity

--------------------------------------------------

