Claim 1:
Type: methodology
Statement: Natural language explanations of neurons can be rigorously evaluated using observational and intervention-based modes.
Location: Section 1: Introduction
Exact Quote: Rigorously Assessing Natural Language Explanations of Neurons

Evidence:
- Evidence Text: Development of two modes of evaluation for natural language explanations that claim individual neurons represent a concept in a text input.
  Strength: strong
  Location: Section 1: Introduction
  Limitations: Limited to the specific framework proposed
  Exact Quote: To help address this, we develop two modes of evaluation for natural language explanations that claim individual neurons represent a concept in a text input.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The proposed framework provides a systematic approach to evaluating natural language explanations of neurons.
Key Limitations: None mentioned

--------------------------------------------------

Claim 2:
Type: methodology
Statement: The observational mode evaluates whether a neuron activates on all and only input strings that refer to a concept picked out by the proposed explanation E.
Location: Section 3.1: Methods
Exact Quote: In the observational mode, we evaluate whether the neuron a activates on all and only input strings that refer to a concept picked out by the proposed explanation E.

Evidence:
- Evidence Text: Definition of EXPLAINM,Q(a, E) as the claim that, for every input q ∈ Q to model M containing neuron a, the activation a(q) > 0 iff q ∈ E.
  Strength: strong
  Location: Section 3.1: Methods
  Limitations: Assumes a finite set of strings for E
  Exact Quote: EXPLAINM,Q(a, E) is the claim that, for every input q ∈ Q to model M containing neuron a, the activation a(q) > 0 iff q ∈ E.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The definition provides a clear criterion for evaluating the observational mode.
Key Limitations: Assumption of a finite set for E

--------------------------------------------------

Claim 3:
Type: methodology
Statement: The intervention mode assesses whether the neuron a is a causal mediator of the concept denoted by E.
Location: Section 4.1: Methods
Exact Quote: The goal of intervention-based evaluation is to assess the claim that a neuron a is a causal mediator of the concept denoted by E.

Evidence:
- Evidence Text: Definition of CAUSALEXPLAINM,τ,T (a, E) as the claim that for all inputs b, s ∈ QE,T, we have τ(Mat←z(b)) = τ(M(s))
  Strength: strong
  Location: Section 4.1: Methods
  Limitations: Requires identifying a task that takes any string q ∈ E as part of the input and has an output behavior that depends on E
  Exact Quote: CAUSALEXPLAINM,τ,T (a, E) is the claim that for all inputs b, s ∈ QE,T, we have τ(Mat←z(b)) = τ(M(s))

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The definition provides a clear criterion for evaluating the intervention mode.
Key Limitations: Requirement of identifying a suitable task

--------------------------------------------------

Claim 4:
Type: result
Statement: GPT-4 generated explanations have low F1 scores in the observational mode and little to no causal efficacy in the intervention mode.
Location: Section 3.3: Results and Section 4.3: Results
Exact Quote: Results over 300 neuron explanations are shown in Table 1... GPT-4 generated explanations have similar causal effects as the random baseline on most tasks.

Evidence:
- Evidence Text: Experimental results showing low F1 scores (0.56) in the observational mode and low IIA scores in the intervention mode
  Strength: strong
  Location: Section 3.3: Results and Section 4.3: Results
  Limitations: Limited to the specific evaluation framework and dataset
  Exact Quote: Results over 300 neuron explanations are shown in Table 1... GPT-4 generated explanations have similar causal effects as the random baseline on most tasks.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The experimental results provide strong evidence for the claim.
Key Limitations: Limited to the specific evaluation framework and dataset

--------------------------------------------------

Claim 5:
Type: contribution
Statement: Natural language may not be the best medium for explaining large language models due to its vagueness, ambiguity, and context dependence.
Location: Section 5.1: Inherent Drawbacks to Natural Language Explanations
Exact Quote: Is natural language the best medium for explaining large language models?

Evidence:
- Evidence Text: Discussion on the limitations of natural language in providing clear explanations
  Strength: moderate
  Location: Section 5.1: Inherent Drawbacks to Natural Language Explanations
  Limitations: Based on general properties of natural language rather than empirical evidence
  Exact Quote: However, natural languages are characterized by vagueness, ambiguity, and context dependence.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The discussion highlights the potential drawbacks of using natural language for explanations.
Key Limitations: Lack of empirical evidence

--------------------------------------------------

