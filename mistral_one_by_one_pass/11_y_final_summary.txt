=== Paper Analysis Summary ===

Raw Claims:
 For example:
```json
{
    "claims": [
        {
            "claim_id": 1,
            "claim_text": "The audio-visual video parsing task aims to parse a video into modality- and category-aware temporal segments.",
            "location": "Abstract",
            "claim_type": "Method",
            "exact_quote": "The audio-visual video parsing task aims to parse a video into modality- and category-aware temporal segments."
        },
        {
            "claim_id": 2,
            "claim_text": "Previous work mainly focuses on weakly-supervised approaches, which learn from video-level event labels.",
            "location": "Abstract",
            "claim_type": "Method",
            "exact_quote": "Previous work mainly focuses on weakly-supervised approaches, which learn from video-level event labels."
        },
        {
            "claim_id": 3,
            "claim_text": "The proposed Multi-modal Grouping Network (MGN) achieves improving results against previous baselines on weakly-supervised audiovisual video parsing.",
            "location": "Abstract",
            "claim_type": "Result",
            "exact_quote": "The proposed Multi-modal Grouping Network (MGN) achieves improving results against previous baselines on weakly-supervised audiovisual video parsing."
        },
        {
            "claim_id": 4,
            "claim_text": "The proposed MGN is much more lightweight, using only 47.2% of the parameters of baselines (17 MB vs. 36 MB).",
            "location": "Abstract",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN is much more lightweight, using only 47.2% of the parameters of baselines (17 MB vs. 36 MB)."
        },
        {
            "claim_id": 5,
            "claim_text": "The audio-visual video parsing task aims to parse a video into temporal event segments and predict the audible, visible, or audio-visible event categories.",
            "location": "1 Introduction",
            "claim_type": "Method",
            "exact_quote": "The audio-visual video parsing task aims to parse a video into temporal event segments and predict the audible, visible, or audio-visible event categories."
        },
        {
            "claim_id": 6,
            "claim_text": "Existing approaches usually focus on learning to leverage the unimodal and cross-modal temporal contexts from weak supervisions.",
            "location": "1 Introduction",
            "claim_type": "Method",
            "exact_quote": "Existing approaches usually focus on learning to leverage the unimodal and cross-modal temporal contexts from weak supervisions."
        },
        {
            "claim_id": 7,
            "claim_text": "The key motivation is to learn compact and discriminative audio and visual representations by explicit multi-modal grouping for mitigating the modality and temporal uncertainties in the weakly-supervised audio-visual video parsing problem.",
            "location": "1 Introduction",
            "claim_type": "Method",
            "exact_quote": "The key motivation is to learn compact and discriminative audio and visual representations by explicit multi-modal grouping for mitigating the modality and temporal uncertainties in the weakly-supervised audio-visual video parsing problem."
        },
        {
            "claim_id": 8,
            "claim_text": "The proposed Multi-modal Grouping Network (MGN) enables explicit grouping in a multi-modal network to learn compact and discriminative audio and visual embeddings.",
            "location": "2 Related Work",
            "claim_type": "Contribution",
            "exact_quote": "The proposed Multi-modal Grouping Network (MGN) enables explicit grouping in a multi-modal network to learn compact and discriminative audio and visual embeddings."
        },
        {
            "claim_id": 9,
            "claim_text": "The proposed MGN introduces class-aware unimodal grouping and modality-aware cross-modal grouping modules to aggregate multi-modal temporal contexts.",
            "location": "2 Related Work",
            "claim_type": "Contribution",
            "exact_quote": "The proposed MGN introduces class-aware unimodal grouping and modality-aware cross-modal grouping modules to aggregate multi-modal temporal contexts."
        },
        {
            "claim_id": 10,
            "claim_text": "The experiments can demonstrate the superiority of our MGN over state-of-the-art AVVP approaches and its generalizability to contrastive learning and label refinement.",
            "location": "2 Related Work",
            "claim_type": "Contribution",
            "exact_quote": "The experiments can demonstrate the superiority of our MGN over state-of-the-art AVVP approaches and its generalizability to contrastive learning and label refinement."
        },
        {
            "claim_id": 11,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics."
        },
        {
            "claim_id": 12,
            "claim_text": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV."
        },
        {
            "claim_id": 13,
            "claim_text": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions."
        },
        {
            "claim_id": 14,
            "claim_text": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual."
        },
        {
            "claim_id": 15,
            "claim_text": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions."
        },
        {
            "claim_id": 16,
            "claim_text": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV."
        },
        {
            "claim_id": 17,
            "claim_text": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4].",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4]."
        },
        {
            "claim_id": 18,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics."
        },
        {
            "claim_id": 19,
            "claim_text": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV."
        },
        {
            "claim_id": 20,
            "claim_text": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions."
        },
        {
            "claim_id": 21,
            "claim_text": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual."
        },
        {
            "claim_id": 22,
            "claim_text": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions."
        },
        {
            "claim_id": 23,
            "claim_text": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV."
        },
        {
            "claim_id": 24,
            "claim_text": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4].",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4]."
        },
        {
            "claim_id": 25,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics."
        },
        {
            "claim_id": 26,
            "claim_text": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV."
        },
        {
            "claim_id": 27,
            "claim_text": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions."
        },
        {
            "claim_id": 28,
            "claim_text": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual."
        },
        {
            "claim_id": 29,
            "claim_text": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions."
        },
        {
            "claim_id": 30,
            "claim_text": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV."
        },
        {
            "claim_id": 31,
            "claim_text": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4].",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4]."
        },
        {
            "claim_id": 32,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics."
        },
        {
            "claim_id": 33,
            "claim_text": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV."
        },
        {
            "claim_id": 34,
            "claim_text": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions."
        },
        {
            "claim_id": 35,
            "claim_text": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual."
        },
        {
            "claim_id": 36,
            "claim_text": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions."
        },
        {
            "claim_id": 37,
            "claim_text": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV."
        },
        {
            "claim_id": 38,
            "claim_text": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4].",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4]."
        },
        {
            "claim_id": 39,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics."
        },
        {
            "claim_id": 40,
            "claim_text": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV."
        },
        {
            "claim_id": 41,
            "claim_text": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions."
        },
        {
            "claim_id": 42,
            "claim_text": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual."
        },
        {
            "claim_id": 43,
            "claim_text": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions."
        },
        {
            "claim_id": 44,
            "claim_text": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV."
        },
        {
            "claim_id": 45,
            "claim_text": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4].",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4]."
        },
        {
            "claim_id": 46,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics."
        },
        {
            "claim_id": 47,
            "claim_text": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV."
        },
        {
            "claim_id": 48,
            "claim_text": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions."
        },
        {
            "claim_id": 49,
            "claim_text": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual."
        },
        {
            "claim_id": 50,
            "claim_text": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions."
        },
        {
            "claim_id": 51,
            "claim_text": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV."
        },
        {
            "claim_id": 52,
            "claim_text": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4].",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4]."
        },
        {
            "claim_id": 53,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics."
        },
        {
            "claim_id": 54,
            "claim_text": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV."
        },
        {
            "claim_id": 55,
            "claim_text": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions."
        },
        {
            "claim_id": 56,
            "claim_text": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual."
        },
        {
            "claim_id": 57,
            "claim_text": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions."
        },
        {
            "claim_id": 58,
            "claim_text": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV."
        },
        {
            "claim_id": 59,
            "claim_text": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4].",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4]."
        },
        {
            "claim_id": 60,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics."
        },
        {
            "claim_id": 61,
            "claim_text": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV."
        },
        {
            "claim_id": 62,
            "claim_text": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions."
        },
        {
            "claim_id": 63,
            "claim_text": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual."
        },
        {
            "claim_id": 64,
            "claim_text": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions."
        },
        {
            "claim_id": 65,
            "claim_text": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV."
        },
        {
            "claim_id": 66,
            "claim_text": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4].",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4]."
        },
        {
            "claim_id": 67,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics."
        },
        {
            "claim_id": 68,
            "claim_text": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves significant performance gains of 1.6 Type@AV and 1.8 Event@AV."
        },
        {
            "claim_id": 69,
            "claim_text": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN outperforms baselines by 3.5 Visual, 1.4 Audio-Visual, and 1.6 Tyep@AV for event-level predictions."
        },
        {
            "claim_id": 70,
            "claim_text": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "Adding the contrastive learning to our MGN achieves the segment-level performance gain of 3.6 Visual and 2.8 Audio-Visual, and the event-level gain of 3.8 Visual and 2.6 Audio-Visual."
        },
        {
            "claim_id": 71,
            "claim_text": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "With the label refinement in MA, we significantly improve MA (w R) by 3.1 segment-level and 4.0 event-level for visual predictions."
        },
        {
            "claim_id": 72,
            "claim_text": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN with both contrastive learning and label refinement achieves the best segment-level performance in terms of Visual, Audio-Visual, Type@AV, and Event@AV."
        },
        {
            "claim_id": 73,
            "claim_text": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4].",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact_quote": "The proposed MGN achieves superior results against previous state-of-the-art methods [1, 2, 3, 4]."
        },
        {
            "claim_id": 74,
            "claim_text": "The proposed MGN achieves the overall best results against previous network baselines in terms most of metrics.",
            "location": "4.2 Comparison to Prior Work",
            "claim_type": "Result",
            "exact

Raw Evidence:


Raw Conclusions:


Execution Times:
claims_analysis_time: 310.34 seconds
evidence_analysis_time: 1.28 seconds
conclusions_analysis_time: 1.28 seconds
total_execution_time: 322.64 seconds
