Claim 1:
Type: result
Statement: Original BERT layers fail to improve the performance of sentence embeddings.
Location: Section 3
Exact Quote: Original BERT layers fail to improve the performance of sentence embeddings.

Evidence:
- Evidence Text: Table 1 shows the BERT layers in bertbase-uncased and roberta-base significantly harm the sentence embeddings performance.
  Strength: strong
  Location: Section 3
  Limitations: None
  Exact Quote: Table 1 shows the BERT layers in bertbase-uncased and roberta-base significantly harm the sentence embeddings performance.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by concrete experimental results showing that BERT layers degrade performance.
Key Limitations: None

--------------------------------------------------

Claim 2:
Type: result
Statement: Embedding biases harm the sentence embeddings performance.
Location: Section 3
Exact Quote: Embedding biases harm the sentence embeddings performance.

Evidence:
- Evidence Text: Table 3 shows the influence of static embedding biases in spearman correlation.
  Strength: strong
  Location: Section 3
  Limitations: None
  Exact Quote: Table 3 shows the influence of static embedding biases in spearman correlation.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results showing that removing biases improves performance.
Key Limitations: None

--------------------------------------------------

Claim 3:
Type: contribution
Statement: Prompt-based sentence embeddings can improve sentence embeddings performance.
Location: Section 4
Exact Quote: Prompt-based sentence embeddings can improve sentence embeddings performance.

Evidence:
- Evidence Text: Table 5 shows that using templates can substantially improve the results of original BERT on all datasets.
  Strength: strong
  Location: Section 5.4
  Limitations: None
  Exact Quote: Table 5 shows that using templates can substantially improve the results of original BERT on all datasets.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results showing that prompt-based methods improve performance.
Key Limitations: None

--------------------------------------------------

Claim 4:
Type: methodology
Statement: Prompt-based contrastive learning with template denoising can improve sentence embeddings performance.
Location: Section 4.3
Exact Quote: Prompt-based contrastive learning with template denoising can improve sentence embeddings performance.

Evidence:
- Evidence Text: Table 8 shows that our method can achieve the best and most stable results among three training objectives.
  Strength: strong
  Location: Section 5.6
  Limitations: None
  Exact Quote: Table 8 shows that our method can achieve the best and most stable results among three training objectives.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results showing that template denoising improves performance.
Key Limitations: None

--------------------------------------------------

Claim 5:
Type: performance
Statement: Prompt-based methods outperform SimCSE in both unsupervised and supervised settings.
Location: Section 5.5
Exact Quote: Prompt-based methods outperform SimCSE in both unsupervised and supervised settings.

Evidence:
- Evidence Text: Table 6 shows that PromptBERT achieves state-of-the-art results in both unsupervised and supervised settings.
  Strength: strong
  Location: Section 5.5
  Limitations: None
  Exact Quote: Table 6 shows that PromptBERT achieves state-of-the-art results in both unsupervised and supervised settings.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results showing that PromptBERT outperforms SimCSE.
Key Limitations: None

--------------------------------------------------

