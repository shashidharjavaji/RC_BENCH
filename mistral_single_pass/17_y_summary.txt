Claim 1:
Type: contribution
Statement: Combining tabular data from financial semi-structured documents with text transcripts and audio recordings improves stock volatility and price movement prediction by 5-12% along with reduction in gender bias learned by audio-based neural networks by over 30%.
Location: Abstract
Exact Quote: In this work, we show that combining tabular data from financial semi-structured documents with text transcripts and audio recordings improves stock volatility and price movement prediction by 5-12% along with reduction in gender bias learned by audio-based neural networks by over 30%.

Evidence:
- Evidence Text: Table 3 shows the performance of several baseline and SOTA models for predicting price movement and stock volatility for Merger & Acquisition calls on the M&A dataset. Table 4 reports the volatility prediction performance on the MAEC dataset.
  Strength: strong
  Location: Section 4
  Limitations: None
  Exact Quote: Table 3 shows the performance of several baseline and SOTA models for predicting price movement and stock volatility for Merger & Acquisition calls on the M&A dataset. Table 4 reports the volatility prediction performance on the MAEC dataset.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by experimental results showing significant improvements in both tasks across multiple models.
Key Limitations: None

--------------------------------------------------

Claim 2:
Type: performance
Statement: The addition of tabular information extracted from company filing data to verbal-vocal cues shows a gain of 10-12% across different settings.
Location: Section 4.1
Exact Quote: The addition of tabular information extracted from company filing data to verbal-vocal cues shows a gain of 10-12% across different settings.

Evidence:
- Evidence Text: Table 5 shows ablation across different modalities observed for the SOTA M3A model applied to both datasets to understand the impact of varying modalities and their correlations.
  Strength: strong
  Location: Section 4.1
  Limitations: None
  Exact Quote: Table 5 shows ablation across different modalities observed for the SOTA M3A model applied to both datasets to understand the impact of varying modalities and their correlations.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by ablation studies showing significant improvements in performance when tabular data is added.
Key Limitations: None

--------------------------------------------------

Claim 3:
Type: result
Statement: The table modality has the least error disparity.
Location: Section 4.1
Exact Quote: The table modality has the least error disparity.

Evidence:
- Evidence Text: Table 6 shows modality specific ∆G i.e. the difference between the MSE and F1 for volatility prediction in Earnings Calls dataset and price prediction in M&A calls, respectively for 3, 7, and 15 days over 5 runs.
  Strength: strong
  Location: Section 4.1
  Limitations: None
  Exact Quote: Table 6 shows modality specific ∆G i.e. the difference between the MSE and F1 for volatility prediction in Earnings Calls dataset and price prediction in M&A calls, respectively for 3, 7, and 15 days over 5 runs.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by empirical data showing that the table modality has the least error disparity.
Key Limitations: None

--------------------------------------------------

Claim 4:
Type: methodology
Statement: Replacing audio clips with tabular data from company filings leads to a reduction of data processing time and data storage requirements by over 90% and 50%, respectively.
Location: Section 4.2
Exact Quote: Replacing audio clips with tabular data from company filings leads to a reduction of data processing time and data storage requirements by over 90% and 50%, respectively.

Evidence:
- Evidence Text: Audio clips require processing-heavy algorithms such as forced alignment to extract meaningful features from linguistic and acoustic utterances as opposed to semi-structured information in tables that can be utilized with minimal processing.
  Strength: strong
  Location: Section 4.2
  Limitations: None
  Exact Quote: Audio clips require processing-heavy algorithms such as forced alignment to extract meaningful features from linguistic and acoustic utterances as opposed to semi-structured information in tables that can be utilized with minimal processing.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by the methodology and processing requirements of audio and tabular data.
Key Limitations: None

--------------------------------------------------

