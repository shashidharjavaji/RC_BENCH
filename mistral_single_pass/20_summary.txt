Claim 1:
Type: methodology
Statement: Large language models generate complex, open-ended outputs.
Location: Abstract
Exact Quote: Large language models generate complex, open-ended outputs: instead of outputting a class label they write summaries, generate dialogue, or produce working code.

Evidence:
- Evidence Text: Large language models generate complex, open-ended outputs.
  Strength: strong
  Location: Abstract
  Limitations: N/A
  Exact Quote: Large language models generate complex, open-ended outputs: instead of outputting a class label they write summaries, generate dialogue, or produce working code.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is directly stated in the abstract and is supported by the methodology described.
Key Limitations: N/A

--------------------------------------------------

Claim 2:
Type: methodology
Statement: The open-ended power of these systems poses new reliability challenges.
Location: Abstract
Exact Quote: The open-ended power of these systems, however, poses new reliability challenges.

Evidence:
- Evidence Text: The open-ended power of these systems, however, poses new reliability challenges.
  Strength: strong
  Location: Abstract
  Limitations: N/A
  Exact Quote: The open-ended power of these systems, however, poses new reliability challenges.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is directly stated in the abstract and is supported by the methodology described.
Key Limitations: N/A

--------------------------------------------------

Claim 3:
Type: methodology
Statement: We aim to identify qualitative categories of erroneous behavior, beyond identifying individual errors.
Location: Abstract
Exact Quote: To hypothesize and test for such qualitative errors, we draw inspiration from human cognitive biases—systematic patterns of deviation from rational judgement.

Evidence:
- Evidence Text: To hypothesize and test for such qualitative errors, we draw inspiration from human cognitive biases—systematic patterns of deviation from rational judgement.
  Strength: strong
  Location: Abstract
  Limitations: N/A
  Exact Quote: To hypothesize and test for such qualitative errors, we draw inspiration from human cognitive biases—systematic patterns of deviation from rational judgement.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is directly stated in the abstract and is supported by the methodology described.
Key Limitations: N/A

--------------------------------------------------

Claim 4:
Type: methodology
Statement: We use cognitive biases as motivation to (i) generate hypotheses for problems that models may have, and (ii) develop experiments that elicit these problems.
Location: Abstract
Exact Quote: We use cognitive biases as motivation to (i) generate hypotheses for problems that models may have, and (ii) develop experiments that elicit these problems.

Evidence:
- Evidence Text: We use cognitive biases as motivation to (i) generate hypotheses for problems that models may have, and (ii) develop experiments that elicit these problems.
  Strength: strong
  Location: Abstract
  Limitations: N/A
  Exact Quote: We use cognitive biases as motivation to (i) generate hypotheses for problems that models may have, and (ii) develop experiments that elicit these problems.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is directly stated in the abstract and is supported by the methodology described.
Key Limitations: N/A

--------------------------------------------------

Claim 5:
Type: result
Statement: We find that OpenAI’s Codex errs predictably based on how the input prompt is framed, adjusts outputs towards anchors, and is biased towards outputs that mimic frequent training examples.
Location: Abstract
Exact Quote: We find that OpenAI’s Codex errs predictably based on how the input prompt is framed, adjusts outputs towards anchors, and is biased towards outputs that mimic frequent training examples.

Evidence:
- Evidence Text: We find that OpenAI’s Codex errs predictably based on how the input prompt is framed, adjusts outputs towards anchors, and is biased towards outputs that mimic frequent training examples.
  Strength: strong
  Location: Abstract
  Limitations: N/A
  Exact Quote: We find that OpenAI’s Codex errs predictably based on how the input prompt is framed, adjusts outputs towards anchors, and is biased towards outputs that mimic frequent training examples.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is directly stated in the abstract and is supported by the methodology described.
Key Limitations: N/A

--------------------------------------------------

Claim 6:
Type: result
Statement: We then use our framework to elicit high-impact errors such as incorrectly deleting files.
Location: Abstract
Exact Quote: We then use our framework to elicit high-impact errors such as incorrectly deleting files.

Evidence:
- Evidence Text: We then use our framework to elicit high-impact errors such as incorrectly deleting files.
  Strength: strong
  Location: Abstract
  Limitations: N/A
  Exact Quote: We then use our framework to elicit high-impact errors such as incorrectly deleting files.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is directly stated in the abstract and is supported by the methodology described.
Key Limitations: N/A

--------------------------------------------------

Claim 7:
Type: result
Statement: Our results indicate that experimental methodology from cognitive science can help characterize how machine learning systems behave.
Location: Abstract
Exact Quote: Our results indicate that experimental methodology from cognitive science can help characterize how machine learning systems behave.

Evidence:
- Evidence Text: Our results indicate that experimental methodology from cognitive science can help characterize how machine learning systems behave.
  Strength: strong
  Location: Abstract
  Limitations: N/A
  Exact Quote: Our results indicate that experimental methodology from cognitive science can help characterize how machine learning systems behave.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is directly stated in the abstract and is supported by the methodology described.
Key Limitations: N/A

--------------------------------------------------

