Claim 1:
Type: contribution
Statement: LLMs often struggle with the inherent uncertainties of human communication, leading to misinterpretations, miscommunications, and biased responses which weaken their ability to be used for real-world tasks.
Location: Introduction
Exact Quote: LLMs often struggle with the inherent uncertainties of human communication, leading to misinterpretations, miscommunications, and biased responses which weaken their ability to be used for real-world tasks.

Evidence:
- Evidence Text: Recent work has demonstrated how LLMs struggle to understand ambiguous text in prompts and instructions.
  Strength: strong
  Location: Introduction
  Limitations: Limited to specific examples and anecdotal evidence.
  Exact Quote: Recent work has demonstrated how LLMs struggle to understand ambiguous text in prompts and instructions.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by specific examples and anecdotal evidence.
Key Limitations: Limited to specific examples and anecdotal evidence.

--------------------------------------------------

Claim 2:
Type: contribution
Statement: Simple, training-free, token-level disambiguation methods may be effectively used to improve LLM performance for ambiguous question answering tasks.
Location: Abstract
Exact Quote: Simple, training-free, token-level disambiguation methods may be effectively used to improve LLM performance for ambiguous question answering tasks.

Evidence:
- Evidence Text: We empirically show our findings and discuss best practices and broader impacts regarding ambiguity in LLMs.
  Strength: strong
  Location: Abstract
  Limitations: Limited to specific methods and datasets.
  Exact Quote: We empirically show our findings and discuss best practices and broader impacts regarding ambiguity in LLMs.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by empirical findings and discussion of best practices.
Key Limitations: Limited to specific methods and datasets.

--------------------------------------------------

Claim 3:
Type: methodology
Statement: Using open-domain question answering as a test case, we compare off-the-shelf and few-shot LLM performance, focusing on measuring the impact of explicit disambiguation strategies.
Location: Introduction
Exact Quote: Using open-domain question answering as a test case, we compare off-the-shelf and few-shot LLM performance, focusing on measuring the impact of explicit disambiguation strategies.

Evidence:
- Evidence Text: We conduct a series of controlled experiments involving the two LLMs on a dataset of ambiguous real-world questions.
  Strength: strong
  Location: Methodology and Experimental Settings
  Limitations: Limited to specific datasets and models.
  Exact Quote: We conduct a series of controlled experiments involving the two LLMs on a dataset of ambiguous real-world questions.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by specific experimental methodology.
Key Limitations: Limited to specific datasets and models.

--------------------------------------------------

Claim 4:
Type: result
Statement: We demonstrate how simple, training-free, token-level disambiguation methods may be effectively used to improve LLM performance for ambiguous question answering tasks.
Location: Abstract
Exact Quote: We demonstrate how simple, training-free, token-level disambiguation methods may be effectively used to improve LLM performance for ambiguous question answering tasks.

Evidence:
- Evidence Text: We empirically show our findings and discuss best practices and broader impacts regarding ambiguity in LLMs.
  Strength: strong
  Location: Abstract
  Limitations: Limited to specific methods and datasets.
  Exact Quote: We empirically show our findings and discuss best practices and broader impacts regarding ambiguity in LLMs.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by empirical findings and discussion of best practices.
Key Limitations: Limited to specific methods and datasets.

--------------------------------------------------

Claim 5:
Type: contribution
Statement: Simple training-free prompting methods for disambiguation work well in improving performance.
Location: Results and Discussion
Exact Quote: Simple training-free prompting methods for disambiguation work well in improving performance.

Evidence:
- Evidence Text: Interestingly, we see that for both GPT 4o and 4o-mini, using simple disambiguating prompts improves performance over the naive setting.
  Strength: strong
  Location: Results and Discussion
  Limitations: Limited to specific models and datasets.
  Exact Quote: Interestingly, we see that for both GPT 4o and 4o-mini, using simple disambiguating prompts improves performance over the naive setting.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by specific experimental results.
Key Limitations: Limited to specific models and datasets.

--------------------------------------------------

Claim 6:
Type: result
Statement: Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.
Location: Results and Discussion
Exact Quote: Contextual enrichment has the ability to significantly enhance model disambiguation accuracy, but it is often inaccurate because it tends to add irrelevant context to questions.

Evidence:
- Evidence Text: Although adding context should skew the plot 2 to the right (ie: be more similar to the ground truth), but instead its skewed to the left since its being held back every time it adds the wrong context which is not a problem when we have simply rephrased the question.
  Strength: strong
  Location: Results and Discussion
  Limitations: Limited to specific datasets and models.
  Exact Quote: Although adding context should skew the plot 2 to the right (ie: be more similar to the ground truth), but instead its skewed to the left since its being held back every time it adds the wrong context which is not a problem when we have simply rephrased the question.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The claim is supported by specific experimental results.
Key Limitations: Limited to specific datasets and models.

--------------------------------------------------

