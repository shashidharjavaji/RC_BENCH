{
    "paper_analysis": [
        {
            "claim_id": 1,
            "claim": {
                "text": "Incorporating external knowledge into large language models (LLMs) has emerged as a promising approach to mitigate outdated knowledge and hallucination in LLMs.",
                "location": "Abstract",
                "type": "Methodology",
                "exact_quote": "Incorporating external knowledge into large language models (LLMs) has emerged as a promising approach to mitigate outdated knowledge and hallucination in LLMs."
            },
            "evidence": [
                {
                    "evidence_id": 1,
                    "evidence_text": "Incorporating external knowledge into large language models (LLMs) has emerged as an effective approach to mitigate this problem (Tu et al., 2024; Zhao et al., 2024).",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Abstract",
                    "exact_quote": "Incorporating external knowledge into large language models (LLMs) has emerged as an effective approach to mitigate this problem (Tu et al., 2024; Zhao et al., 2024)."
                },
                {
                    "evidence_id": 2,
                    "evidence_text": "External knowledge is often imperfect. In addition to useful knowledge, external knowledge is rich in irrelevant or misinformation in the context that can impair the reliability of LLM responses.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Abstract",
                    "exact_quote": "External knowledge is often imperfect. In addition to useful knowledge, external knowledge is rich in irrelevant or misinformation in the context that can impair the reliability of LLM responses."
                }
            ],
            "conclusion": {
                "claim_id": 1,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 2,
            "claim": {
                "text": "External knowledge is often imperfect, containing irrelevant information and misinformation that can impair the reliability of LLM responses.",
                "location": "Abstract",
                "type": "Problem Statement",
                "exact_quote": "External knowledge is often imperfect. In addition to useful knowledge, external knowledge is rich in irrelevant or misinformation in the context that can impair the reliability of LLM responses."
            },
            "evidence": [],
            "conclusion": {
                "claim_id": 2,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 3,
            "claim": {
                "text": "The paper proposes an automated Chain of Evidence (CoE) discrimination approach to characterize and explore LLMs' preferences for external knowledge.",
                "location": "Abstract",
                "type": "Methodology",
                "exact_quote": "This paper focuses on LLMs\u2019 preferred external knowledge in imperfect contexts when handling multi-hop QA. Inspired by criminal procedural law\u2019s Chain of Evidence (CoE), we characterize that knowledge preferred by LLMs should maintain both relevance to the question and mutual support among knowledge pieces."
            },
            "evidence": [
                {
                    "evidence_id": 3,
                    "evidence_text": "This paper proposes an automated Chain of Evidence (CoE) discrimination approach and explore LLMs\u2019 preferences from their effectiveness, faithfulness and robustness, as well as CoE\u2019s usability in a naive Retrieval-Augmented Generation (RAG) case.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Abstract",
                    "exact_quote": "This paper focuses on LLMs\u2019 preferred external knowledge in imperfect contexts when handling multi-hop QA. Inspired by criminal procedural law\u2019s Chain of Evidence (CoE), we characterize that knowledge preferred by LLMs should maintain both relevance to the question and mutual support among knowledge pieces. Accordingly, we propose an automated CoE discrimination approach and explore LLMs\u2019 preferences from their effectiveness, faithfulness and robustness, as well as CoE\u2019s usability in a naive Retrieval-Augmented Generation (RAG) case."
                }
            ],
            "conclusion": {
                "claim_id": 3,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 4,
            "claim": {
                "text": "The CoE discrimination approach enhances LLMs' performance in terms of accuracy, faithfulness, robustness, and usability in a naive Retrieval-Augmented Generation (RAG) case.",
                "location": "Abstract",
                "type": "Methodology",
                "exact_quote": "The evaluation on five LLMs reveals that CoE enhances LLMs through more accurate generation, stronger answer faithfulness, better robustness against knowledge conflict, and improved performance in a popular RAG case."
            },
            "evidence": [
                {
                    "evidence_id": 4,
                    "evidence_text": "The evaluation on five LLMs reveals that CoE enhances LLMs through more accurate generation, stronger answer faithfulness, better robustness against knowledge conflict, and improved performance in a popular RAG case.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Abstract",
                    "exact_quote": "The evaluation on five LLMs reveals that CoE enhances LLMs through more accurate generation, stronger answer faithfulness, better robustness against knowledge conflict, and improved performance in a popular RAG case."
                }
            ],
            "conclusion": {
                "claim_id": 4,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 5,
            "claim": {
                "text": "LLMs exhibit a preference for external knowledge that forms a Chain of Evidence (CoE), demonstrating relevance and interconnectivity among knowledge pieces.",
                "location": "Introduction",
                "type": "Methodology",
                "exact_quote": "In our study, we focus on characterizing what external knowledge is more capable of resisting the surrounding noise and guiding LLMs for better generation."
            },
            "evidence": [
                {
                    "evidence_id": 5,
                    "evidence_text": "Inspired by the Chain of Evidence (CoE) theory in criminal procedural law (Murphy, 2013), we characterize that knowledge preferred by LLMs should maintain both relevance to the question and mutual support among knowledge pieces.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Introduction",
                    "exact_quote": "Inspired by the Chain of Evidence (CoE) theory in criminal procedural law (Murphy, 2013), we characterize that knowledge preferred by LLMs should maintain both relevance to the question and mutual support among knowledge pieces."
                },
                {
                    "evidence_id": 5,
                    "evidence_text": "Accordingly, we propose an automated CoE discrimination approach and explore LLMs\u2019 preferences from their effectiveness, faithfulness and robustness, as well as CoE\u2019s usability in a naive Retrieval-Augmented Generation (RAG) case.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Introduction",
                    "exact_quote": "Accordingly, we propose an automated CoE discrimination approach and explore LLMs\u2019 preferences from their effectiveness, faithfulness and robustness, as well as CoE\u2019s usability in a naive Retrieval-Augmented Generation (RAG) case."
                }
            ],
            "conclusion": {
                "claim_id": 5,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 6,
            "claim": {
                "text": "The CoE discrimination approach can effectively identify relevant and interconnected external knowledge.",
                "location": "Introduction",
                "type": "Methodology",
                "exact_quote": "Based on the principle, we first characterize what knowledge can be considered CoE and propose a discrimination approach to determine whether the given external knowledge contains CoE."
            },
            "evidence": [
                {
                    "evidence_id": 6,
                    "evidence_text": "The evaluation on five LLMs reveals that CoE enhances LLMs through more accurate generation, stronger answer faithfulness, better robustness against knowledge conflict, and improved performance in a popular RAG case.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "Abstract",
                    "exact_quote": "The evaluation on five LLMs reveals that CoE enhances LLMs through more accurate generation, stronger answer faithfulness, better robustness against knowledge conflict, and improved performance in a popular RAG case."
                }
            ],
            "conclusion": {
                "claim_id": 6,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 7,
            "claim": {
                "text": "External knowledge equipped with CoE helps LLMs generate correct answers more effectively than Non-CoE.",
                "location": "5. Effectiveness Assessment",
                "type": "Finding",
                "exact_quote": "External knowledge equipped with CoE can more effectively (than Non-CoE) help LLMs generate correct answers in context rich with irrelevant information."
            },
            "evidence": [
                {
                    "evidence_id": 7,
                    "evidence_text": "Using HotpotQA (Yang et al., 2018) and 2WikiMultihopQA (Ho et al., 2020) as sources, we constructed 1,336 multi-hop QA pairs and the corresponding CoE based on the proposed CoE discrimination approach.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "3 CoE Discrimination Approach",
                    "exact_quote": "Using HotpotQA (Yang et al., 2018) and 2WikiMultihopQA (Ho et al., 2020) as sources, we constructed 1,336 multi-hop QA pairs and the corresponding CoE based on the proposed CoE discrimination approach."
                },
                {
                    "evidence_id": 7,
                    "evidence_text": "By applying perturbations to CoE, we also build Non-CoE samples (that is, knowledge lacking the necessary relevance or interconnectivity to establish CoE) for each QA pair.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "4 Subject Dataset and LLMs",
                    "exact_quote": "By applying perturbations to CoE, we also build Non-CoE samples (that is, knowledge lacking the necessary relevance or interconnectivity to establish CoE) for each QA pair."
                }
            ],
            "conclusion": {
                "claim_id": 7,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 8,
            "claim": {
                "text": "LLMs exhibit higher faithfulness to the answer implicated in CoE, even when CoE contains factual errors.",
                "location": "6. Faithfulness Assessment",
                "type": "Finding",
                "exact_quote": "LLMs exhibit higher faithfulness to the answer implicated in CoE (than Non-CoE), even when CoE contains factual errors."
            },
            "evidence": [
                {
                    "evidence_id": 8,
                    "evidence_text": "LLMs exhibit higher faithfulness to the answer implicated in CoE (than Non-CoE), even when CoE contains factual errors.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "6 Faithfulness Assessment",
                    "exact_quote": "LLMs exhibit higher faithfulness to the answer implicated in CoE (than Non-CoE), even when CoE contains factual errors."
                }
            ],
            "conclusion": {
                "claim_id": 8,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 9,
            "claim": {
                "text": "LLMs exhibit higher robustness against knowledge conflict when external knowledge is equipped with CoE.",
                "location": "7. Robustness Assessment",
                "type": "Finding",
                "exact_quote": "LLMs augmented with CoE exibit higher robustness against knowledge conflict than Non-CoE."
            },
            "evidence": [
                {
                    "evidence_id": 9,
                    "evidence_text": "LLMs exhibit higher robustness against knowledge conflict (than Non-CoE) if the external knowledge is equipped with CoE.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "7 Robustness Assessment",
                    "exact_quote": "LLMs augmented with CoE ex-hibit higher robustness against knowledge con-flict than Non-CoE."
                }
            ],
            "conclusion": {
                "claim_id": 9,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 10,
            "claim": {
                "text": "The CoE-guided retrieval strategy improves LLMs' accuracy in the naive RAG framework.",
                "location": "8. Usability Assessment",
                "type": "Finding",
                "exact_quote": "For the subject case, CoE-guided retrieval could improve the LLMs\u2019 accuracy in the naive framework."
            },
            "evidence": [
                {
                    "evidence_id": 10,
                    "evidence_text": "For the selected case, the CoE-guided retrieval strategy can effectively improve LLM\u2019s accuracy after substituting the reranking component in the naive RAG framework.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "8 Usability Assessment",
                    "exact_quote": "For the selected case, the CoE-guided retrieval strategy can effectively improve LLM\u2019s accuracy after substituting the reranking component in the naive RAG framework."
                }
            ],
            "conclusion": {
                "claim_id": 10,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 11,
            "claim": {
                "text": "The CoE-guided retrieval strategy makes LLMs more efficient in knowledge utilization, leading to improved performance and reduced dependency on large amounts of external data.",
                "location": "8. Usability Assessment",
                "type": "Finding",
                "exact_quote": "ScopeCoE can help LLMs generate more accurate outputs with fewer knowledge pieces."
            },
            "evidence": [
                {
                    "evidence_id": 11,
                    "evidence_text": "The CoE-guided retrieval strategy makes LLMs more efficient in knowledge utilization, leading to improved performance and reduced dependency on large amounts of external data.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "8 Usability Assessment",
                    "exact_quote": "The CoE-guided retrieval strategy makes LLMs more efficient in knowledge utilization, leading to improved performance and reduced dependency on large amounts of external data."
                }
            ],
            "conclusion": {
                "claim_id": 11,
                "conclusion_justified": true,
                "robustness": "high",
                "key_limitations": "None",
                "confidence_level": "high"
            }
        },
        {
            "claim_id": 12,
            "claim": {
                "text": "The paper's findings provide insights for future research in designing the retrieval process and assessing the quality of external knowledge.",
                "location": "Conclusion",
                "type": "Conclusion",
                "exact_quote": "The above findings could provide insights for future research in designing the retrieval process and assessing the quality of external knowledge with the proposed CoE discrimination approach."
            },
            "evidence": [
                {
                    "evidence_id": 12,
                    "evidence_text": "The above findings could provide insights for future research in designing the retrieval process and assessing the quality of external knowledge with the proposed CoE discrimination approach.",
                    "strength": "strong",
                    "limitations": "None",
                    "location": "9 Conclusion",
                    "exact_quote": "The above findings could provide insights for future research in designing the retrieval process and assessing the quality of external knowledge with the proposed CoE discrimination approach."
                }
            ],
            "conclusion": {
                "claim_id": 12,
                "conclusion_justified": true,
                "robustness": "medium",
                "key_limitations": "The paper does not explore broader applications of CoE in RAG scenarios, such as retrieval corpus construction and retriever optimization.",
                "confidence_level": "medium"
            }
        }
    ],
    "execution_times": {
        "claims_analysis_time": "133.30 seconds",
        "evidence_analysis_time": "239.00 seconds",
        "conclusions_analysis_time": "70.44 seconds",
        "total_execution_time": "445.94 seconds"
    }
}