Claim 1:
Type: performance
Statement: kNN-Prompt substantially improves zero-shot performance on a wide range of multiple-choice and classification tasks.
Location: Abstract
Exact Quote: kNN-Prompt substantially improves zero-shot performance on a wide range of multiple-choice and classification tasks.

Evidence:
- Evidence Text: kNN-Prompt outperforms all baselines in all tasks, improving over the base LM by 13.4% on average.
  Strength: strong
  Location: Experimental Results
  Limitations: None mentioned in the abstract
  Exact Quote: kNN-Prompt outperforms all baselines in all tasks, improving over the base LM by 13.4% on average.

- Evidence Text: kNN-Prompt consistently outperforms baselines in few-shot inference.
  Strength: strong
  Location: Few-shot inference
  Limitations: None mentioned in the abstract
  Exact Quote: kNN-Prompt consistently outperform baselines, demonstrating that kNN-Prompt is applicable to the few-shot setting as well.

- Evidence Text: kNN-Prompt enables efficient domain adaptation with no additional training.
  Strength: strong
  Location: Domain adaptation
  Limitations: None mentioned in the abstract
  Exact Quote: kNN-Prompt enables efficient domain adaptation with no additional training.

- Evidence Text: The benefits of kNN-Prompt scale with the size of the retrieval model.
  Strength: moderate
  Location: Retrieval model size and inference model size
  Limitations: None mentioned in the abstract
  Exact Quote: The benefits of kNN-Prompt scale with the size of the retrieval model.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The experimental results show consistent improvement over baselines in multiple tasks and settings.
Key Limitations: None mentioned in the abstract

--------------------------------------------------

Claim 2:
Type: methodology
Statement: kNN-Prompt incorporates three features on top of the base LM: kNN retrieval and interpolation, fuzzy verbalizers, and PMI scoring.
Location: Method
Exact Quote: kNN-Prompt incorporates three features on top of the base LM: kNN retrieval and interpolation (Section 2.2), fuzzy verbalizers (Section 2.3), and PMI scoring (Section 2.4).

Evidence:
- Evidence Text: kNN-Prompt's performance is analyzed through ablation studies.
  Strength: moderate
  Location: Model ablations
  Limitations: None mentioned in the abstract
  Exact Quote: Table 5 shows the results of ablation experiments analyzing the contribution of each component.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The ablation studies provide evidence for the contribution of each component to the overall performance.
Key Limitations: None mentioned in the abstract

--------------------------------------------------

Claim 3:
Type: result
Statement: Adding kNN to LM gives trivial improvement (+0.4%), but much greater once we add fuzzy verbalizers on top of them (+10.3%).
Location: Model ablations
Exact Quote: First, we find that adding kNN to LM gives trivial improvement (+0.4%), but much greater once we add fuzzy verbalizers on top of them (+10.3%).

Evidence:
- Evidence Text: kNN-LM alone yields a fairly small improvement over the base LM (about 0.4% on average).
  Strength: strong
  Location: Model ablations
  Limitations: None mentioned in the abstract
  Exact Quote: First, we find that adding kNN to LM gives trivial improvement (+0.4% on average).

- Evidence Text: With fuzzy verbalizers, this increases to 78%.
  Strength: strong
  Location: Model ablations
  Limitations: None mentioned in the abstract
  Exact Quote: With fuzzy verbalizers, this increases to 78%.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The experimental results show a significant improvement when fuzzy verbalizers are added to kNN-LM.
Key Limitations: None mentioned in the abstract

--------------------------------------------------

Claim 4:
Type: result
Statement: The effect of PMI scoring is increased when using fuzzy verbalizers and kNN retrieval together.
Location: Model ablations
Exact Quote: The effect of PMI scoring is increased, however, when we use fuzzy verbalizers and kNN retrieval together (+13.4% for the full model versus +10.3% for kNN with fuzzy verbalizers).

Evidence:
- Evidence Text: With fuzzy verbalizers, this increases to 78%.
  Strength: strong
  Location: Model ablations
  Limitations: None mentioned in the abstract
  Exact Quote: With fuzzy verbalizers, this increases to 78%.

- Evidence Text: The effect of PMI scoring is increased, however, when we use fuzzy verbalizers and kNN retrieval together (+13.4% for the full model versus +10.3% for kNN with fuzzy verbalizers).
  Strength: strong
  Location: Model ablations
  Limitations: None mentioned in the abstract
  Exact Quote: The effect of PMI scoring is increased, however, when we use fuzzy verbalizers and kNN retrieval together (+13.4% for the full model versus +10.3% for kNN with fuzzy verbalizers).

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The experimental results show a significant improvement when fuzzy verbalizers and kNN retrieval are used together.
Key Limitations: None mentioned in the abstract

--------------------------------------------------

Claim 5:
Type: result
Statement: Performance monotonically improves with the number of neighbors as k is increased to 1024.
Location: kNN retrieval hyperparameters
Exact Quote: Figure 4 shows how the number of retrieved neighbors (k) and softmax temperature affect model performance on three datasets. In most cases, performance monotonically improves with the number of neighbors as k is increased to 1024.

Evidence:
- Evidence Text: Performance monotonically improves with the number of neighbors as k is increased to 1024.
  Strength: strong
  Location: kNN retrieval hyperparameters
  Limitations: None mentioned in the abstract
  Exact Quote: Performance monotonically improves with the number of neighbors as k is increased to 1024.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The experimental results show a consistent improvement with increasing the number of neighbors.
Key Limitations: None mentioned in the abstract

--------------------------------------------------

Claim 6:
Type: result
Statement: The benefits of kNN-Prompt scale with the size of the retrieval model.
Location: Retrieval model size and inference model size
Exact Quote: The benefits of kNN-Prompt scale with the size of the retrieval model.

Evidence:
- Evidence Text: Substantial gains as the size of the retriever increases, which hold regardless of inference model size.
  Strength: strong
  Location: Retrieval model size and inference model size
  Limitations: None mentioned in the abstract
  Exact Quote: Substantial gains as the size of the retriever increases, which hold regardless of inference model size.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The experimental results show a consistent improvement with increasing the size of the retriever.
Key Limitations: None mentioned in the abstract

--------------------------------------------------

