Claim 1:
Type: methodology
Statement: Knowledge neurons in pretrained Transformers can be identified using a knowledge attribution method.
Location: Section 3: Identifying Knowledge Neurons
Exact Quote: We propose a knowledge attribution method to identify the neurons that express a relational fact.

Evidence:
- Evidence Text: The knowledge attribution method computes the contribution of each neuron to the knowledge prediction.
  Strength: strong
  Location: Section 3: Knowledge Attribution
  Limitations: The method assumes that knowledge is stored in feed-forward network (FFN) modules and may not account for other components.
  Exact Quote: Our method can evaluate the contribution of each neuron to knowledge predictions.

- Evidence Text: The method identifies neurons by computing the inner product of FFN(key) and FFN(val).
  Strength: moderate
  Location: Section 3: Knowledge Attribution
  Limitations: The method relies on the analogy between FFNs and key-value memories, which may not fully capture the complexity of knowledge storage.
  Exact Quote: We view FFNs in Transformer as key-value memories as illustrated in Figure 2.

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The method is based on a clear and well-defined process of attributing knowledge to neurons.
Key Limitations: The method may not account for other components of Transformers that store knowledge.

--------------------------------------------------

Claim 2:
Type: result
Statement: Knowledge neurons are positively correlated to knowledge expression.
Location: Section 4.5: Knowledge Neurons are Activated by Knowledge-Expressing Prompts
Exact Quote: For our method, the identified knowledge neurons are more significantly activated by knowledge-expressing prompts.

Evidence:
- Evidence Text: The average activation of knowledge neurons for knowledge-expressing prompts is higher than for control groups.
  Strength: strong
  Location: Section 4.5: Knowledge Neurons are Activated by Knowledge-Expressing Prompts
  Limitations: The comparison is based on a specific dataset and may not generalize to other datasets.
  Exact Quote: For our method, the identified knowledge neurons are more significantly activated by knowledge-expressing prompts (T1 = 0.485).

- Evidence Text: The activation of knowledge neurons can distinguish knowledge-expressing prompts from control groups.
  Strength: moderate
  Location: Section 4.5: Knowledge Neurons are Activated by Knowledge-Expressing Prompts
  Limitations: The method may not account for other factors that influence neuron activation.
  Exact Quote: For our method, the identified knowledge neurons are more significantly activated by knowledge-expressing prompts (T1 = 0.485).

Evaluation:
Conclusion Justified: Yes
Robustness: high
Confidence Level: high
Justification: The evidence shows a clear correlation between knowledge neurons and knowledge expression.
Key Limitations: The method may not account for other factors that influence neuron activation.

--------------------------------------------------

Claim 3:
Type: contribution
Statement: Knowledge neurons can be used to update or erase specific factual knowledge in pretrained Transformers.
Location: Section 5: Case Studies
Exact Quote: We present two preliminary studies that attempt to utilize knowledge neurons to update or erase knowledge in pretrained Transformers.

Evidence:
- Evidence Text: The success rate of updating facts using knowledge neurons is 34.4%.
  Strength: moderate
  Location: Section 5: Case Studies
  Limitations: The success rate may vary depending on the complexity of the fact and the number of knowledge neurons manipulated.
  Exact Quote: The surgery of knowledge neurons achieves a nontrivial success rate for updating facts, while random neurons are insufficient.

- Evidence Text: The perplexity of the removed knowledge increases after erasing knowledge neurons.
  Strength: strong
  Location: Section 5: Case Studies
  Limitations: The method may not be effective for all types of knowledge or relations.
  Exact Quote: With the erasing operation, the perplexity of the removed knowledge increases as expected.

Evaluation:
Conclusion Justified: Yes
Robustness: medium
Confidence Level: medium
Justification: The evidence shows that knowledge neurons can be used to manipulate factual knowledge.
Key Limitations: The method may not be effective for all types of knowledge or relations.

--------------------------------------------------

